<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>BMMB 554 / 2017</title>
    <link>https://nekrut.github.io/BMMB554/index.xml</link>
    <description>Recent content on BMMB 554 / 2017</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 13 Feb 2017 10:11:10 -0400</lastBuildDate>
    <atom:link href="https://nekrut.github.io/BMMB554/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>9. Non-diploid variant calling</title>
      <link>https://nekrut.github.io/BMMB554/post/topic9/</link>
      <pubDate>Mon, 13 Feb 2017 10:11:10 -0400</pubDate>
      
      <guid>https://nekrut.github.io/BMMB554/post/topic9/</guid>
      <description>

&lt;p&gt;The majority of life on Earth is non-diploid and represented by prokaryotes, viruses and their derivatives such as our own mitochondria or plant&amp;rsquo;s chloroplasts. In non-diploid systems allele frequencies can range anywhere between 0 and 100% and there could be multiple (not just two) alleles per locus. The main challenge associated with non-diploid variant calling is the difficulty in distinguishing between sequencing noise (abundant in all NGS platforms) and true low frequency variants. Some of the early attempts to do this well have been accomplished on human mitochondrial DNA although the same approaches will work equally good on viral and bacterial genomes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2014 | &lt;a href=&#34;http://www.pnas.org/content/111/43/15474.abstract&#34;&gt;Maternal age effect and severe germ-line bottleneck in the inheritance of human mitochondrial DNA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2015 | &lt;a href=&#34;http://www.pnas.org/content/112/8/2491.abstract&#34;&gt;Extensive tissue-related and allele-related mtDNA heteroplasmy suggests positive selection for somatic mutations&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As an example of non-diploid system we will be using human mitochondrial genome as an example. However, this approach will also work for most bacterial and viral genomes as well.&lt;/p&gt;

&lt;h1 id=&#34;mapping-and-pre-processing&#34;&gt;Mapping and pre-processing&lt;/h1&gt;

&lt;p&gt;There are two ways one can call variants:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;By comparing reads against an existing genome assembly&lt;/li&gt;
&lt;li&gt;By assembling genome first and then mapping against that assembly&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/ref_vs_assembly.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This figure from a manuscript by &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4493402/&#34;&gt;Olson:2015&lt;/a&gt; contrasts the two approaches.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In this tutorials we will take the &lt;em&gt;first&lt;/em&gt; path is which we map reads against an existing assembly. Later in the course (after we learn about assembly approaches) we will try the second approach as well.&lt;/p&gt;

&lt;h2 id=&#34;finding-variants-in-human-mitochondria&#34;&gt;Finding variants in human mitochondria&lt;/h2&gt;

&lt;p&gt;The goal of this example is to detect heteroplasmies (variants within mitochondrial DNA). Mitochondria is transmitted maternally and heteroplasmy frequencies may change dramatically and unpredictably during the transmission, due to a germ-line bottleneck &lt;a href=&#34;http://www.nature.com/ng/journal/v40/n2/abs/ng.2007.63.html&#34;&gt;Cree:2008&lt;/a&gt;. As we mentioned above the procedure for finding variants in bacterial or viral genomes will be essentially the same.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://usegalaxy.org/library/list#folders/Fe4842bd0c37b03a7&#34;&gt;A Galaxy Library&lt;/a&gt; contains datasets representing a child and a mother. These datasets are obtained by paired-end Illumina sequencing of human genomic DNA enriched for mitochondria. The enrichment was performed using long-range PCR with two primer pairs that amplify the entire mitochondrial genome. This means that these samples still contain a lot of DNA from the nuclear genome, which, in this case, is a contaminant.&lt;/p&gt;

&lt;p&gt;But first lets import data into Galaxy:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_lib.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Select four datasets from &lt;a href=&#34;https://usegalaxy.org/library/list#folders/Fe4842bd0c37b03a7&#34;&gt;a library&lt;/a&gt; and click &lt;strong&gt;to History&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let&amp;rsquo;s QC the datasets first by running  &lt;strong&gt;NGS: QC and manipulation &amp;#8594; FastQC&lt;/strong&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_qc.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;QC&amp;rsquo;ing reads using &lt;a href=&#34;http://www.bioinformatics.babraham.ac.uk/projects/fastqc/&#34;&gt;FastQC&lt;/a&gt;. Note that we selected all four datasets at once by pressing the middle button &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_middle_button.png&#34; alt=&#34;&#34; /&gt; adjacent to the &lt;strong&gt;Short read data from your current history&lt;/strong&gt; widget.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The data have generally high quality in this example:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_qc_plot.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;FastQC plot for one of the mitochondrial datasets shows that qualities are acceptable for 250 bp reads (mostly in the green, which is at or above &lt;a href=&#34;https://en.wikipedia.org/wiki/Phred_quality_scorescore&#34;&gt;phred score&lt;/a&gt; of 30).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;mapping-the-reads&#34;&gt;Mapping the reads&lt;/h2&gt;

&lt;p&gt;Our reads are long (250 bp) and as a result we will be using &lt;a href=&#34;https://arxiv.org/pdf/1303.3997v2.pdf&#34;&gt;bwa mem&lt;/a&gt; to align them against the reference genome as it has good mapping performance for longer reads (100bp and up).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_bwa_mem.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Running &lt;code&gt;bwa mem&lt;/code&gt; on our datasets. Look &lt;strong&gt;carefully&lt;/strong&gt; at parameter settings:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;We select &lt;code&gt;hg38&lt;/code&gt; version of the human genome as the reference&lt;/li&gt;
&lt;li&gt;By using the middle button again &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_middle_button.png&#34; alt=&#34;&#34; /&gt; we select datasets 1 and 3 as &lt;strong&gt;Select the first set of reads&lt;/strong&gt; and datasets 2 and 4 as &lt;strong&gt;Select the second set of reads&lt;/strong&gt;. Galaxy will automatically launch two bwa-mem jobs using datasets 1,2 and 3,4 generating two resulting BAM files.&lt;/li&gt;
&lt;li&gt;By setting &lt;strong&gt;Set read groups information&lt;/strong&gt; to `Set read groups (SAM/BAM specifications) and clicking &lt;strong&gt;Auto-assign&lt;/strong&gt; we will ensure that the reads in the resulting BAM dataset are properly set.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;hr color=&#34;red&#34;&gt;

&lt;h3 id=&#34;font-color-red-9888-reminder-font&#34;&gt;&lt;font color=&#34;red&#34;&gt;&amp;#9888; Reminder&lt;/font&gt;&lt;/h3&gt;

&lt;p&gt;We already learned about read groups. Read again &lt;a href=&#34;https://nekrut.github.io/BMMB554/BMMB554/post/topic7/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;hr color=&#34;red&#34;&gt;

&lt;h2 id=&#34;merging-bam-datasets&#34;&gt;Merging BAM datasets&lt;/h2&gt;

&lt;p&gt;Because we have set read groups, we can now merge the two BAM dataset into one. This is because read groups label each read as belonging to either &lt;em&gt;mother&lt;/em&gt; or &lt;em&gt;child&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;We can BAM dataset using &lt;strong&gt;NGS: Picard&lt;/strong&gt; &amp;#8594; &lt;strong&gt;MergeSAMFiles&lt;/strong&gt; tool:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_bam_merging.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Merging two BAM datasets into one. Note that two inputs are highlighted.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;removing-duplicates&#34;&gt;Removing duplicates&lt;/h2&gt;

&lt;p&gt;Recall from our &lt;a href=&#34;https://nekrut.github.io/BMMB554/BMMB554/post/topic7/&#34;&gt;earlier material&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Preparation of sequencing libraries (at least at the time of writing) for technologies such as Illumina (used in this example) involves PCR amplification. It is required to generate sufficient number of sequencing templates so that a reliable detection can be performed by base callers. Yet PCR has it&amp;rsquo;s biases, which are especially profound in cases of multitemplate PCR used for construction of sequencing libraries (Kanagawa et al. &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;amp;db=PubMed&amp;amp;dopt=Abstract&amp;amp;list_uids=16233530&#34;&gt;2003&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Duplicates can be identified based on their outer alignment coordinates or using sequence-based clustering. One of the common ways for identification of duplicate reads is the &lt;code&gt;MarkDuplicates&lt;/code&gt; utility from &lt;a href=&#34;https://broadinstitute.github.io/picard/command-line-overview.html&#34;&gt;Picard&lt;/a&gt; package. It is designed to identify both PCR and optical duplicates:&lt;/p&gt;

&lt;p&gt;Duplicates are identified as read pairs having identical 5&amp;rsquo; positions (coordinate and strand) for both reads in a mate pair (and optionally, matching unique molecular identifier reads; see BARCODE_TAG option). Optical, or more broadly Sequencing, duplicates are duplicates that appear clustered together spatially during sequencing and can arise from optical/imagine-processing artifacts or from bio-chemical processes during clonal amplification and sequencing; they are identified using the READ_NAME_REGEX and the OPTICAL_DUPLICATE_PIXEL_DISTANCE options. The tool&amp;rsquo;s main output is a new SAM or BAM file in which duplicates have been identified in the SAM flags field, or optionally removed (see REMOVE_DUPLICATE and REMOVE_SEQUENCING_DUPLICATES), and optionally marked with a duplicate type in the &amp;lsquo;DT&amp;rsquo; optional attribute. In addition, it also outputs a metrics file containing the numbers of READ_PAIRS_EXAMINED, UNMAPPED_READS, UNPAIRED_READS, UNPAIRED_READ DUPLICATES, READ_PAIR_DUPLICATES, and READ_PAIR_OPTICAL_DUPLICATES. Usage example: java -jar picard.jar MarkDuplicates I=input.bam \ O=marked_duplicates.bam M=marked_dup_metrics.txt.`&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let&amp;rsquo;s use &lt;strong&gt;NGS: Picard&lt;/strong&gt; &amp;#8594; &lt;strong&gt;MarkDuplicates&lt;/strong&gt; tool:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_dedup.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;De-duplicating the merged BAM dataset&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;MarkDuplicates&lt;/strong&gt; produces a BAM dataset with duplicates removed and also a metrics file. Let&amp;rsquo;s take a look at the metrics data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;raw_child-ds-	55	27551	55	50	1658	0	0.061026	219628
raw_mother-ds-	96	54972	96	90	4712	0	0.086459	302063
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where columns are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;LIBRARY (read group in our case)&lt;/li&gt;
&lt;li&gt;UNPAIRED_READS_EXAMINED&lt;/li&gt;
&lt;li&gt;READ_PAIRS_EXAMINED-&lt;/li&gt;
&lt;li&gt;UNMAPPED_READS&lt;/li&gt;
&lt;li&gt;UNPAIRED_READ_DUPLICATES&lt;/li&gt;
&lt;li&gt;READ_PAIR_DUPLICATES&lt;/li&gt;
&lt;li&gt;READ_PAIR_OPTICAL_DUPLICATES&lt;/li&gt;
&lt;li&gt;PERCENT_DUPLICATION&lt;/li&gt;
&lt;li&gt;ESTIMATED_LIBRARY_SIZE&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In other words the two datasets had ~6% and ~9% duplicates, respectively.&lt;/p&gt;

&lt;h2 id=&#34;left-aligning-indels&#34;&gt;Left-aligning indels&lt;/h2&gt;

&lt;p&gt;Left aligning of indels (a variant of re-aligning) is extremely important for obtaining accurate variant calls. This concept, while not difficult, requires some explanation. For illustrating how left-aligning works we expanded on an example provided by &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/31/13/2202.abstract&#34;&gt;Tan:2015&lt;/a&gt;. Suppose you have a reference sequence and a sequencing read:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Reference GGGCACACACAGGG
Read      GGGCACACAGGG
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you look carefully you will see that the read is simply missing a &lt;code&gt;CA&lt;/code&gt; repeat. But it is not apparent to a mapper, so some of possible alignments and corresponding variant calls include:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Alignment                 Variant Call

GGGCACACACAGGG            Ref: CAC
GGGCAC--ACAGGG            Alt: C

GGGCACACACAGGG            Ref: ACA
GGGCA--CACAGGG            Alt: A

GGGCACACACAGGG            Ref: GCA
GGG--CACACAGGG            Alt: G
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The last of these is &lt;em&gt;left-aligned&lt;/em&gt;. In this case gaps (dashes) as moved as far left as possible (for a formal definition of left-alignment and variant normalization see &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/31/13/2202.abstract&#34;&gt;Tan:2015&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s perform left alignment using &lt;strong&gt;NGS: Variant Analysis&lt;/strong&gt; &amp;#8594; &lt;strong&gt;BamLeftAlign&lt;/strong&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_left_align.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Left-aligning a de-duplicated BAM dataset&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;filtering-reads&#34;&gt;Filtering reads&lt;/h2&gt;

&lt;p&gt;Remember that we are trying to call variants in mitochondrial genome. Let focus only on the reads derived from the mitochondrial genome by filtering everything else out. For this we will use &lt;strong&gt;NGS: BamTools&lt;/strong&gt; &amp;#8594; &lt;strong&gt;Filter&lt;/strong&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_filtering.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Filtering reads. There are several important point to note here:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;mapQuality&lt;/strong&gt; is set to &amp;#8925; 20 Mapping quality reflects the probability that the read is placed &lt;em&gt;incorrectly&lt;/em&gt;. It uses &lt;a href=&#34;https://en.wikipedia.org/wiki/Phred_quality_scorescore&#34;&gt;phred scale&lt;/a&gt;. Thus 20 is &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;100&lt;/sub&gt; or 1% chance that the read is incorrectly mapped. By setting this parameter to &amp;#8925; 20 we will keep all reads that have 1% or less probability of being mapped incorrectly.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;isPaired&lt;/em&gt; will eliminate singleton (unpaired) reads (make sure &lt;strong&gt;Yes&lt;/strong&gt; is clicked on)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;isProperPair&lt;/em&gt; will only keep reads that map to the same chromosome and are properly placed (again, make sure &lt;strong&gt;Yes&lt;/strong&gt; is clicked)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;reference&lt;/em&gt; is set to &lt;em&gt;chrM&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;calling-non-diploid-variants-with-freebayes&#34;&gt;Calling non-diploid variants with FreeBayes&lt;/h1&gt;

&lt;p&gt;FreeBayes is widely used for calling variants in diploid systems. However, it can also be used for calling variants in pooled samples where the number of samples is not known. This is the exact scenario we have here: in our sample we have multiple mitochondrial (or bacterial or viral) genomes but we do not know exactly how many. Thus we will use the &lt;code&gt;--pooled-continuous&lt;/code&gt; option of FreeBayes to generate &lt;em&gt;frequency-based&lt;/em&gt; variant calls as well as some other options highlighted below (the tool is in &lt;strong&gt;NGS: Variant Analysis&lt;/strong&gt; &amp;#8594; &lt;strong&gt;FreeBayes&lt;/strong&gt;):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_freebayes_genome.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Set genome to &lt;code&gt;hg38&lt;/code&gt; (the latest version)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_freebayes_regions.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Set regions to &lt;code&gt;chrM&lt;/code&gt; from &lt;code&gt;1&lt;/code&gt; to &lt;code&gt;16000&lt;/code&gt;. This will simply save us time since we are only interested in mitochondrial variants anyway&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_freebayes_alloptions.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Choose &lt;code&gt;Complete list of all samples&lt;/code&gt; from &lt;strong&gt;Choose parameter selection level&lt;/strong&gt; drop down.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_freebayes_popmodel.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This is one of the most important parameter choices one needs to make when calling variants in non-diploid systems. Here set &lt;strong&gt;Set population model&lt;/strong&gt; to &lt;code&gt;Yes&lt;/code&gt; and then:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Set &lt;strong&gt;ploidy&lt;/strong&gt; to &lt;code&gt;1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Set &lt;strong&gt;Assume that samples result from pooled sequencing&lt;/strong&gt; to &lt;code&gt;Yes&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Set &lt;strong&gt;Output all alleles which pass input filters, regardless of genotyping outcome or model&lt;/strong&gt; to &lt;code&gt;Yes&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_freebayes_allelic_scope.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We will also set &lt;strong&gt;Allelic scope&lt;/strong&gt; to &lt;code&gt;Yes&lt;/code&gt; and restrict variant types to single nucleotide polymorphisms only by:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Keeping &lt;strong&gt;Ignore SNP alleles&lt;/strong&gt; and &lt;strong&gt;Ignore indels alleles&lt;/strong&gt; set to &lt;code&gt;No&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Setting &lt;strong&gt;Ignore MNPs&lt;/strong&gt; and &lt;strong&gt;Ignore complex events&lt;/strong&gt; to &lt;code&gt;Yes&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Mitochondria has a number of low complexity regions (mononucleotide repeats). Setting these parameters as described above will decrease noise from these regions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_freebayes_inputfilters.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Finally, let&amp;rsquo;s set &lt;strong&gt;Input filters&lt;/strong&gt; to &lt;code&gt;Yes&lt;/code&gt; and set:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Exclude alignments from analysis if they have a mapping quality less than&lt;/strong&gt; to &lt;code&gt;20&lt;/code&gt; (phred score of 20). This will make FreeBayes to only consider reliably aligned reads.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Exclude alleles from analysis if their supporting base quality less than&lt;/strong&gt; to &lt;code&gt;30&lt;/code&gt; (phred score of 30). This will make FreeBayes to only consider high quality bases.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;This will produce a &lt;a href=&#34;https://samtools.github.io/hts-specs/VCFv4.2.pdf&#34;&gt;VCF dataset&lt;/a&gt; shows below (you may need to scroll sideways to see it in full). It lists 30 sites of interest (everything starting with &lt;code&gt;#&lt;/code&gt; is a comment):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
Chrom	Pos	ID	Ref	Alt	Qual	Filter	Info	Format	data
##fileformat=VCFv4.1
##fileDate=20161108
##source=freeBayes v0.9.20
##reference=/galaxy/data/hg38/sam_index/hg38.fa
##phasing=none
##commandline=&amp;quot;freebayes --bam localbam_0.bam --fasta-reference /galaxy/data/hg38/sam_index/hg38.fa --vcf /galaxy-repl/main/files/017/782/dataset_17782376.dat --region chrM:1..16000&amp;quot;
##INFO=&amp;lt;ID=NS,Number=1,Type=Integer,Description=&amp;quot;Number of samples with data&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=DP,Number=1,Type=Integer,Description=&amp;quot;Total read depth at the locus&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=DPB,Number=1,Type=Float,Description=&amp;quot;Total read depth per bp at the locus; bases in reads overlapping / bases in haplotype&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=AC,Number=A,Type=Integer,Description=&amp;quot;Total number of alternate alleles in called genotypes&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=AN,Number=1,Type=Integer,Description=&amp;quot;Total number of alleles in called genotypes&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=AF,Number=A,Type=Float,Description=&amp;quot;Estimated allele frequency in the range (0,1]&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=RO,Number=1,Type=Integer,Description=&amp;quot;Reference allele observation count, with partial observations recorded fractionally&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=AO,Number=A,Type=Integer,Description=&amp;quot;Alternate allele observations, with partial observations recorded fractionally&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=PRO,Number=1,Type=Float,Description=&amp;quot;Reference allele observation count, with partial observations recorded fractionally&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=PAO,Number=A,Type=Float,Description=&amp;quot;Alternate allele observations, with partial observations recorded fractionally&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=QR,Number=1,Type=Integer,Description=&amp;quot;Reference allele quality sum in phred&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=QA,Number=A,Type=Integer,Description=&amp;quot;Alternate allele quality sum in phred&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=PQR,Number=1,Type=Float,Description=&amp;quot;Reference allele quality sum in phred for partial observations&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=PQA,Number=A,Type=Float,Description=&amp;quot;Alternate allele quality sum in phred for partial observations&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=SRF,Number=1,Type=Integer,Description=&amp;quot;Number of reference observations on the forward strand&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=SRR,Number=1,Type=Integer,Description=&amp;quot;Number of reference observations on the reverse strand&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=SAF,Number=A,Type=Integer,Description=&amp;quot;Number of alternate observations on the forward strand&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=SAR,Number=A,Type=Integer,Description=&amp;quot;Number of alternate observations on the reverse strand&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=SRP,Number=1,Type=Float,Description=&amp;quot;Strand balance probability for the reference allele: Phred-scaled upper-bounds estimate of the probability of observing the deviation between SRF and SRR given E(SRF/SRR) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=SAP,Number=A,Type=Float,Description=&amp;quot;Strand balance probability for the alternate allele: Phred-scaled upper-bounds estimate of the probability of observing the deviation between SAF and SAR given E(SAF/SAR) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=AB,Number=A,Type=Float,Description=&amp;quot;Allele balance at heterozygous sites: a number between 0 and 1 representing the ratio of reads showing the reference allele to all reads, considering only reads from individuals called as heterozygous&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=ABP,Number=A,Type=Float,Description=&amp;quot;Allele balance probability at heterozygous sites: Phred-scaled upper-bounds estimate of the probability of observing the deviation between ABR and ABA given E(ABR/ABA) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=RUN,Number=A,Type=Integer,Description=&amp;quot;Run length: the number of consecutive repeats of the alternate allele in the reference genome&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=RPP,Number=A,Type=Float,Description=&amp;quot;Read Placement Probability: Phred-scaled upper-bounds estimate of the probability of observing the deviation between RPL and RPR given E(RPL/RPR) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=RPPR,Number=1,Type=Float,Description=&amp;quot;Read Placement Probability for reference observations: Phred-scaled upper-bounds estimate of the probability of observing the deviation between RPL and RPR given E(RPL/RPR) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=RPL,Number=A,Type=Float,Description=&amp;quot;Reads Placed Left: number of reads supporting the alternate balanced to the left (5&#39;) of the alternate allele&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=RPR,Number=A,Type=Float,Description=&amp;quot;Reads Placed Right: number of reads supporting the alternate balanced to the right (3&#39;) of the alternate allele&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=EPP,Number=A,Type=Float,Description=&amp;quot;End Placement Probability: Phred-scaled upper-bounds estimate of the probability of observing the deviation between EL and ER given E(EL/ER) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=EPPR,Number=1,Type=Float,Description=&amp;quot;End Placement Probability for reference observations: Phred-scaled upper-bounds estimate of the probability of observing the deviation between EL and ER given E(EL/ER) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=DPRA,Number=A,Type=Float,Description=&amp;quot;Alternate allele depth ratio. Ratio between depth in samples with each called alternate allele and those without.&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=ODDS,Number=1,Type=Float,Description=&amp;quot;The log odds ratio of the best genotype combination to the second-best.&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=GTI,Number=1,Type=Integer,Description=&amp;quot;Number of genotyping iterations required to reach convergence or bailout.&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=TYPE,Number=A,Type=String,Description=&amp;quot;The type of allele, either snp, mnp, ins, del, or complex.&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=CIGAR,Number=A,Type=String,Description=&amp;quot;The extended CIGAR representation of each alternate allele, with the exception that &#39;=&#39; is replaced by &#39;M&#39; to ease VCF parsing. Note that INDEL alleles do not have the first matched base (which is provided by default, per the spec) referred to by the CIGAR.&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=NUMALT,Number=1,Type=Integer,Description=&amp;quot;Number of unique non-reference alleles in called genotypes at this position.&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=MEANALT,Number=A,Type=Float,Description=&amp;quot;Mean number of unique non-reference allele observations per sample with the corresponding alternate alleles.&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=LEN,Number=A,Type=Integer,Description=&amp;quot;allele length&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=MQM,Number=A,Type=Float,Description=&amp;quot;Mean mapping quality of observed alternate alleles&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=MQMR,Number=1,Type=Float,Description=&amp;quot;Mean mapping quality of observed reference alleles&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=PAIRED,Number=A,Type=Float,Description=&amp;quot;Proportion of observed alternate alleles which are supported by properly paired read fragments&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=PAIREDR,Number=1,Type=Float,Description=&amp;quot;Proportion of observed reference alleles which are supported by properly paired read fragments&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=technology.ILLUMINA,Number=A,Type=Float,Description=&amp;quot;Fraction of observations supporting the alternate observed in reads from ILLUMINA&amp;quot;&amp;gt;
##FORMAT=&amp;lt;ID=GT,Number=1,Type=String,Description=&amp;quot;Genotype&amp;quot;&amp;gt;
##FORMAT=&amp;lt;ID=GQ,Number=1,Type=Float,Description=&amp;quot;Genotype Quality, the Phred-scaled marginal (or unconditional) probability of the called genotype&amp;quot;&amp;gt;
##FORMAT=&amp;lt;ID=GL,Number=G,Type=Float,Description=&amp;quot;Genotype Likelihood, log10-scaled likelihoods of the data given the called genotype for each possible genotype generated from the reference and alternate alleles given the sample ploidy&amp;quot;&amp;gt;
##FORMAT=&amp;lt;ID=DP,Number=1,Type=Integer,Description=&amp;quot;Read Depth&amp;quot;&amp;gt;
##FORMAT=&amp;lt;ID=RO,Number=1,Type=Integer,Description=&amp;quot;Reference allele observation count&amp;quot;&amp;gt;
##FORMAT=&amp;lt;ID=QR,Number=1,Type=Integer,Description=&amp;quot;Sum of quality of the reference observations&amp;quot;&amp;gt;
##FORMAT=&amp;lt;ID=AO,Number=A,Type=Integer,Description=&amp;quot;Alternate allele observation count&amp;quot;&amp;gt;
##FORMAT=&amp;lt;ID=QA,Number=A,Type=Integer,Description=&amp;quot;Sum of quality of the alternate observations&amp;quot;&amp;gt;
#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	raw_child-ds-	raw_mother-ds-
chrM	73	.	A	G	33368.5	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1095;CIGAR=1X;DP=1098;DPB=1098;DPRA=0;EPP=107.005;EPPR=5.18177;GTI=0;LEN=1;MEANALT=1.5;MQM=55.7744;MQMR=60;NS=2;NUMALT=1;ODDS=509.945;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=37602;QR=37;RO=1;RPL=359;RPP=284.863;RPPR=5.18177;RPR=736;RUN=1;SAF=507;SAP=16.0213;SAR=588;SRF=0;SRP=5.18177;SRR=1;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:273:0:0:273:9187:-827.167,-82.1812,0	1/1:825:1:37:822:28415:-2554.14,-241.429,0
chrM	263	.	A	G	13774.9	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=508;CIGAR=1X;DP=524;DPB=524;DPRA=0;EPP=39.1901;EPPR=0;GTI=0;LEN=1;MEANALT=2.5;MQM=60;MQMR=0;NS=2;NUMALT=1;ODDS=255.818;PAIRED=1;PAIREDR=0;PAO=0;PQA=0;PQR=0;PRO=0;QA=15693;QR=0;RO=0;RPL=373;RPP=245.138;RPPR=0;RPR=135;RUN=1;SAF=219;SAP=23.9556;SAR=289;SRF=0;SRP=0;SRR=0;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:154:0:0:150:4661:-419.661,-45.1545,0	1/1:370:0:0:358:11032:-993.047,-107.769,0
chrM	309	.	CT	CCTC,CC	4399.1	.	AB=0.56535,0.285714;ABP=15.2141,134.229;AC=2,2;AF=0.5,0.5;AN=4;AO=186,94;CIGAR=1M2I1X,1M1X;DP=329;DPB=555.5;DPRA=0,0;EPP=23.6043,97.6311;EPPR=31.9633;GTI=0;LEN=3,1;MEANALT=6,6;MQM=60,59.8085;MQMR=60;NS=2;NUMALT=2;ODDS=89.3381;PAIRED=1,1;PAIREDR=1;PAO=13.3333,13.3333;PQA=339,339;PQR=290;PRO=11.3333;QA=4084,2577;QR=686;RO=30;RPL=114,78;RPP=23.6043,91.8097;RPPR=38.0434;RPR=72,16;RUN=1,1;SAF=0,63;SAP=406.904,26.6655;SAR=186,31;SRF=21;SRP=13.4334;SRR=9;TYPE=complex,snp;technology.ILLUMINA=1,1	GT:DP:RO:QR:AO:QA:GL	1/2:93:6:123:59,23:1308,638:-159.543,-53.5005,-52.9104,-105.161,0,-113.176	1/2:236:24:563:127,71:2776,1939:-368.987,-136.961,-169.835,-200.763,0,-245.13
chrM	513	.	GCACACACACAC	GCACACACACACAC	3522.72	.	AB=0.647399;ABP=35.6577;AC=3;AF=0.75;AN=4;AO=156;CIGAR=1M2I11M;DP=231;DPB=321.083;DPRA=0;EPP=75.17;EPPR=5.48477;GTI=1;LEN=2;MEANALT=13.5;MQM=60;MQMR=60;NS=2;NUMALT=1;ODDS=3.87694;PAIRED=1;PAIREDR=1;PAO=46.5;PQA=1383.5;PQR=1383.5;PRO=46.5;QA=4585;QR=1403;RO=43;RPL=39;RPP=87.6977;RPPR=3.0608;RPR=117;RUN=1;SAF=111;SAP=63.6445;SAR=45;SRF=26;SRP=7.10075;SRR=17;TYPE=ins;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:58:7:225:44:1251:-105.403,0,-13.0389	0/1:173:36:1178:112:3334:-290.141,0,-96.0932
chrM	750	.	A	G	51447.4	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1722;CIGAR=1X;DP=1736;DPB=1736;DPRA=0;EPP=3.03048;EPPR=20.3821;GTI=0;LEN=1;MEANALT=3;MQM=59.8868;MQMR=60;NS=2;NUMALT=1;ODDS=753.623;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=57871;QR=122;RO=8;RPL=720;RPP=103.291;RPPR=12.7819;RPR=1002;RUN=1;SAF=1151;SAP=427.217;SAR=571;SRF=1;SRP=12.7819;SRR=7;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:436:4:53:429:13615:-1220.76,-116.422,0	1/1:1300:4:69:1293:44256:-3977.02,-373.134,0
chrM	1438	.	A	G	79172.1	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=2474;CIGAR=1X;DP=2480;DPB=2480;DPRA=0;EPP=7.56039;EPPR=3.44459;GTI=0;LEN=1;MEANALT=1.5;MQM=59.8319;MQMR=58;NS=2;NUMALT=1;ODDS=1085.01;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=88621;QR=102;RO=5;RPL=1546;RPP=338.232;RPPR=3.44459;RPR=928;RUN=1;SAF=1055;SAP=119.304;SAR=1419;SRF=3;SRP=3.44459;SRR=2;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:551:1:16:550:19482:-1752.13,-161.526,0	1/1:1929:4:86:1924:69139:-6214.93,-560.827,0
chrM	2487	.	A	C	4432.57	.	AB=0.278634;ABP=775.959;AC=1;AF=0.25;AN=4;AO=621;CIGAR=1X;DP=2340;DPB=2340;DPRA=0;EPP=15.1824;EPPR=99.2128;GTI=1;LEN=1;MEANALT=2.5;MQM=59.3285;MQMR=59.9115;NS=2;NUMALT=1;ODDS=63.7254;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=9402;QR=56614;RO=1707;RPL=281;RPP=15.1824;RPPR=127.637;RPR=340;RUN=1;SAF=0;SAP=1351.49;SAR=621;SRF=1352;SRP=1267.49;SRR=355;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/0:524:405:13274:115:1754:-119.206,0,-1156.18	0/1:1816:1302:43340:506:7648:-607.816,0,-3820.28
chrM	2706	.	A	G	49482.2	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1889;CIGAR=1X;DP=1969;DPB=1969;DPRA=0;EPP=11.3157;EPPR=6.95112;GTI=0;LEN=1;MEANALT=2.5;MQM=59.9645;MQMR=59.5926;NS=2;NUMALT=1;ODDS=759.158;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=55923;QR=722;RO=27;RPL=810;RPP=86.1918;RPPR=5.02092;RPR=1079;RUN=1;SAF=802;SAP=96.3813;SAR=1087;SRF=18;SRP=9.52472;SRR=9;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:408:5:99:391:11529:-1028.82,-99.3894,0	1/1:1561:22:623:1498:44394:-3939.48,-352.569,0
chrM	3197	.	T	C	135699	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=4208;CIGAR=1X;DP=4241;DPB=4241;DPRA=0;EPP=168.325;EPPR=3.13803;GTI=0;LEN=1;MEANALT=3;MQM=59.9943;MQMR=60;NS=2;NUMALT=1;ODDS=2145.76;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=152221;QR=558;RO=17;RPL=2378;RPP=157.977;RPPR=6.20364;RPR=1830;RUN=1;SAF=1641;SAP=445.497;SAR=2567;SRF=8;SRP=3.13803;SRR=9;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:1499:6:179:1486:53236:-4775.26,-416.785,0	1/1:2742:11:379:2722:98985:-8874.65,-758.304,0
chrM	3243	.	A	G	46067	.	AB=0.612338;ABP=290.859;AC=2;AF=0.5;AN=4;AO=1608;CIGAR=1X;DP=2626;DPB=2626;DPRA=0;EPP=31.0126;EPPR=64.3549;GTI=0;LEN=1;MEANALT=2;MQM=59.9627;MQMR=59.815;NS=2;NUMALT=1;ODDS=1288.98;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=53165;QR=35336;RO=1011;RPL=974;RPP=159.119;RPPR=763.402;RPR=634;RUN=1;SAF=558;SAP=329.898;SAR=1050;SRF=383;SRP=131.935;SRR=628;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/1:1068:221:7574:841:27395:-2380.4,0,-596.524	0/1:1558:790:27762:767:25770:-2317.69,0,-2496.98
chrM	3483	.	G	C	685.467	.	AB=0.254386;ABP=182.214;AC=1;AF=0.25;AN=4;AO=127;CIGAR=1X;DP=550;DPB=550;DPRA=0;EPP=37.6342;EPPR=22.2028;GTI=1;LEN=1;MEANALT=1.5;MQM=59.4646;MQMR=59.8504;NS=2;NUMALT=1;ODDS=25.0865;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=2032;QR=13200;RO=421;RPL=87;RPP=40.7802;RPPR=245.89;RPR=40;RUN=1;SAF=1;SAP=270.17;SAR=126;SRF=321;SRP=254.927;SRR=100;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/0:208:166:5264:40:608:-35.5966,0,-454.8	0/1:342:255:7936:87:1424:-108.297,0,-694.524
chrM	3488	.	T	A	682.097	.	AB=0.264706;ABP=166.509;AC=1;AF=0.25;AN=4;AO=130;CIGAR=1X;DP=546;DPB=546;DPRA=0;EPP=44.7694;EPPR=34.7681;GTI=1;LEN=1;MEANALT=1;MQM=59.4231;MQMR=59.7139;NS=2;NUMALT=1;ODDS=17.5994;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=2069;QR=13578;RO=416;RPL=90;RPP=44.7694;RPPR=211.806;RPR=40;RUN=1;SAF=0;SAP=285.302;SAR=130;SRF=315;SRP=242.06;SRR=101;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/0:206:166:5535:40:650:-39.5324,0,-479.353	0/1:340:250:8043:90:1419:-109.544,0,-705.868
chrM	3511	.	A	C	434.289	.	AB=0.260394;ABP=230.901;AC=1;AF=0.25;AN=4;AO=185;CIGAR=1X;DP=752;DPB=752;DPRA=0;EPP=322.569;EPPR=29.1769;GTI=1;LEN=1;MEANALT=3;MQM=59.7838;MQMR=59.7348;NS=2;NUMALT=1;ODDS=57.1305;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=2698;QR=16673;RO=558;RPL=11;RPP=314.869;RPPR=115.475;RPR=174;RUN=1;SAF=1;SAP=396.094;SAR=184;SRF=292;SRP=5.64097;SRR=266;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/0:295:226:6735:66:923:-61.5611,0,-584.793	0/1:457:332:9938:119:1775:-135.644,0,-870.462
chrM	4769	.	A	G	54711.1	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1746;CIGAR=1X;DP=1752;DPB=1752;DPRA=0;EPP=85.7949;EPPR=5.18177;GTI=0;LEN=1;MEANALT=2.5;MQM=51.2801;MQMR=58;NS=2;NUMALT=1;ODDS=911.774;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=61628;QR=15;RO=1;RPL=549;RPP=525.238;RPPR=5.18177;RPR=1197;RUN=1;SAF=1003;SAP=87.0833;SAR=743;SRF=1;SRP=5.18177;SRR=0;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:604:1:15:601:20766:-1867.77,-177.095,0	1/1:1148:0:0:1145:40862:-3677.79,-344.679,0
chrM	5539	.	A	G	11837	.	AB=0.479167;ABP=6.26751;AC=2;AF=0.5;AN=4;AO=414;CIGAR=1X;DP=864;DPB=864;DPRA=0;EPP=192.358;EPPR=179.441;GTI=0;LEN=1;MEANALT=1.5;MQM=54.1957;MQMR=53.5924;NS=2;NUMALT=1;ODDS=622.768;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=14380;QR=15965;RO=449;RPL=85;RPP=315.283;RPPR=358.189;RPR=329;RUN=1;SAF=309;SAP=221.29;SAR=105;SRF=337;SRP=247.845;SRR=112;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/1:338:249:8721:89:3010:-252.807,0,-766.809	0/1:526:200:7244:325:11370:-1015.56,0,-644.23
chrM	7028	.	C	T	76141.7	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=2473;CIGAR=1X;DP=2499;DPB=2499;DPRA=0;EPP=3.74876;EPPR=34.9902;GTI=0;LEN=1;MEANALT=2.5;MQM=55.905;MQMR=57.6364;NS=2;NUMALT=1;ODDS=1210.59;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=85103;QR=439;RO=22;RPL=1260;RPP=4.94996;RPPR=4.58955;RPR=1213;RUN=1;SAF=1102;SAP=66.5485;SAR=1371;SRF=9;SRP=4.58955;SRR=13;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:827:6:107:820:28371:-2543.94,-224.334,0	1/1:1672:16:332:1653:56732:-5076.14,-434.286,0
chrM	7269	.	G	A	62196.6	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1937;CIGAR=1X;DP=1947;DPB=1947;DPRA=0;EPP=54.8308;EPPR=5.18177;GTI=0;LEN=1;MEANALT=3;MQM=58.2685;MQMR=60;NS=2;NUMALT=1;ODDS=1033.49;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=69240;QR=16;RO=1;RPL=1011;RPP=11.1099;RPPR=5.18177;RPR=926;RUN=1;SAF=933;SAP=8.66151;SAR=1004;SRF=0;SRP=5.18177;SRR=1;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:704:1:16:698:24364:-2191.49,-206.139,0	1/1:1243:0:0:1239:44876:-4039.06,-372.976,0
chrM	8557	.	G	C	2590.97	.	AB=0.267066;ABP=790.051;AC=2;AF=0.5;AN=4;AO=446;CIGAR=1X;DP=1670;DPB=1670;DPRA=0;EPP=44.2196;EPPR=97.7883;GTI=0;LEN=1;MEANALT=3;MQM=57.6951;MQMR=59.5256;NS=2;NUMALT=1;ODDS=125.064;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=6303;QR=38747;RO=1212;RPL=177;RPP=44.2196;RPPR=385.426;RPR=269;RUN=1;SAF=2;SAP=954.193;SAR=444;SRF=906;SRP=648.002;SRR=306;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/1:724:538:17225:181:2490:-182.373,0,-1508.7	0/1:946:674:21522:265:3813:-301.57,0,-1895.55
chrM	8860	.	A	G	55525	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1846;CIGAR=1X;DP=1861;DPB=1861;DPRA=0;EPP=5.72052;EPPR=6.91895;GTI=0;LEN=1;MEANALT=3;MQM=47.1728;MQMR=58.6;NS=2;NUMALT=1;ODDS=1039.99;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=61929;QR=160;RO=5;RPL=984;RPP=20.5185;RPPR=6.91895;RPR=862;RUN=1;SAF=987;SAP=22.283;SAR=859;SRF=2;SRP=3.44459;SRR=3;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:729:0:0:726:24114:-2170.46,-218.548,0	1/1:1132:5:160:1120:37815:-3389.07,-311.012,0
chrM	9477	.	G	A	34109.5	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1099;CIGAR=1X;DP=1104;DPB=1104;DPRA=0;EPP=9.42988;EPPR=3.0103;GTI=0;LEN=1;MEANALT=2;MQM=59.3794;MQMR=60;NS=2;NUMALT=1;ODDS=565.855;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=38032;QR=67;RO=2;RPL=598;RPP=21.6012;RPPR=7.35324;RPR=501;RUN=1;SAF=542;SAP=3.45487;SAR=557;SRF=1;SRP=3.0103;SRR=1;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:401:2:67:398:13308:-1191.76,-109.337,0	1/1:703:0:0:701:24724:-2225.39,-211.022,0
chrM	9548	.	G	A	26846.1	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=942;CIGAR=1X;DP=970;DPB=970;DPRA=0;EPP=3.04718;EPPR=3.73412;GTI=0;LEN=1;MEANALT=3;MQM=59.6921;MQMR=60;NS=2;NUMALT=1;ODDS=502.835;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=29956;QR=66;RO=3;RPL=524;RPP=28.9112;RPPR=3.73412;RPR=418;RUN=1;SAF=487;SAP=5.3708;SAR=455;SRF=3;SRP=9.52472;SRR=0;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:364:1:38:350:10822:-970.712,-99.6786,0	1/1:606:2:28:592:19134:-1719.73,-171.045,0
chrM	11467	.	A	G	164822	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=5200;CIGAR=1X;DP=5225;DPB=5225;DPRA=0;EPP=350.339;EPPR=4.78696;GTI=0;LEN=1;MEANALT=2.5;MQM=59.9342;MQMR=53.6364;NS=2;NUMALT=1;ODDS=2859.91;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=187277;QR=283;RO=11;RPL=3887;RPP=2769.75;RPPR=3.20771;RPR=1313;RUN=1;SAF=2257;SAP=199.527;SAR=2943;SRF=6;SRP=3.20771;SRR=5;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:2016:2:46:2008:71984:-6474.61,-594.606,0	1/1:3209:9:237:3192:115293:-10355.2,-916.222,0
chrM	11719	.	G	A	95624.7	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=3302;CIGAR=1X;DP=3356;DPB=3356;DPRA=0;EPP=179.466;EPPR=18.4661;GTI=0;LEN=1;MEANALT=2;MQM=59.5924;MQMR=58.2353;NS=2;NUMALT=1;ODDS=1506.69;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=106982;QR=483;RO=17;RPL=1766;RPP=37.7986;RPPR=6.20364;RPR=1536;RUN=1;SAF=1728;SAP=18.6065;SAR=1574;SRF=3;SRP=18.4661;SRR=14;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:911:4:122:891:28560:-2559.58,-247.982,0	1/1:2445:13:361:2411:78422:-7025.63,-662.959,0
chrM	12308	.	A	G	67204.7	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=2144;CIGAR=1X;DP=2161;DPB=2161;DPRA=0;EPP=8.55647;EPPR=3.87889;GTI=0;LEN=1;MEANALT=2;MQM=59.9664;MQMR=59.7;NS=2;NUMALT=1;ODDS=949.477;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=75192;QR=257;RO=10;RPL=1284;RPP=185.09;RPPR=3.87889;RPR=860;RUN=1;SAF=1005;SAP=21.1964;SAR=1139;SRF=4;SRP=3.87889;SRR=6;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:635:7:216:628:21603:-1924.87,-155.503,0	1/1:1526:3:41:1516:53589:-4819.52,-444.815,0
chrM	12372	.	G	A	62064	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1984;CIGAR=1X;DP=1992;DPB=1992;DPRA=0;EPP=10.3697;EPPR=4.45795;GTI=0;LEN=1;MEANALT=2;MQM=59.9919;MQMR=60;NS=2;NUMALT=1;ODDS=933.299;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=69281;QR=192;RO=6;RPL=861;RPP=78.1406;RPPR=4.45795;RPR=1123;RUN=1;SAF=1010;SAP=4.42876;SAR=974;SRF=4;SRP=4.45795;SRR=2;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:634:5:155:628:21590:-1929.21,-164.556,0	1/1:1358:1:37:1356:47691:-4288.95,-401.925,0
chrM	13617	.	T	C	28593.6	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=901;CIGAR=1X;DP=906;DPB=906;DPRA=0;EPP=251.346;EPPR=3.73412;GTI=0;LEN=1;MEANALT=2;MQM=59.9034;MQMR=60;NS=2;NUMALT=1;ODDS=462.343;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=32868;QR=92;RO=3;RPL=674;RPP=484.564;RPPR=9.52472;RPR=227;RUN=1;SAF=339;SAP=122.861;SAR=562;SRF=2;SRP=3.73412;SRR=1;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:303:1:14:301:10938:-983.358,-87.1961,0	1/1:603:2:78:600:21930:-1966.72,-168.809,0
chrM	14766	.	C	T	60668.6	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=2022;CIGAR=1X;DP=2039;DPB=2039;DPRA=0;EPP=13.3243;EPPR=19.0002;GTI=0;LEN=1;MEANALT=2.5;MQM=59.9782;MQMR=60;NS=2;NUMALT=1;ODDS=954.02;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=67719;QR=140;RO=11;RPL=989;RPP=5.08941;RPPR=12.6832;RPR=1033;RUN=1;SAF=1199;SAP=154.837;SAR=823;SRF=1;SRP=19.0002;SRR=10;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:637:6:78:628:20191:-1810.35,-169.906,0	1/1:1402:5:62:1394:47528:-4272.15,-401.924,0
chrM	14793	.	A	G	58080	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1967;CIGAR=1X;DP=1998;DPB=1998;DPRA=0;EPP=8.57532;EPPR=5.80219;GTI=0;LEN=1;MEANALT=3;MQM=59.9736;MQMR=59.2857;NS=2;NUMALT=1;ODDS=930.516;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=64876;QR=104;RO=7;RPL=1133;RPP=101.705;RPPR=3.32051;RPR=834;RUN=1;SAF=1124;SAP=90.1794;SAR=843;SRF=1;SRP=10.7656;SRR=6;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:600:4:62:589:19341:-1735.29,-163.219,0	1/1:1398:3:42:1378:45535:-4094.54,-403.304,0
chrM	15301	.	G	A	76440.4	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=2590;CIGAR=1X;DP=2644;DPB=2644;DPRA=0;EPP=3.76487;EPPR=7.94546;GTI=0;LEN=1;MEANALT=3;MQM=60;MQMR=60;NS=2;NUMALT=1;ODDS=1170.15;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=85385;QR=292;RO=11;RPL=1134;RPP=89.9396;RPPR=4.78696;RPR=1456;RUN=1;SAF=1194;SAP=37.2206;SAR=1396;SRF=3;SRP=7.94546;SRR=8;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:726:5:116:709:23434:-2098.78,-192.286,0	1/1:1918:6:176:1881:61951:-5559.91,-535.386,0
chrM	15326	.	A	G	79542.1	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=2574;CIGAR=1X;DP=2586;DPB=2586;DPRA=0;EPP=3.76956;EPPR=5.18177;GTI=0;LEN=1;MEANALT=3;MQM=60;MQMR=60;NS=2;NUMALT=1;ODDS=1207.35;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=88636;QR=86;RO=4;RPL=1116;RPP=101.683;RPPR=5.18177;RPR=1458;RUN=1;SAF=1198;SAP=29.7395;SAR=1376;SRF=0;SRP=11.6962;SRR=4;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:715:2:50:710:24322:-2184.63,-204.389,0	1/1:1871:2:36:1864:64314:-5785.22,-552.228,0

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;filtering-vcf-data&#34;&gt;Filtering VCF data&lt;/h2&gt;

&lt;p&gt;Even though we selected somewhat stringent input parameters (restricting base quality to a minimum of 30 and mapping quality to a minimum of 20) there is still a lot of just in our data. &lt;a href=&#34;https://github.com/ekg&#34;&gt;Erik Garrison&lt;/a&gt; has a beautiful illustration of various biases potentially affecting called variants (and making a locus sequence-able):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_biases.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here you can see that in an ideal case (indicated with a green star) a variant is evenly represent by different areas of sequencing reads (cycle and placement biases) and is balanced across the two strands (strand bias). Allele imbalance is not applicable in our case as it reflects significant deviation from the diploid (&lt;sup&gt;50&lt;/sup&gt;&amp;frasl;&lt;sub&gt;50&lt;/sub&gt;) expectation (see &lt;a href=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/freebayes.pdf&#34;&gt;here&lt;/a&gt; for more details).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A robust tool set for processing VCF data is provided by &lt;a href=&#34;https://github.com/vcflib/vcflib&#34;&gt;vcflib&lt;/a&gt; developed by Erik Garrison, the author of FreeBayes. One way to filter VCF is using &lt;code&gt;INFO&lt;/code&gt; fields of the VCF dataset. If you look at the VCF dataset shown above you will see all comment lines beginning with &lt;code&gt;##INFO&lt;/code&gt;.  These are &lt;code&gt;INFO&lt;/code&gt; fields. Each VCF record contains a list of &lt;code&gt;INFO&lt;/code&gt; tags describing a wide range of properties for each VCF record. You will see that FreeBayes and NVC differ significantly in the number and types of &lt;code&gt;INFO&lt;/code&gt; fields each of these caller generates. This why the two require different filtering strategies.&lt;/p&gt;

&lt;p&gt;Among numerous types of data generated by FreeBayes let&amp;rsquo;s consider the following variant properties:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;##INFO=&amp;lt;ID=DP,Number=1,Type=Integer,Description=&amp;quot;Total read depth at the locus&amp;quot;&amp;gt;&lt;/code&gt; This is simply the number of reads covering a given site.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;##INFO=&amp;lt;ID=SRP,Number=1,Type=Float,Description=&amp;quot;Strand balance probability for the reference allele: Phred-scaled upper-bounds estimate of the probability of observing the deviation between SRF and SRR given E(SRF/SRR) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;&lt;/code&gt; The higher this quantity the better the site as it diminishes the chances of the sites having significant strand bias.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;##INFO=&amp;lt;ID=SAP,Number=A,Type=Float,Description=&amp;quot;Strand balance probability for the alternate allele: Phred-scaled upper-bounds estimate of the probability of observing the deviation between SAF and SAR given E(SAF/SAR) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;&lt;/code&gt; The higher this quantity the better the site as it diminishes the chances of the sites having significant strand bias  (also see &lt;a href=&#34;https://groups.google.com/forum/#!topic/freebayes/fX4TOAqXJrA&#34;&gt;here&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;##INFO=&amp;lt;ID=EPP,Number=A,Type=Float,Description=&amp;quot;End Placement Probability: Phred-scaled upper-bounds estimate of the probability of observing the deviation between EL and ER given E(EL/ER) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;&lt;/code&gt; The higher this number the lower the chance of having significant placement bias.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;QUAL&lt;/code&gt; - phred scaled variant quality.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To perform filtering we will use &lt;strong&gt;NGS: VCF Manipulation&lt;/strong&gt; &amp;#8594; &lt;strong&gt;VCFfilter&lt;/strong&gt;):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_vcffilter.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Filtering FreeBayes VCF for strand bias (&lt;code&gt;SPR&lt;/code&gt; and &lt;code&gt;SAP&lt;/code&gt;), placement bias (&lt;code&gt;EPP&lt;/code&gt;), variant quality (&lt;code&gt;QUAL&lt;/code&gt;), and depth of coverage (&lt;code&gt;DP&lt;/code&gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The resulting VCF only contains five variants (most comments fields are omitted here):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	raw_child-ds-	raw_mother-ds-
chrM	3243	.	A	G	46067	.	AB=0.612338;ABP=290.859;AC=2;AF=0.5;AN=4;AO=1608;CIGAR=1X;DP=2626;DPB=2626;DPRA=0;EPP=31.0126;EPPR=64.3549;GTI=0;LEN=1;MEANALT=2;MQM=59.9627;MQMR=59.815;NS=2;NUMALT=1;ODDS=1288.98;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=53165;QR=35336;RO=1011;RPL=974;RPP=159.119;RPPR=763.402;RPR=634;RUN=1;SAF=558;SAP=329.898;SAR=1050;SRF=383;SRP=131.935;SRR=628;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/1:1068:221:7574:841:27395:-2380.4,0,-596.524	0/1:1558:790:27762:767:25770:-2317.69,0,-2496.98
chrM	3483	.	G	C	685.467	.	AB=0.254386;ABP=182.214;AC=1;AF=0.25;AN=4;AO=127;CIGAR=1X;DP=550;DPB=550;DPRA=0;EPP=37.6342;EPPR=22.2028;GTI=1;LEN=1;MEANALT=1.5;MQM=59.4646;MQMR=59.8504;NS=2;NUMALT=1;ODDS=25.0865;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=2032;QR=13200;RO=421;RPL=87;RPP=40.7802;RPPR=245.89;RPR=40;RUN=1;SAF=1;SAP=270.17;SAR=126;SRF=321;SRP=254.927;SRR=100;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/0:208:166:5264:40:608:-35.5966,0,-454.8	0/1:342:255:7936:87:1424:-108.297,0,-694.524
chrM	3488	.	T	A	682.097	.	AB=0.264706;ABP=166.509;AC=1;AF=0.25;AN=4;AO=130;CIGAR=1X;DP=546;DPB=546;DPRA=0;EPP=44.7694;EPPR=34.7681;GTI=1;LEN=1;MEANALT=1;MQM=59.4231;MQMR=59.7139;NS=2;NUMALT=1;ODDS=17.5994;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=2069;QR=13578;RO=416;RPL=90;RPP=44.7694;RPPR=211.806;RPR=40;RUN=1;SAF=0;SAP=285.302;SAR=130;SRF=315;SRP=242.06;SRR=101;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/0:206:166:5535:40:650:-39.5324,0,-479.353	0/1:340:250:8043:90:1419:-109.544,0,-705.868
chrM	5539	.	A	G	11837	.	AB=0.479167;ABP=6.26751;AC=2;AF=0.5;AN=4;AO=414;CIGAR=1X;DP=864;DPB=864;DPRA=0;EPP=192.358;EPPR=179.441;GTI=0;LEN=1;MEANALT=1.5;MQM=54.1957;MQMR=53.5924;NS=2;NUMALT=1;ODDS=622.768;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=14380;QR=15965;RO=449;RPL=85;RPP=315.283;RPPR=358.189;RPR=329;RUN=1;SAF=309;SAP=221.29;SAR=105;SRF=337;SRP=247.845;SRR=112;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/1:338:249:8721:89:3010:-252.807,0,-766.809	0/1:526:200:7244:325:11370:-1015.56,0,-644.23
chrM	8557	.	G	C	2590.97	.	AB=0.267066;ABP=790.051;AC=2;AF=0.5;AN=4;AO=446;CIGAR=1X;DP=1670;DPB=1670;DPRA=0;EPP=44.2196;EPPR=97.7883;GTI=0;LEN=1;MEANALT=3;MQM=57.6951;MQMR=59.5256;NS=2;NUMALT=1;ODDS=125.064;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=6303;QR=38747;RO=1212;RPL=177;RPP=44.2196;RPPR=385.426;RPR=269;RUN=1;SAF=2;SAP=954.193;SAR=444;SRF=906;SRP=648.002;SRR=306;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/1:724:538:17225:181:2490:-182.373,0,-1508.7	0/1:946:674:21522:265:3813:-301.57,0,-1895.55
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;looking-at-the-data&#34;&gt;Looking at the data&lt;/h2&gt;

&lt;p&gt;For visalizaning VCFs Galaxy relies on the two external tools.  The first is called &lt;a href=&#34;http://vcf.iobio.io/&#34;&gt;VCF.IOBIO&lt;/a&gt; and is developed by &lt;a href=&#34;http://marthlab.org/&#34;&gt;Gabor Marth&amp;rsquo;s group&lt;/a&gt; at the University of Utah. The second is called &lt;a href=&#34;http://software.broadinstitute.org/software/igv/&#34;&gt;IGV&lt;/a&gt; developed by Broad Institute.&lt;/p&gt;

&lt;h3 id=&#34;vcf-iobio&#34;&gt;VCF.IOBIO&lt;/h3&gt;

&lt;p&gt;VCF.IOBIO can be invoked by expanding a VCF dataset in Galaxy&amp;rsquo;s history by clicking on it:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_vcf_dataset_collapsed.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Clicking on the dataset above will expand it as shown below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_vcf_dataset_expanded.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;At the bottom there is a link &amp;ldquo;display at vcf.iobio&amp;rdquo;
Clicking on this link will start indexing of VCF datasets, which is required to display them. After indexing VCF.IOBIO will open:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_vcfiobio.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Of course there are not that many variants to look at in this example. Nevertheless there are helpful statistics such as Transition/Transversion (Ts/Tn) ratio.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;igv&#34;&gt;IGV&lt;/h3&gt;

&lt;p&gt;Similarly to VCF.BIOIO expanding a history item representing a VCF dataset will reveal an IGV link:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_vcf_dataset_expanded.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;At the bottom there is a link &amp;ldquo;display at IGV: local Human hg38&amp;rdquo;
The difference between &amp;ldquo;local&amp;rdquo; and &amp;ldquo;Human hg38&amp;rdquo; links is explained in the following video:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/123414437&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;Visualizing our FreeBayes dataset will produce this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_igv.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here we focus on one particular variant at position 3,243 for reasons that will become apparent in the next section.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;digging-into-the-data&#34;&gt;Digging into the data&lt;/h2&gt;

&lt;p&gt;Visualizing VCF dataset may be a good way to get an overall idea of the data, but it does not tell a lot of details. For example, above we have visualized site 3,243 using IGV. It is interesting but we need to find out more. One thing we can do is to convert VCF dataset into a tab-delimited representation and play a bit more with it.&lt;/p&gt;

&lt;p&gt;Using &lt;strong&gt;NGS: VCF Manipulation&lt;/strong&gt; &amp;#8594; &lt;strong&gt;VCFtoTab-delimited&lt;/strong&gt; on the filtered VCF dataset:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_vcfToTab.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Make sure &lt;strong&gt;Report data per sample&lt;/strong&gt; is set to &lt;code&gt;Yes&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This will produce a dataset with &lt;em&gt;very&lt;/em&gt; many columns:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_tab.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;There are 53 columns in this dataset (not all are shown here).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The columns in this dataset represent INFO and Genotype fields on the original VCF dataset. Let&amp;rsquo;s restrict ourselves to just a few:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2 &lt;code&gt;POS&lt;/code&gt; - position along mitochondrial genome&lt;/li&gt;
&lt;li&gt;4 &lt;code&gt;REF&lt;/code&gt; - reference allele&lt;/li&gt;
&lt;li&gt;5 &lt;code&gt;ALT&lt;/code&gt; - alternative allele&lt;/li&gt;
&lt;li&gt;50 &lt;code&gt;SAMPLE&lt;/code&gt; - name of the sample&lt;/li&gt;
&lt;li&gt;51 &lt;code&gt;AO&lt;/code&gt; - number of alternative observations (how many times do we see the alternative allele at this position in this sample)&lt;/li&gt;
&lt;li&gt;52 &lt;code&gt;DP&lt;/code&gt; - depth of coverage at this site for this sample&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To cut these columns out we will use &lt;strong&gt;Text Manipulation&lt;/strong&gt; &amp;#8594; &lt;strong&gt;Cut&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/mt_cut.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that column names are pre-ceded with &lt;code&gt;c&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This will generate the following dataset:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;POS  REF ALT     SAMPLE       AO    DP
--------------------------------------
3243  A   G   raw_child-ds-  841  1068
3243  A   G   raw_mother-ds- 767  1558
3483  G   C   raw_child-ds-   40   208
3483  G   C   raw_mother-ds-  87   342
3488  T   A   raw_child-ds-   40   206
3488  T   A   raw_mother-ds-  90   340
5539  A   G   raw_child-ds-   89   338
5539  A   G   raw_mother-ds- 325   526
8557  G   C   raw_child-ds-  181   724
8557  G   C   raw_mother-ds- 265   946

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s look at site 4,243. At this site Mother has 841 &lt;code&gt;G&lt;/code&gt;s (since &lt;code&gt;G&lt;/code&gt; is an alternative allele) and 1,068-841=227 &lt;code&gt;A&lt;/code&gt;s. This child has 767 &lt;code&gt;G&lt;/code&gt;s and 1,558-767=791 &lt;code&gt;A&lt;/code&gt;s:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Allele     A     G
-------------------
Mother   227   841
Child    791   767
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Thus the &lt;em&gt;major&lt;/em&gt; allele in mother (&lt;code&gt;G&lt;/code&gt;) becomes the &lt;em&gt;minor&lt;/em&gt; allele in child &amp;ndash; a remarkable frequency change due to mitochondrial bottleneck!&lt;/p&gt;

&lt;h1 id=&#34;take-a-look-at-the-whole-thing&#34;&gt;Take a look at the whole thing&lt;/h1&gt;

&lt;p&gt;This entire analysis is available as a &lt;a href=&#34;https://usegalaxy.org/u/aun1/h/non-diploid-freebayes&#34;&gt;Galaxy history&lt;/a&gt; that you can import into your Galaxy account and play with.&lt;/p&gt;

&lt;p&gt;Now you know how to call variants in non-diploid system, so try it on bacteria, viruses etc&amp;hellip;&lt;/p&gt;

&lt;h1 id=&#34;exercise&#34;&gt;Exercise&lt;/h1&gt;

&lt;p&gt;Suppose you obtained a virus from some source and you would like to see how it is different from its published reference sequence. You have sequenced the virus and obtained two Illumina files (these files are large, so don&amp;rsquo;t open them. Rather copy their addresses (right click) and use them to upload into Galaxy as explained in &lt;em&gt;Hints&lt;/em&gt; section below):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.bx.psu.edu/~anton/share/ng_test_data/bmmb554/hw4/f.fq.gz&#34;&gt;Forward reads&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.bx.psu.edu/~anton/share/ng_test_data/bmmb554/hw4/r.fq.gz&#34;&gt;Reverse reads&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Analyze these files using Galaxy as was explained in this lesson by mapping them against &lt;a href=&#34;http://www.bx.psu.edu/~anton/share/ng_test_data/bmmb554/hw4/phix.fa&#34;&gt;this reference genome&lt;/a&gt; (again right click to copy the address); see &lt;em&gt;Hints&lt;/em&gt;).&lt;/p&gt;

&lt;h4 id=&#34;hints&#34;&gt;Hints&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;You need to upload reads and the reference genome into Galaxy (&lt;a href=&#34;http://usegalaxy.org&#34;&gt;http://usegalaxy.org&lt;/a&gt;) as shown in &lt;a href=&#34;https://vimeo.com/120973708&#34;&gt;this video&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;You will be mapping reads against an uploaded reference genome as shown in &lt;a href=&#34;https://vimeo.com/123108417&#34;&gt;this video&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>8. Diploid variant calling</title>
      <link>https://nekrut.github.io/BMMB554/post/topic8/</link>
      <pubDate>Sun, 12 Feb 2017 11:42:45 -0400</pubDate>
      
      <guid>https://nekrut.github.io/BMMB554/post/topic8/</guid>
      <description>

&lt;p&gt;Today we hear a lot about personalized medicine. Yet the &lt;em&gt;personalization&lt;/em&gt; is defined by the genetic make up of the individual. Today we will discuss how this information can be uncovered from the genomic sequencing data. The figure above shows distribution of rare and common variants in 1,092 human genomes described by the &lt;a href=&#34;http://www.nature.com/nature/journal/v491/n7422/abs/nature11632.html&#34;&gt;1000 Genome Consortium&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;calling-variants&#34;&gt;Calling variants&lt;/h1&gt;

&lt;p&gt;Variant calling is a complex field that was significantly propelled by advances in DNA sequencing and efforts of large scientific consortia such as the &lt;a href=&#34;http://www.1000genomes.org&#34;&gt;1000 Genomes&lt;/a&gt;. Here we summarize basic ideas central to Genotype and Variant calling. First, let&amp;rsquo;s contrast the two things although they often go together:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Variant calling&lt;/strong&gt; - identification of positions where the sequenced sample is different from the reference sequence (or &lt;a href=&#34;https://github.com/vgteam/vg&#34;&gt;reference genome graph&lt;/a&gt;);&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Genotype calling&lt;/strong&gt; - identifying individual&amp;rsquo;s genotype at variable sites.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A typical workflow for variation discovery involves the following steps (e.g., see Nielsen et al. &lt;a href=&#34;http://www.nature.com/nrg/journal/v12/n6/full/nrg2986.html&#34;&gt;2011&lt;/a&gt;):&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Mapping reads against the reference genome&lt;/li&gt;
&lt;li&gt;Thresholding BAM datasets by, for example, retaining paired, properly mapped reads&lt;/li&gt;
&lt;li&gt;Performing quality score recalibration&lt;/li&gt;
&lt;li&gt;Performing realignment&lt;/li&gt;
&lt;li&gt;Performing variant calling/genotype assignment&lt;/li&gt;
&lt;li&gt;Performing filtering and genotype quality score recalibration&lt;/li&gt;
&lt;li&gt;Annotating variants and performing downstream analyses&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;However, continuing evolution of variant detection methods has made some of these steps obsolete. For instance, omitting quality score recalibration and re-alignment (steps 3 and 4 above) when using haplotype-aware variant callers such as &lt;a href=&#34;https://github.com/ekg/freebayes&#34;&gt;FreeBayes&lt;/a&gt; does not have an effect on the resulting calls (see Brad Chapman&amp;rsquo;s methodological comparisons at &lt;a href=&#34;http://bit.ly/1S9kFJN&#34;&gt;bcbio&lt;/a&gt;). Before going forward with an actual genotype calling in Galaxy let&amp;rsquo;s take a look as some basic ideas behind modern variant callers.&lt;/p&gt;

&lt;h3 id=&#34;how-does-snp-calling-and-genotyping-work&#34;&gt;How does SNP calling and genotyping work?&lt;/h3&gt;

&lt;p&gt;Consider a set of sequencing reads derived from a diploid individual:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;REFERENCE: atcatgacggcaGtagcatat
--------------------------------
READ1:     atcatgacggcaGtagcatat
READ2:         tgacggcaGtagcatat
READ3:     atcatgacggcaAtagca
READ4:            cggcaGtagcatat
READ5:     atcatgacggcaGtagc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The capitalized position contains a G &amp;#8594; A &lt;a href=&#34;https://en.wikipedia.org/wiki/Transition_(genetics)&#34;&gt;transition&lt;/a&gt;. So, in principle this can be a heterozygous site with two alleles &lt;strong&gt;G&lt;/strong&gt; and &lt;strong&gt;A&lt;/strong&gt;. A commonly used nave procedure would define a site as &lt;em&gt;heterozygous&lt;/em&gt; if there is a non-reference allele with frequency between 20% and 80%. In this case &lt;strong&gt;A&lt;/strong&gt; is present in &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;5&lt;/sub&gt; or 20% of the cases, so we can say that this is a heterozygous site. Yet it is only represented by a single read and thus is hardly reliable. Here are some of the possibilities that would explain this &lt;em&gt;variant&lt;/em&gt;. It can be:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A true variant&lt;/li&gt;
&lt;li&gt;Experimental artifact: A library preparation error (e.g., PCR-derived)&lt;/li&gt;
&lt;li&gt;Base calling error&lt;/li&gt;
&lt;li&gt;Analysis error: A misalignment (though unlikely in the above example)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The modern variant callers attempt to assign a reliability estimate for each genotype call. This is done using Bayes reasoning (for a great visual explanation see &lt;a href=&#34;https://oscarbonilla.com/2009/05/visualizing-bayes-theorem/&#34;&gt;blog&lt;/a&gt; by Oscar Bonilla). Here we present a SNP-relevant &amp;ldquo;translation&amp;rdquo; on this explanation (with inspiration from &lt;a href=&#34;https://github.com/ekg&#34;&gt;Erik Garrison&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Suppose in a population you have $A$ individuals (not to be confused with nucleotide &lt;strong&gt;A&lt;/strong&gt;; in this case $A$ is a number of individuals) with a variant. You are performing re-sequencing and observe a variant in $B$ (again, a number) of your sequencing reads. We want to estimate the probability of having the real polymorphism in the population given our observations in sequencing reads. The logic is as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The probability of having polymorphism &lt;strong&gt;A&lt;/strong&gt; in the population is $P(A) = |A|/|U|$&lt;/li&gt;
&lt;li&gt;The probability of seeing a variant given our identification approach (i.e., sequencing) is $P(B) = |B|/|U|$&lt;/li&gt;
&lt;li&gt;Now, the probability of having a variant and it being observed in our sequencing data is the overlap between $A$ and $B$ sets $P(AB) = |AB|/|U|$. This is presented graphically below:&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/pA.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/pB.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/pAB.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;$P(A)$ Polymorphisms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$P(B)$ &lt;br&gt; Variant calls&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$P(AB)$ Polymorphisms + Varinat calls&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now we can ask the following question: &lt;em&gt;What is the probability of a having a real polymorphism&lt;/em&gt; $A$ &lt;em&gt;given our observation of variants in reads&lt;/em&gt; $B$? In other words &lt;em&gt;what is the probability of&lt;/em&gt; $A$ &lt;em&gt;given&lt;/em&gt; $B$? Or, as stated in the original &lt;a href=&#34;https://oscarbonilla.com/2009/05/visualizing-bayes-theorem/&#34;&gt;blog&lt;/a&gt;: &amp;ldquo;&lt;em&gt;given that we are in region $B$ what is the probability that we are in the region $AB$&lt;/em&gt;?&amp;rdquo;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$P(A|B) = \frac{|AB|}{|B|}$&lt;/li&gt;
&lt;li&gt;Dividing by $|U|$: $P(A|B) = \frac{\frac{|AB|}{|U|}}{\frac{|B|}{|U|}}$&lt;/li&gt;
&lt;li&gt;Because we know that $P(AB) = \frac{|AB|}{|U|}$ and $P(B) = \frac{|B|}{|U|}$ we can rewrite the equation in the previous bullet point as $P(A|B) = \frac{P(AB)}{P(B)}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now, let&amp;rsquo;s ask an opposite question. Given a true polymorphism $A$ what are the chances that we do detect it (i.e., find ourselves in $AB$)? It will be:&lt;/p&gt;

&lt;p&gt;[
    P(B|A) = \frac{P(AB)}{P(A)}
]&lt;/p&gt;

&lt;p&gt;So, because we know that $P(A|B) = \frac{P(AB)}{P(B)}$ and we just reasoned that $P(B|A) = \frac{P(AB)}{P(A)}$, we can say that $P(A|B)P(B) = P(B|A)P(A)$ leading us to the &lt;a href=&#34;http://www.math.cornell.edu/~mec/2008-2009/TianyiZheng/Bayes.html&#34;&gt;Bayes formula&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;[
    P(A|B) = \frac{P(B|A)P(A)}{P(B)}
]&lt;/p&gt;

&lt;p&gt;Translating this into &amp;ldquo;genomics terms&amp;rdquo; the probability of having a genotype $G$ given sequencing reads $S$ is: $P(G|S) = \frac{P(S|G)P(G)}{P(S)}$. Because in a given calculation of $P(G|S)$ reads are fixed we can re-write the Bayes formula in the following way:&lt;/p&gt;

&lt;p&gt;$P(G|S) \approx P(S|G)P(G)$&lt;/p&gt;

&lt;p&gt;with $P(S)$ becoming a constant. This leaves us with the need to estimate two things:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;$P(S|G)$, the data likelihood&lt;/li&gt;
&lt;li&gt;$P(G)$, the prior probability for the variant&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In the simplest case we can estimate these as follows:&lt;/p&gt;

&lt;h3 id=&#34;p-s-g&#34;&gt;$P(S|G)$&lt;/h3&gt;

&lt;p&gt;Suppose $S_i$ is a base in read $i$ corresponding to a genome position with genotype $G$. The probability of seeing $S_i$ given $G$, or $P(S_i|G)$, is given by the quality score of $S_i$ (the quality scores are given by base calling software and reported as &lt;a href=&#34;https://en.wikipedia.org/wiki/Phred_quality_score&#34;&gt;phred scores&lt;/a&gt;). Thus the genotype likelihood $P(S|G)$ is the product of $P(S_i|G)$ over all $i$. In reality however there are many other sources of uncertainty (in addition to base qualities) that are incorporated in the calculation of data likelihoods including NGS technology-related issues, dependency of error rates on substitution type (e.g., transitions versus transversions), sequencing context etc&amp;hellip;&lt;/p&gt;

&lt;h3 id=&#34;p-g-a-single-sample-case&#34;&gt;$P(G)$ - a single sample case&lt;/h3&gt;

&lt;p&gt;One can assign an equal probability to all possible genotypes, or to source this information based on previously obtained knowledge containing in a database, such as &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/SNP/&#34;&gt;dbSNP&lt;/a&gt;. In this case (as exemplified in &lt;a href=&#34;http://www.nature.com/nrg/journal/v12/n6/full/nrg2986.html&#34;&gt;Nielsen et al. 2011&lt;/a&gt;) we may, for instance, have a site with a &lt;strong&gt;G/T&lt;/strong&gt; polymorphism and genotypes &lt;strong&gt;GG&lt;/strong&gt;, &lt;strong&gt;TT&lt;/strong&gt;, and &lt;strong&gt;GT&lt;/strong&gt; having frequencies of 0.45, 0.45, 0.09, respectively. We will use these values as priors.&lt;/p&gt;

&lt;h3 id=&#34;p-g-a-multi-sample-case&#34;&gt;$P(G)$ - a multi-sample case&lt;/h3&gt;

&lt;p&gt;Genotype calling reliability can be significantly improved when analyzing multiple samples jointly. In this case genotype frequencies can be inferred from allele frequencies using Hardy-Weinberg equilibrium (&lt;a href=&#34;https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle&#34;&gt;HWE&lt;/a&gt;). The following example (again from &lt;a href=&#34;http://www.nature.com/nrg/journal/v12/n6/full/nrg2986.html&#34;&gt;Nielsen et al. 2011&lt;/a&gt;) illustrates this idea: suppose you are calling genotypes for a single individual using a combination of multiple samples. There are two genotypes, &lt;strong&gt;AT&lt;/strong&gt; and &lt;strong&gt;AA&lt;/strong&gt;, with equally large genotype likelihoods. If, however, in our collection of multiple samples the frequency of &lt;strong&gt;A&lt;/strong&gt; is 1% ($p = 0.01$; $q = 1 - p = 0.99$), then from the HWE we have:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0.0001&lt;/td&gt;
&lt;td&gt;0.0198&lt;/td&gt;
&lt;td&gt;0.9801&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;AA&lt;/strong&gt; ($p^2$)&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;AT&lt;/strong&gt; ($2pq$)&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;TT&lt;/strong&gt; ($q^2$)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This makes it highly unlikely that &lt;strong&gt;AA&lt;/strong&gt; is a true genotype of this individual.&lt;/p&gt;

&lt;h2 id=&#34;calling-with-freebayes&#34;&gt;Calling with FreeBayes&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ekg/freebayes&#34;&gt;FreeBayes&lt;/a&gt; is an open source variant caller that has been battle-tested by the 1000 Genomes community and is extensively used today (also see &lt;a href=&#34;https://bcbio.wordpress.com/&#34;&gt;bcbio&lt;/a&gt;). It has a number of features that simplify variant discovery workflows. These include (from FreeBayes github page):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Indel realignment is accomplished internally&lt;/strong&gt; using a read-independent method, and issues resulting from discordant alignments are dramatically reducedy through the direct detection of haplotypes;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The need for base quality recalibration is avoided&lt;/strong&gt; through the direct detection of haplotypes. Sequencing platform errors tend to cluster (e.g. at the ends of reads), and generate unique, non-repeating haplotypes at a given locus;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Variant quality recalibration is avoided&lt;/strong&gt; by incorporating a number of metrics, such as read placement bias and allele balance, directly into the Bayesian model;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ability to incorporate non-diploid cases&lt;/strong&gt; such as pooled datasets or data from polyploid samples.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Freebayes is a &lt;em&gt;haplotype-based&lt;/em&gt; variant caller. This implies that instead of looking at an individual positions within an alignment of reads to the reference genome, it looks at a haplotype window, length of which is dynamically determined (see section 3.2. in &lt;a href=&#34;http://arxiv.org/pdf/1207.3907v2.pdf&#34;&gt;FreeBayes manuscript&lt;/a&gt;):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/freebayes.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Looking at a haplotype window makes misalignments tolerable. In this case a low complexity poly(A) stretch is misaligned. As a result looking at individual positions will result in calling multiple spurious varians. In the case of FreeBayes looking at a haplotype identifies two alleles (this is a diploid example) &lt;code&gt;A(7)&lt;/code&gt; and &lt;code&gt;A(6)&lt;/code&gt;, while &lt;code&gt;A(8)&lt;/code&gt; is likely an error. Image by &lt;a href=&#34;https://github.com/ekg/freebayes&#34;&gt;Erik Garrison&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;let-s-try-it&#34;&gt;Let&amp;rsquo;s try it&lt;/h1&gt;

&lt;h2 id=&#34;the-data&#34;&gt;The data&lt;/h2&gt;

&lt;p&gt;In this example we will perform variant calling and annotation using &lt;a href=&#34;http://jimb.stanford.edu/giab/&#34;&gt;genome in the bottle data&lt;/a&gt;. Specifically, we will use Ashkenazim Father-Mother-Son trio data from the Personal Genome Project:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;HG002 - NA24385 - huAA53E0 (son)&lt;/li&gt;
&lt;li&gt;HG003 - NA24149 - hu6E4515 (father)&lt;/li&gt;
&lt;li&gt;HG004 - NA24143 - hu8E87A9 (mother)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Yet for a quick tutorial these datasets are way too big, so we created a downsampled (watered down) dataset. This dataset was produced by mapping the trio reads against the &lt;code&gt;hg19&lt;/code&gt; version of the human genome, merging the resulting bam files together (we use readgroups to label individual reads so they can be traced to each of the original individuals), and restricting alignments to a small portion of chromosome 19 containing the &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/gene?cmd=Retrieve&amp;amp;dopt=Graphics&amp;amp;list_uids=5442&#34;&gt;&lt;em&gt;POLRMT&lt;/em&gt;&lt;/a&gt; gene.&lt;/p&gt;

&lt;p&gt;Here is what to do to load the data:&lt;/p&gt;

&lt;h2 id=&#34;loading-the-data&#34;&gt;Loading the data&lt;/h2&gt;

&lt;p&gt;Go to the &lt;a href=&#34;https://usegalaxy.org/library/list#folders/F9ff2d127cd7ed6bc&#34;&gt;data library&lt;/a&gt; and select both BAM and PED datasets. Then Click &lt;strong&gt;to History&lt;/strong&gt; button:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/library_import.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Galaxy will ask you if you want to import these data into a new history, which you might want (in the case below I called this history &lt;code&gt;genotyping try&lt;/code&gt;):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/history_import.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The datasets will appear in your history:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/library_import_complete.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;generating-and-post-processing-freebayes-calls&#34;&gt;Generating and post-processing FreeBayes calls&lt;/h2&gt;

&lt;p&gt;Select &lt;strong&gt;FreeBayes&lt;/strong&gt; from &lt;strong&gt;NGS: Variant Analysis&lt;/strong&gt; section of the tool menu (left pane of Galaxy&amp;rsquo;s interface).&lt;/p&gt;

&lt;h3 id=&#34;running-freebayes&#34;&gt;Running FreeBayes&lt;/h3&gt;

&lt;p&gt;Make sure the top part of the interface looks like shown below. Here we selected &lt;code&gt;GIAB-Ashkenazim-Trio-hg19&lt;/code&gt; as input and set &lt;strong&gt;Using reference genome&lt;/strong&gt; to &lt;code&gt;hg19&lt;/code&gt; and &lt;strong&gt;Choose parameter selection level&lt;/strong&gt; to &lt;code&gt;5&lt;/code&gt;. The interface should look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/FreeBayes_settings.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Scrolling down to &lt;strong&gt;Tweak algorithmic features?&lt;/strong&gt; click &lt;code&gt;Yes&lt;/code&gt; and set &lt;strong&gt;Calculate the marginal probability of genotypes and report as GQ in each sample field in the VCF output&lt;/strong&gt; to &lt;code&gt;Yes&lt;/code&gt;. This would help us evaluating the quality of genotype calls.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/nekrut/galaxy/wiki/images/freebayes_gq.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Depending on how busy Galaxy is this may take a little bit of time (coffee break?). Eventially this will produce a dataset in &lt;a href=&#34;http://www.1000genomes.org/wiki/Analysis/variant-call-format&#34;&gt;VCF&lt;/a&gt; format containing 35 putative variants. Before we can continue we need to post-process this dataset by breaking compound variants into multiple independent variants with &lt;strong&gt;VcfAllelicPrimitives&lt;/strong&gt; tool found within &lt;strong&gt;NGS: VCF Manipulation&lt;/strong&gt; section. This is necessary for ensuring the smooth sailing through downstream analyses:&lt;/p&gt;

&lt;h3 id=&#34;simplifying-variant-representation&#34;&gt;Simplifying variant representation&lt;/h3&gt;

&lt;p&gt;Select FreeBayes output as the input for this tool and make sure &lt;strong&gt;Maintain site and allele-level annotations when decomposing&lt;/strong&gt; and &lt;strong&gt;Maintain genotype-level annotations when decomposing&lt;/strong&gt; are set to &lt;code&gt;Yes&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/vcfallelicprimitives.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;VCFAllelicPrimities&lt;/strong&gt; generated a VCF files containing 37 records (the input VCF only contained 35). This is because a multiple nucleotide polymorphism (&lt;code&gt;TAGG|CAGA&lt;/code&gt;) at position 618851 have been converted to two:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Before:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chr19 618851 . TAGG CAGA 81.7546
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;After:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chr19 618851 . T C 81.7546
chr19 618854 . G A 81.7546
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;annotating-variants-with-snpeff&#34;&gt;Annotating variants with SnpEff&lt;/h3&gt;

&lt;p&gt;At this point we are ready to begin annotating variants using &lt;a href=&#34;http://snpeff.sourceforge.net/SnpEff.html&#34;&gt;SnpEff&lt;/a&gt;. SnpEff, a project maintained by &lt;a href=&#34;https://www.linkedin.com/in/pablocingolani&#34;&gt;Pablo Cingolani&lt;/a&gt; &amp;ldquo;&lt;em&gt;&amp;hellip;annotates and predicts the effects of variants on genes (such as amino acid changes)&amp;hellip;&lt;/em&gt;&amp;rdquo; and so is critical for functional interpretation of variation data.&lt;/p&gt;

&lt;p&gt;Select the latest version of annotation database matching genome version against which reads were mapped and VCF produced. In this case it is &lt;code&gt;GRCh37.75: hg19&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/snpeff.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;SnpEff will generate two outputs: (1) an annotated VCF file and (2) an HTML report. The report contains a number of useful metrics such as distribution of variants across gene features:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/snpeff_chart.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;or changes to codons:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/snpeff_codons.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;manipulating-variation-data-with-gemini&#34;&gt;Manipulating variation data with GEMINI&lt;/h3&gt;

&lt;p&gt;Now that we have an annotated VCF file it is time to peek inside our variation data. &lt;a href=&#34;http://quinlanlab.org/&#34;&gt;Aaron Quinlan&lt;/a&gt;, creator of &lt;a href=&#34;http://gemini.readthedocs.org/en/latest/index.html&#34;&gt;GEMINI&lt;/a&gt;, calls it &lt;em&gt;Detective work&lt;/em&gt;.&lt;/p&gt;

&lt;h4 id=&#34;loading-data-into-gemini&#34;&gt;Loading data into GEMINI&lt;/h4&gt;

&lt;p&gt;The first step is to convert a VCF file we would like to analyze into a GEMINI database. For this we will use &lt;strong&gt;GEMINI Load&lt;/strong&gt; tool from &lt;strong&gt;NGS: GEMINI&lt;/strong&gt; section. GEMINI takes as input a VCF file and a &lt;a href=&#34;http://pngu.mgh.harvard.edu/~purcell/plink/data.shtml&#34;&gt;PED&lt;/a&gt; file describing the relationship between samples. In the case of our dataset the PED file looks like this (accessible from &lt;a href=&#34;https://usegalaxy.org/library/list#folders/F9ff2d127cd7ed6bc/datasets/418b2500e809568b&#34;&gt;here&lt;/a&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#family_id sample_id            paternal_id          maternal_id         sex phenotype ethnicity
family1    HG004_NA24143_mother -9                   -9                   2  1         CEU
family1	   HG003_NA24149_father -9                   -9                   1  1         CEU
family1	   HG002_NA24385_son	HG003_NA24149_father HG004_NA24143_mother 1  2         CEU
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So let&amp;rsquo;s load data into GEMINI. Set VCF and PED inputs:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/gemini_load.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This creates a sqlite database. To see the content of the database use &lt;strong&gt;GEMINI_db_info&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/gemini_db_info.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This produce a list of &lt;a href=&#34;https://github.com/nekrut/galaxy/wiki/datasets/gemini_tables.txt&#34;&gt;all tables and fields&lt;/a&gt; in the database.&lt;/p&gt;

&lt;h4 id=&#34;querying-gemini-database&#34;&gt;Querying GEMINI database&lt;/h4&gt;

&lt;p&gt;GEMINI database is queried using the versatile SQL language (more on SQL &lt;a href=&#34;http://swcarpentry.github.io/sql-novice-survey&#34;&gt;here&lt;/a&gt;). In Galaxy&amp;rsquo;s version of GEMINI this is done using &lt;strong&gt;GEMINI_query&lt;/strong&gt; tool. Within this tool SQL commands are typed directly into the &lt;strong&gt;The query to be issued to the database&lt;/strong&gt; text box. Let&amp;rsquo;s begin getting information from some of the tables we discovered with &lt;strong&gt;GEMINI_db_info&lt;/strong&gt; tool above.
&amp;gt;
The examples below are taken from &amp;ldquo;&lt;a href=&#34;https://s3.amazonaws.com/gemini-tutorials/Intro-To-Gemini.pdf&#34;&gt;Intro to Gemini&lt;/a&gt;&amp;rdquo; tutorial. For extensive documentation see &amp;ldquo;&lt;a href=&#34;http://gemini.readthedocs.org/en/latest/content/querying.html&#34;&gt;Querying GEMINI&lt;/a&gt;&amp;rdquo;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;h4 id=&#34;are-there-novel-varinats-that-are-not-annotated-in-dbsnp-database&#34;&gt;&lt;em&gt;Are there &amp;ldquo;novel&amp;rdquo; varinats that are not annotated in dbSNP database?&lt;/em&gt;&lt;/h4&gt;
&lt;/blockquote&gt;

&lt;p&gt;To answer this question we will type the following query:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT count(*) FROM variants WHERE in_dbsnp == 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;into &lt;strong&gt;The query to be issued to the database&lt;/strong&gt; field of the interface:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/gemini_query1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;As we can see from &lt;a href=&#34;https://usegalaxy.org/datasets/bbd44e69cb8906b51bb37b9032761321/display/?preview=True&#34;&gt;output (Click this link to see it)&lt;/a&gt; there are 21 variants that are not annotated in dbSNP.&lt;/p&gt;

&lt;blockquote&gt;
&lt;h4 id=&#34;which-variants-are-found-within-polrmt-gene&#34;&gt;&lt;em&gt;Which variants are found within POLRMT gene?&lt;/em&gt;&lt;/h4&gt;
&lt;/blockquote&gt;

&lt;p&gt;To answer this type:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT * FROM variants WHERE filter is NULL and gene = &#39;POLRMT&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above query will produce &lt;a href=&#34;https://usegalaxy.org/datasets/bbd44e69cb8906b5a0bb5b2cc0695697/display/?preview=True&#34;&gt;output&lt;/a&gt; with very large number of columns. To restrict the number of columns to a manageable set let&amp;rsquo;s use this command (you may need to scroll sideways):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT rs_ids, aaf_esp_ea, impact, clinvar_disease_name, clinvar_sig FROM variants WHERE filter is NULL and gene = &#39;POLRMT&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(column definitions can be found &lt;a href=&#34;http://gemini.readthedocs.org/en/latest/content/database_schema.html&#34;&gt;here&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://usegalaxy.org/datasets/bbd44e69cb8906b540d65297cd1d26bb/display/?preview=True&#34;&gt;Output&lt;/a&gt; shows varinats found within the &lt;em&gt;POLRMT&lt;/em&gt; gene.&lt;/p&gt;

&lt;h4 id=&#34;querying-genotypes&#34;&gt;Querying genotypes&lt;/h4&gt;

&lt;p&gt;GEMINI provides access to genotype, sequencing depth, genotype quality, and genotype likelihoods for each individual (&lt;code&gt;subjectID&lt;/code&gt;):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;gt_types.subjectID&lt;/code&gt; - three types of genotype types: &lt;code&gt;HOM_REF&lt;/code&gt;, &lt;code&gt;HET&lt;/code&gt;, &amp;lsquo;HOM_ALT`;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gt_quals.subjectID&lt;/code&gt; - genotype quality&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gt_depths.subjectID&lt;/code&gt; - total number of reads in this subject at position&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gt_ref_depths.subjectID&lt;/code&gt; -  number of reference allele reads in this subject at position&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gt_alt_depths.subjectID&lt;/code&gt; - number of alternate allele reads in this subject at position&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;h4 id=&#34;at-how-many-sites-does-child-in-our-trio-have-a-non-reference-allele&#34;&gt;&lt;em&gt;At how many sites does child in our trio have a non-reference allele?&lt;/em&gt;&lt;/h4&gt;
&lt;/blockquote&gt;

&lt;p&gt;To answer this we will use two fields of &lt;strong&gt;GEMINI_query&lt;/strong&gt; interface. In the &lt;strong&gt;The query to be issued to the database&lt;/strong&gt; we will type:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT * from variants
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and in the field &lt;strong&gt;Restrictions to apply to genotype values&lt;/strong&gt; we will enter:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gt_types.HG002_NA24385_son &amp;lt;&amp;gt; HOM_REF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/gemini_query2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This produce &lt;a href=&#34;https://usegalaxy.org/datasets/bbd44e69cb8906b560921700703d0255/display/?preview=True&#34;&gt;a list of sites&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;h4 id=&#34;at-how-many-sites-both-father-and-son-have-non-reference-alleles&#34;&gt;&lt;em&gt;At how many sites both father and son have non reference alleles?&lt;/em&gt;&lt;/h4&gt;
&lt;/blockquote&gt;

&lt;p&gt;To answer this we will type the same expression&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT * from variants
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;into &lt;strong&gt;The query to be issued to the database&lt;/strong&gt; field and&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; (gt_types.HG002_NA24385_son &amp;lt;&amp;gt; HOM_REF AND gt_types.HG003_NA24149_father &amp;lt;&amp;gt; HOM_REF)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;into &lt;strong&gt;Restrictions to apply to genotype values&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;This will produce the following &lt;a href=&#34;https://usegalaxy.org/datasets/bbd44e69cb8906b5aab445b3cd632ba7/display/?preview=True&#34;&gt;output&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;h4 id=&#34;list-genotypes-for-father-and-son-where-they-have-non-reference-alleles&#34;&gt;&lt;em&gt;List genotypes for father and son where they have non-reference alleles.&lt;/em&gt;&lt;/h4&gt;
&lt;/blockquote&gt;

&lt;p&gt;Type the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT gts.HG002_NA24385_son, gts.HG003_NA24149_father from variants
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;into &lt;strong&gt;The query to be issued to the database&lt;/strong&gt; and&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(gt_types.HG002_NA24385_son &amp;lt;&amp;gt; HOM_REF AND gt_types.HG003_NA24149_father &amp;lt;&amp;gt; HOM_REF)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;into &lt;strong&gt;Restrictions to apply to genotype values&lt;/strong&gt;. Output will look like &lt;a href=&#34;https://usegalaxy.org/datasets/bbd44e69cb8906b543c67f80be21ed02/display/?preview=True&#34;&gt;this&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;using-wildcards&#34;&gt;Using wildcards&lt;/h4&gt;

&lt;p&gt;Wilcards simply writing SQL expressions when searching across multiple terms. The syntax for genotype filter wilcards is&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(COLUMN).(SAMPLE_WILDCARD).(SAMPLE_WILDCARD_RULE).(RULE_ENFORCEMENT)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s try a few examples.&lt;/p&gt;

&lt;blockquote&gt;
&lt;h4 id=&#34;at-which-variants-all-samples-are-heterozygous&#34;&gt;&lt;em&gt;At which variants all samples are heterozygous?&lt;/em&gt;&lt;/h4&gt;
&lt;/blockquote&gt;

&lt;p&gt;Type&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT chrom, start, end, ref, alt, gene, impact, (gts).(*) FROM variants
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;into &lt;strong&gt;The query to be issued to the database&lt;/strong&gt; and&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(gt_types).(*).(==HET).(all)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;into &lt;strong&gt;Restrictions to apply to genotype values&lt;/strong&gt;. Here we use wildcards for the query&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;(gts.*)&lt;/code&gt; = get genotypes for &lt;strong&gt;all&lt;/strong&gt; samples&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;and genotype filtering&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;(gt_types).(*).(==HET).(all)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;the &lt;a href=&#34;http://gemini.readthedocs.org/en/latest/content/querying.html#the-all-operator&#34;&gt;all operator&lt;/a&gt; implies that want results for &lt;strong&gt;all&lt;/strong&gt; afftected individuals). Output will look like &lt;a href=&#34;https://usegalaxy.org/datasets/bbd44e69cb8906b5819e1404b5e127d1/display/?preview=True&#34;&gt;this&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;going-further&#34;&gt;Going further&lt;/h3&gt;

&lt;p&gt;This short tutorial should give you an overall idea on how generate variant data in Galaxy and process it with GEMINI. Yet there is much more to learn. Below we list GEMINI tutorials and links to Galaxy libraries with relevant data:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Introduction&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.amazonaws.com/gemini-tutorials/Intro-To-Gemini.pdf&#34;&gt; PDF &lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://usegalaxy.org/library/list#folders/F0283ca691a41c352&#34;&gt; Sample Data &lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://usegalaxy.org/u/aun1/h/gemini-introduction&#34;&gt; Galaxy history &lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Identifying &lt;em&gt;de novo&lt;/em&gt; mutations underlying Mendelian disease&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.amazonaws.com/gemini-tutorials/Gemini-DeNovo-Tutorial.pdf&#34;&gt; PDF &lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://usegalaxy.org/library/list#folders/F775008f45cbbf010&#34;&gt; Sample Data &lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://usegalaxy.org/u/aun1/h/gemini-de-novo-mutations&#34;&gt; Galaxy history &lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Identifying autosomal recessive variants underlying Mendelian disease&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.amazonaws.com/gemini-tutorials/Gemini-Recessive-Tutorial.pdf&#34;&gt; PDF &lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://usegalaxy.org/library/list#folders/F35b262f5ac8aa63a&#34;&gt; Sample Data &lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://usegalaxy.org/u/aun1/h/gemini-autosomal-recessive&#34;&gt; Galaxy history &lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Identifying autosomal dominant variants underlying Mendelian disease&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.amazonaws.com/gemini-tutorials/Gemini-Dominant-Tutorial.pdf&#34;&gt; PDF &lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://usegalaxy.org/library/list#folders/F1c4722ad56892a31&#34;&gt; Sample Data &lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://usegalaxy.org/u/aun1/h/gemini-autosomal-dominant&#34;&gt; Galaxy history &lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;how-to-use-these-tutorials&#34;&gt;How to use these tutorials?&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Right click on the &lt;strong&gt;PDF&lt;/strong&gt; link and open tutorial in a new browser tab&lt;/li&gt;
&lt;li&gt;Right click on &lt;strong&gt;Galaxy history&lt;/strong&gt; link and open Galaxy history in another new browser tab&lt;/li&gt;
&lt;li&gt;When Galaxy history interface opens you will need to click &lt;strong&gt;Import history&lt;/strong&gt; link highlighted within a red outline in the following figure:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/nekrut/galaxy/wiki/images/import_history.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If you have a wide screen arrange browsers tabs side by side:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/side-by-side.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Proceed with tutorial. For example, to repeat the following command from GEMINI tutorial:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/gemini_command.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Use Galaxy&amp;rsquo;s &lt;strong&gt;GEMINI_load&lt;/strong&gt; tool:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/galaxy_command.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;and so on&amp;hellip;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>7. NGS data: Practicalities</title>
      <link>https://nekrut.github.io/BMMB554/post/topic7/</link>
      <pubDate>Wed, 08 Feb 2017 11:26:49 -0400</pubDate>
      
      <guid>https://nekrut.github.io/BMMB554/post/topic7/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/topic7_cover.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In this section we will look at practical aspects of manipulation of next-generation sequencing data. We will start with Fastq format produced by most sequencing machines and will finish with SAM/BAM format representing mapped reads. The cover image above shows a screen dump of a SAM dataset.&lt;/p&gt;

&lt;h1 id=&#34;getting-ngs-data-in&#34;&gt;Getting NGS data in&lt;/h1&gt;

&lt;p&gt;You can data in Galaxy using one of five ways:&lt;/p&gt;

&lt;h2 id=&#34;from-your-computer&#34;&gt;From your computer&lt;/h2&gt;

&lt;p&gt;This works well for small files because web browser do not like lengthy file transfers:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/120901536&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h2 id=&#34;using-ftp&#34;&gt;Using FTP&lt;/h2&gt;

&lt;p&gt;FTP (&lt;a href=&#34;https://en.wikipedia.org/wiki/File_Transfer_Protocol&#34;&gt;file transfer protocol&lt;/a&gt;) allows transferring large collection of files:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/120972739&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h2 id=&#34;from-the-web&#34;&gt;From the Web&lt;/h2&gt;

&lt;p&gt;Upload from the web works when URL (addresses) of data files are known:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/120973708&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h2 id=&#34;from-ebi-short-read-archive&#34;&gt;From EBI short read archive&lt;/h2&gt;

&lt;p&gt;This is the best way to upload published datasets deposited to EBI SRA. The problem is that not all datasets are available from EBI. Next option (below) explain how to deal with NCBI SRA datasets:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/121187220&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h2 id=&#34;from-ncbi-short-read-archive&#34;&gt;From NCBI short read archive&lt;/h2&gt;

&lt;p&gt;Finally, datasets can be uploaded directly from NCBI&amp;rsquo;s short read archive:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/121190377&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;font-color-red-9888-try-it-yourself-font&#34;&gt;&lt;font color=&#34;red&#34;&gt;&amp;#9888; Try it yourself&lt;/font&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Create a new Galaxy history at &lt;a href=&#34;http://usegalaxy.org&#34;&gt;http://usegalaxy.org&lt;/a&gt; (don&amp;rsquo;t forget to log in).&lt;/li&gt;
&lt;li&gt;Import the following two datasets (for help see the above video &amp;ldquo;&lt;em&gt;From the Web&lt;/em&gt;&amp;rdquo;):&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.bx.psu.edu/~anton/share/ng_test_data/var/raw_mother-ds-1.fq.gz&#34;&gt;http://www.bx.psu.edu/~anton/share/ng_test_data/var/raw_mother-ds-1.fq.gz&lt;/a&gt;
&lt;a href=&#34;http://www.bx.psu.edu/~anton/share/ng_test_data/var/raw_mother-ds-2.fq.gz&#34;&gt;http://www.bx.psu.edu/~anton/share/ng_test_data/var/raw_mother-ds-2.fq.gz&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;These are paired end data (see below for explanation of what paired-end is) for a single Illumina run.&lt;/p&gt;

&lt;p&gt;Keep Galaxy history for later. We will need it again in a few minutes.&lt;/p&gt;

&lt;h1 id=&#34;fastq-manipulation-and-quality-control&#34;&gt;Fastq manipulation and quality control&lt;/h1&gt;

&lt;h2 id=&#34;what-is-fastq&#34;&gt;What is Fastq?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/FASTQ_format&#34;&gt;FastQ&lt;/a&gt; is not a very well defined format. In the beginning various manufacturers of sequencing instruments were free to interpret fastq as they saw fit, resulting in a multitude of fastq flavors. This variation stemmed primarily from different ways of encoding quality values as described &lt;a href=&#34;http://en.wikipedia.org/wiki/FASTQ_format&#34;&gt;here&lt;/a&gt; (below you will explanation of quality scores and their meaning). Today, &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/pubmed/20015970&#34;&gt;fastq Sanger&lt;/a&gt; version of the format is considered to be the standard form of fastq. Galaxy is using fastq sanger as the only legitimate input for downstream processing tools and provides &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/pubmed/20562416&#34;&gt;a number of utilities for converting fastq files&lt;/a&gt; into this form (see &lt;strong&gt;NGS: QC and manipulation&lt;/strong&gt; section of Galaxy tools).&lt;/p&gt;

&lt;p&gt;Fastq format looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
@M02286:19:000000000-AA549:1:1101:12677:1273 1:N:0:23
CCTACGGGTGGCAGCAGTGAGGAATATTGGTCAATGGACGGAAGTCTGAACCAGCCAAGTAGCGTGCAG
+
ABC8C,:@F:CE8,B-,C,-6-9-C,CE9-CC--C-&amp;lt;-C++,,+;CE&amp;lt;,,CD,CEFC,@E9&amp;lt;FCFCF?9
@M02286:19:000000000-AA549:1:1101:15048:1299 1:N:0:23
CCTACGGGTGGCTGCAGTGAGGAATATTGGACAATGGTCGGAAGACTGATCCAGCCATGCCGCGTGCAG
+
ABC@CC77CFCEG;F9&amp;lt;F89&amp;lt;9--C,CE,--C-6C-,CE:++7:,CF&amp;lt;,CEF,CFGGD8FFCFCFEGCF
@M02286:19:000000000-AA549:1:1101:11116:1322 1:N:0:23
CCTACGGGAGGCAGCAGTAGGGAATCTTCGGCAATGGACGGAAGTCTGACCGAGCAACGCCGCGTGAGT
+
AAC&amp;lt;CCF+@@&amp;gt;CC,C9,F9C9@9-CFFFE@7@:+CC8-C@:7,@EFE,6CF:+8F7EFEEF@EGGGEEE

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each sequencing read is represented by four lines:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;@ followed by read ID and optional information about sequencing run&lt;/li&gt;
&lt;li&gt;sequenced bases&lt;/li&gt;
&lt;li&gt;+ (optionally followed by the read ID and some additional info)&lt;/li&gt;
&lt;li&gt;quality scores for each base of the sequence encoded as &lt;a href=&#34;https://en.wikipedia.org/wiki/ASCII&#34;&gt;ASCII symbols&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;paired-end-data&#34;&gt;Paired end data&lt;/h2&gt;

&lt;p&gt;It is common to prepare pair-end and mate-pair sequencing libraries. This is highly beneficial for a number of applications discussed in subsequent topics. For now let&amp;rsquo;s just briefly discuss what these are and how they manifest themselves in fastq form.&lt;/p&gt;

&lt;blockquote&gt;

&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/pe_mp.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;&lt;strong&gt;Paired-end and mate-pair reads&lt;/strong&gt;. In paired end sequencing (left) the actual ends of rather short DNA molecules (&amp;lt;1kb) are determined, while for mate pair sequencing (right) the ends of long molecules are joined and prepared in special sequencing libraries. In these mate pair protocols, the ends of long, size-selected molecules are connected with an internal adapter sequence (i.e. linker, yellow) in a circularization reaction. The circular molecule is then processed using restriction enzymes or fragmentation. Fragments are enriched for the linker and outer library adapters are added around the two combined molecule ends. The internal adapter can then be used as a second priming site for an additional sequencing reaction in the same orientation or sequencing can be performed from the second adapter, from the reverse strand. (From Ph.D. dissertation by &lt;a href=&#34;https://core.ac.uk/download/pdf/35186947.pdf&#34;&gt;Martin Kircher&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Thus in both cases (paired-end and mate-pair) a single physical piece of DNA (or RNA in the case of RNA-seq) is sequenced from two ends and so generates two reads. These can be represented as separate files (two fastq files with first and second reads) or a single file were reads for each end are interleaved. Here are examples:&lt;/p&gt;

&lt;h4 id=&#34;two-single-files&#34;&gt;Two single files&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;File 1&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; @M02286:19:000000000-AA549:1:1101:12677:1273 1:N:0:23
 CCTACGGGTGGCAGCAGTGAGGAATATTGGTCAATGGACGGAAGTCT
 +
 ABC8C,:@F:CE8,B-,C,-6-9-C,CE9-CC--C-&amp;lt;-C++,,+;CE
 @M02286:19:000000000-AA549:1:1101:15048:1299 1:N:0:23
 CCTACGGGTGGCTGCAGTGAGGAATATTGGACAATGGTCGGAAGACT
 +
 ABC@CC77CFCEG;F9&amp;lt;F89&amp;lt;9--C,CE,--C-6C-,CE:++7:,CF
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;File 2&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@M02286:19:000000000-AA549:1:1101:12677:1273 2:N:0:23
CACTACCCGTGTATCTAATCCTGTTTGATACCCGCACCTTCGAGCTTA
+
--8A,CCE+,,;,&amp;lt;CC,,&amp;lt;CE@,CFD,,C,CFF+@+@CCEF,,,B+C,
@M02286:19:000000000-AA549:1:1101:15048:1299 2:N:0:23
CACTACCGGGGTATCTAATCCTGTTCGCTCCCCACGCTTTCGTCCATC
+
-6AC,EE@::CF7CFF&amp;lt;&amp;lt;FFGGDFFF,@FGGGG?F7FEGGGDEFF&amp;gt;FF
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Note that read ID are &lt;strong&gt;identical&lt;/strong&gt; in two files and they are listed in &lt;strong&gt;the same&lt;/strong&gt; order. In some cases read IDs in the first and second file may be appended with &lt;code&gt;/1&lt;/code&gt; and &lt;code&gt;/2&lt;/code&gt; tags, respectively.&lt;/p&gt;

&lt;h4 id=&#34;interleaved-file&#34;&gt;Interleaved file&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;@1/1
AGGGATGTGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTA
+
EGGEGGGDFGEEEAEECGDEGGFEEGEFGBEEDDECFEFDD@CDD&amp;lt;ED
@1/2
CCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAAC
+
GHHHDFDFGFGEGFBGEGGEGEGGGHGFGHFHFHHHHHHHEF?EFEFF
@2/1
AGGGATGTGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTA
+
HHHHHHEGFHEEFEEHEEHHGGEGGGGEFGFGGGGHHHHFBEEEEEFG
@2/2
CCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAAC
+
HHHHHHHHHHHHHGHHHHHHGHHHHHHHHHHHFHHHFHHHHHHHHHHH
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Here the first and the second reads are identified with &lt;code&gt;/1&lt;/code&gt; and &lt;code&gt;/2&lt;/code&gt; tags.&lt;/p&gt;

&lt;p&gt;&lt;font color=&#34;red&#34;&gt;&amp;#10148;&lt;/font&gt; &lt;strong&gt;Note&lt;/strong&gt;: Fastq format is not strictly defined and its variations will always cause headache for you. See &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/books/NBK242622/&#34;&gt;this page&lt;/a&gt; for more information.&lt;/p&gt;

&lt;h2 id=&#34;what-are-base-qualities&#34;&gt;What are base qualities?&lt;/h2&gt;

&lt;p&gt;As we&amp;rsquo;ve seen above, fastq datasets contain two types of information:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;sequence of the read&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;base qualities&lt;/em&gt; for each nucleotide in the read.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The base qualities allow us to judge how trustworthy each base in a sequencing read is. The following excerpt from an excellent &lt;a href=&#34;http://chagall.med.cornell.edu/RNASEQcourse/Intro2RNAseq.pdf&#34;&gt;tutorial&lt;/a&gt; by Friederike D&amp;uuml;ndar, Luce Skrabanek, Paul Zumbo explains what base qualities are:&lt;/p&gt;

&lt;p&gt;Illumina sequencing is based on identifying the individual nucleotides by the fluorescence signal emitted upon their incorporation into the growing sequencing read. Once the fluorescence intensities are extracted and translated into the four letter code. The deduction of nucleotide sequences from the images acquired during sequencing is commonly referred to as base calling. Due to the imperfect nature of the sequencing process and limitations of the optical instruments, base calling will always have inherent uncertainty. This is the reason why FASTQ files store the DNA sequence of each read together with a position-specific quality score that represents the error probability, i.e., how likely it is that an individual base call may be incorrect. The score is called &lt;a href=&#34;http://www.phrap.com/phred/&#34;&gt;Phred score&lt;/a&gt;, $Q$, which is proportional to the probability $p$ that a base call is incorrect, where $Q = 10lg(p)$. For example, a Phred score of 10 corresponds to one error in every ten base calls ($Q = 10lg(0.1)$), or 90% accuracy; a Phred score of 20 corresponds to one error in every 100 base calls, or 99% accuracy. A higher Phred score thus reflects higher confidence in the reported base. To assign each base a unique score identifier (instead of numbers of varying character length), Phred scores are typically represented as ASCII characters. At &lt;a href=&#34;http://ascii-code.com/&#34;&gt;http://ascii-code.com/&lt;/a&gt; you can see which characters are assigned to what number. For raw reads, the range of scores will depend on the sequencing technology and the base caller used (Illumina, for example, used a tool called Bustard, or, more recently, RTA). Unfortunately, Illumina has been anything but consistent in how they a) calculated and b) ASCII-encoded the Phred score (see below)! In addition, Illumina now allows Phred scores for base calls with as high as 45, while 41 used to be the maximum score until the HiSeq X. This may cause issues with downstream sapplications that expect an upper limit of 41.&lt;/p&gt;

&lt;hr /&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/illumina_qs.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;Base call quality scores are represented with the Phred range. Different Illumina (formerly Solexa) versions
used different scores and ASCII offsets. Starting with Illumina format 1.8, the score now represents the standard
Sanger/Phred format that is also used by other sequencing platforms and the sequencing archives.&lt;/p&gt;

&lt;hr /&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/fastq_qs.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;The ASCII interpretation and ranges of the different Phred score notations used by Illumina and the original
Sanger interpretation. Although the Sanger format allows a theoretical score of 93, raw sequencing
reads typically do not exceed a Phred score of 60. In fact, most Illumina-based sequencing will result in maximum
scores of 41 to 45 (image from &lt;a href=&#34;https://en.wikipedia.org/wiki/FASTQ_format&#34;&gt;Wikipedia&lt;/a&gt;).&lt;/p&gt;

&lt;h2 id=&#34;assessing-data-quality&#34;&gt;Assessing data quality&lt;/h2&gt;

&lt;p&gt;One of the first steps in the analysis of NGS data is seeing how good the data actually is. &lt;a href=&#34;http://www.bioinformatics.babraham.ac.uk/projects/fastqc/&#34;&gt;FastqQC&lt;/a&gt; is a fantastic tool allowing you to gauge the quality of fastq datasets (and deciding whether to blame or not to blame whoever has done sequencing for you).&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://galaxyproject.org/ngs101/good_fq.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://galaxyproject.org/ngs101/bad_fq.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;strong&gt;A.&lt;/strong&gt; Excellent quality&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;strong&gt;B.&lt;/strong&gt; Hmmm&amp;hellip;OK&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Here you can see FastQC base quality reports (the tools gives you many other types of data) for two datasets: &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt;. The &lt;strong&gt;A&lt;/strong&gt; dataset has long reads (250 bp) and very good quality profile with no qualities dropping below &lt;a href=&#34;http://www.phrap.com/phred/&#34;&gt;phred score&lt;/a&gt; of 30. The &lt;strong&gt;B&lt;/strong&gt; dataset is significantly worse with ends of the reads dipping below phred score of 20. The &lt;strong&gt;B&lt;/strong&gt; reads may need to be trimmed for further processing.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/123453134&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;font-color-red-try-it-yourself-font&#34;&gt;&lt;font color=&#34;red&#34;&gt;Try it yourself&lt;/font&gt;&lt;/h3&gt;

&lt;p&gt;QC datasets you have uploaded before.&lt;/p&gt;

&lt;h2 id=&#34;mapping-your-data&#34;&gt;Mapping your data&lt;/h2&gt;

&lt;p&gt;Mapping of NGS reads against reference sequences is one of the key steps of the analysis. In &lt;a href=&#34;https://nekrut.github.io/BMMB554/post/topic5/&#34;&gt;Topic 5&lt;/a&gt; we covered basic principles behind mapping of sequencing reads against large genomes. Now it is time to see how this is done in practice. Below is a list of key publications highlighting popular mapping tools:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2009 Bowtie 1 - &lt;a href=&#34;http://genomebiology.com/content/10/3/R25&#34;&gt;Langmead et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2012 Bowtie 2 - &lt;a href=&#34;http://www.nature.com/nmeth/journal/v9/n4/full/nmeth.1923.htm&#34;&gt;Langmead and Salzberg&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2009 BWA - &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/25/14/1754.long&#34;&gt;Li and Durbin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2010 BWA - &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/26/5/589&#34;&gt;Li and Durbin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2013 BWA-MEM - &lt;a href=&#34;http://arxiv.org/abs/1303.3997&#34;&gt;Li&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;mapping-against-a-pre-computed-genome-index&#34;&gt;Mapping against a pre-computed genome index&lt;/h3&gt;

&lt;p&gt;Mappers usually compare reads against a reference sequence that has been transformed into a highly accessible data structure called genome index. Such indexes should be generated before mapping begins. Galaxy instances typically store indexes for a number of publicly available genome builds.&lt;/p&gt;

&lt;blockquote&gt;

&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/cached_genome.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;Mapping against a pre-computed index in Galaxy&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For example, the image above shows indexes for &lt;code&gt;hg38&lt;/code&gt; version of the human genome. You can see that there are actually three choices: (1) &lt;code&gt;hg38&lt;/code&gt;, (2) &lt;code&gt;hg38 canonical&lt;/code&gt; and (3) &lt;code&gt;hg38 canonical female&lt;/code&gt;. The &lt;code&gt;hg38&lt;/code&gt; contains all chromosomes as well as all unplaced contigs. The &lt;code&gt;hg38 canonical&lt;/code&gt; does not contain unplaced sequences and only consists of chromosomes 1 through 22, X, Y, and mitochondria. The
&lt;code&gt;hg38 canonical female&lt;/code&gt; contains everything from the canonical set with the exception of chromosome Y.&lt;/p&gt;

&lt;p&gt;The following video show mapping using BWA:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/123102338&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;font-color-red-try-it-yourself-font-1&#34;&gt;&lt;font color=&#34;red&#34;&gt;Try it yourself&lt;/font&gt;&lt;/h3&gt;

&lt;p&gt;Map datasets uploaded before using BWA against &lt;code&gt;hg38&lt;/code&gt; version of the human genome.&lt;/p&gt;

&lt;h3 id=&#34;what-if-pre-computed-index-does-not-exist&#34;&gt;What if pre-computed index does not exist?&lt;/h3&gt;

&lt;p&gt;If Galaxy does not have a genome you need to map against, you can upload your genome sequence as a FASTA file and use it in the mapper directly as shown below (&lt;strong&gt;Load reference genome&lt;/strong&gt; is set to &lt;code&gt;History&lt;/code&gt;).&lt;/p&gt;

&lt;blockquote&gt;

&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/uploaded_genome.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;Mapping against a pre-computed index in Galaxy&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In this case Galaxy will first create an index from this dataset and then run mapping analysis against it. The following video shows how this works in practice:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/123108417&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h2 id=&#34;sam-bam-datasets&#34;&gt;SAM/BAM datasets&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&#34;https://samtools.github.io/hts-specs/SAMv1.pdf&#34;&gt;SAM/BAM&lt;/a&gt; format is an accepted standard for storing aligned reads (it can also store unaligned reads and some mappers such as BWA are accepting unaligned BAM as input). The binary form of the format (BAM) is compact and can be rapidly searched (if indexed). In Galaxy BAM datasets are always indexed (accompanies by a .bai file) and sorted in coordinate order. In the following duscussion I once again rely on &lt;a href=&#34;http://chagall.med.cornell.edu/RNASEQcourse/Intro2RNAseq.pdf&#34;&gt;tutorial&lt;/a&gt; by Friederike D&amp;uuml;ndar, Luce Skrabanek, and Paul Zumbo.&lt;/p&gt;

&lt;p&gt;The output option of STAR already indicates that the results of the alignment will be stored in a SAM or BAM file. The Sequence Alignment/Map (SAM) format is, in fact, a generic nucleotide alignment format that describes the alignment of sequencing reads (or query sequences) to a reference. The human readable, TABdelimited SAM files can be compressed into the Binary Alignment/Map format. These BAM files are bigger than simply gzipped SAM files, because they have been optimized for fast random access rather than size reduction. Position-sorted BAM files can be indexed so that all reads aligning to a locus can be efficiently retrieved without loading the entire file into memory.&lt;/p&gt;

&lt;p&gt;As shown below, SAM files typically contain a short header section and a very long alignment section where each row represents a single read alignment. The following sections will explain the SAM format in a bit more detail. For the most comprehensive and updated information go to &lt;a href=&#34;https://github.com/samtools/hts-specs&#34;&gt;https://github.com/samtools/hts-specs&lt;/a&gt;.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/bam_structure.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;Schematic representation of a SAM file. Each line of the optional header section starts with @, followed by the appropriate abbreviation (e.g., SQ for sequence dictionary which lists all chromosomes names (SN) and their lengths (LN)). The vast majority of lines within a SAM file typically correspond to read alignments where each read is described by the 11 mandatory entries (black font) and a variable number of optional fields (grey font).&lt;/p&gt;

&lt;h3 id=&#34;sam-header&#34;&gt;SAM Header&lt;/h3&gt;

&lt;p&gt;The header section includes information about how the alignment was generated and stored. All lines in the header section are tab-delimited and begin with the @ character, followed by tag:value pairs, where tag is a two-letter string that defines the content and the format of value. For example, the @SQ line in the header section contains the information about the names and lengths of the *reference sequences to which the reads were aligned. For a hypothetical organism with three chromosomes of length 1,000 bp, the SAM header should contain the following three lines:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@SQ SN:chr1 LN:1000
@SQ SN:chr2 LN:1000
@SQ SN:chr3 LN:1000
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;sam-alignment-section&#34;&gt;SAM alignment section&lt;/h3&gt;

&lt;p&gt;The optional header section is followed by the alignment section where each line corresponds to one sequenced read. For each read, there are 11 mandatory fields that always appear in the same order:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;QNAME&amp;gt; &amp;lt;FLAG&amp;gt; &amp;lt;RNAME&amp;gt; &amp;lt;POS&amp;gt; &amp;lt;MAPQ&amp;gt; &amp;lt;CIGAR&amp;gt; &amp;lt;MRNM&amp;gt; &amp;lt;MPOS&amp;gt; &amp;lt;ISIZE&amp;gt; &amp;lt;SEQ&amp;gt; &amp;lt;QUAL&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the corresponding information is unavailable or irrelevant, field values can be 0 or * (depending on the field, see below), but they cannot be missing! After the 11 mandatory fields, a variable number of optional fields can be present. Heres an example of one single line of a real-life SAM file (you may need to scroll sideways):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ERR458493 .552967 16 chrI 140 255 12 M61232N37M2S * 0 0 CCACTCGTTCACCAGGGCCGGCGGGCTGATCACTTTATCGTGCATCTTGGC BB?HHJJIGHHJIGIIJJIJGIJIJJIIIGHBJJJJJJHHHHFFDDDA1+B NH:i:1 HI:i:1 AS:i:41 nM:i:2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The following table explains the format and content of each field. The &lt;code&gt;FLAG&lt;/code&gt;, &lt;code&gt;CIGAR&lt;/code&gt;, and the optional fields (marked in blue) are explained in more detail below. The number of optional fields can vary widely between different SAM files and even between reads within in the same file. The field types marked in blue are explained in more detail in the main text below.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/sam_fields.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;h4 id=&#34;flag-field&#34;&gt;&lt;code&gt;FLAG&lt;/code&gt; field&lt;/h4&gt;

&lt;p&gt;The FLAG field encodes various pieces of information about the individual read, which is particularly important for PE reads. It contains an integer that is generated from a sequence of Boolean bits (0, 1). This way, answers to multiple binary (Yes/No) questions can be compactly stored as a series of bits, where each of the single bits can be addressed and assigned separately.&lt;/p&gt;

&lt;p&gt;The following table gives an overview of the different properties that can be encoded in the FLAG field. The developers of the SAM format and samtools tend to use the hexadecimal encoding as a means to refer to the different bits in their documentation. The value of the FLAG field in a given SAM file, however, will always be the decimal representation of the sum of the underlying binary values (as shown in Table below, row 2).&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/sam_flag.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;The &lt;code&gt;FLAG&lt;/code&gt; field of SAM files stores information about the respective read alignment in one single decimal number. The decimal number is the sum of all the answers to the Yes/No questions associated with each binary bit. The hexadecimal representation is used to refer to the individual bits (questions). A bit is set if the corresponding state is true. For example, if a read is paired, &lt;code&gt;0x1&lt;/code&gt; will be set, returning the decimal value of 1. Therefore, all &lt;code&gt;FLAG&lt;/code&gt; values associated with paired reads must be uneven decimal numbers. Conversely, if the &lt;code&gt;0x1&lt;/code&gt; bit is unset (= read is not paired), no assumptions can be made about &lt;code&gt;0x2&lt;/code&gt;, &lt;code&gt;0x8&lt;/code&gt;, &lt;code&gt;0x20&lt;/code&gt;, &lt;code&gt;0x40&lt;/code&gt; and &lt;code&gt;0x80&lt;/code&gt; because they refer to paired reads.&lt;/p&gt;

&lt;p&gt;In a run with single reads, the flags you most commonly see are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;0: This read has been mapped to the forward strand. (None of the bit-wise flags have been set.)&lt;/li&gt;
&lt;li&gt;4: The read is unmapped (&lt;code&gt;0x4&lt;/code&gt; is set).&lt;/li&gt;
&lt;li&gt;16: The read is mapped to the reverse strand (&lt;code&gt;0x10&lt;/code&gt; is set)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(&lt;code&gt;0x100&lt;/code&gt;, &lt;code&gt;0x200&lt;/code&gt; and &lt;code&gt;0x400&lt;/code&gt; are not used by most aligners/mappers, but could, in principle be set for single reads.) Some common &lt;code&gt;FLAG&lt;/code&gt; values that you may see in a PE experiment include:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;69&lt;/strong&gt; (= 1 + 4 + 64)&lt;/td&gt;
&lt;td&gt;The read is paired, is the first read in the pair, and is unmapped.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;77&lt;/strong&gt; (= 1 + 4 + 8 + 64)&lt;/td&gt;
&lt;td&gt;The read is paired, is the first read in the pair, both are unmapped.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;83&lt;/strong&gt; (= 1 + 2 + 16 + 64)&lt;/td&gt;
&lt;td&gt;The read is paired, mapped in a proper pair, is the first read in the pair, and it is mapped to the reverse strand.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;99&lt;/strong&gt; (= 1 + 2 + 32 + 64)&lt;/td&gt;
&lt;td&gt;The read is paired, mapped in a proper pair, is the first read in the pair, and its mate is mapped to the reverse strand.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;133&lt;/strong&gt; (= 1 + 4 + 128)&lt;/td&gt;
&lt;td&gt;The read is paired, is the second read in the pair, and it is unmapped.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;137&lt;/strong&gt; (= 1 + 8 + 128)&lt;/td&gt;
&lt;td&gt;The read is paired, is the second read in the pair, and it is mapped while its mate is not.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;141&lt;/strong&gt; (= 1 + 4 + 8 + 128)&lt;/td&gt;
&lt;td&gt;The read is paired, is the second read in the pair, but both are unmapped.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;147&lt;/strong&gt; (= 1 + 2 + 16 + 128)&lt;/td&gt;
&lt;td&gt;The read is paired, mapped in a proper pair, is the second read in the pair, and mapped to the reverse strand.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;163&lt;/strong&gt; (= 1 + 2 + 32 + 128)&lt;/td&gt;
&lt;td&gt;The read is paired, mapped in a proper pair, is the second read in the pair, and its mate is mapped to the reverse strand.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;A useful website for quickly translating the FLAG integers into plain English explanations like the ones shown above is: &lt;a href=&#34;https://broadinstitute.github.io/picard/explain-flags.html&#34;&gt;https://broadinstitute.github.io/picard/explain-flags.html&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;cigar-string&#34;&gt;&lt;code&gt;CIGAR&lt;/code&gt; string&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;CIGAR&lt;/code&gt; stands for &lt;em&gt;Concise Idiosyncratic Gapped Alignment Report&lt;/em&gt;. This sixth field of a SAM file
contains a so-called CIGAR string indicating which operations were necessary to map the read to the reference sequence at that particular locus.&lt;/p&gt;

&lt;p&gt;The following operations are defined in CIGAR format (also see figure below):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;M&lt;/strong&gt; - Alignment (can be a sequence match or mismatch!)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;I&lt;/strong&gt; - Insertion in the read compared to the reference&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;D&lt;/strong&gt; - Deletion in the read compared to the reference&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;N&lt;/strong&gt; - Skipped region from the reference. For mRNA-to-genome alignments, an N operation represents an intron. For other types of alignments, the interpretation of N is not defined.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;S&lt;/strong&gt; - Soft clipping (clipped sequences are present in read); S may only have H operations between them and the ends of the string&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;H&lt;/strong&gt; - Hard clipping (clipped sequences are NOT present in the alignment record); can only be present as the first and/or last operation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;P&lt;/strong&gt; - Padding (silent deletion from padded reference)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;=&lt;/strong&gt; - Sequence match (not widely used)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;X&lt;/strong&gt; - Sequence mismatch (not widely used)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The sum of lengths of the &lt;strong&gt;M&lt;/strong&gt;, &lt;strong&gt;I&lt;/strong&gt;, &lt;strong&gt;S&lt;/strong&gt;, &lt;strong&gt;=&lt;/strong&gt;, &lt;strong&gt;X&lt;/strong&gt; operations must equal the length of the read. Here are some examples:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/cigar.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;h4 id=&#34;optional-fields&#34;&gt;Optional fields&lt;/h4&gt;

&lt;p&gt;Following the eleven mandatory SAM file fields, the optional fields are presented as key-value
pairs in the format of &lt;code&gt;&amp;lt;TAG&amp;gt;:&amp;lt;TYPE&amp;gt;:&amp;lt;VALUE&amp;gt;&lt;/code&gt;, where &lt;code&gt;TYPE&lt;/code&gt; is one of:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;A&lt;/code&gt; - Character&lt;/li&gt;
&lt;li&gt;&lt;code&gt;i&lt;/code&gt; - Integer&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; - Float number&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Z&lt;/code&gt; - String&lt;/li&gt;
&lt;li&gt;&lt;code&gt;H&lt;/code&gt; - Hex string&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The information stored in these optional fields will vary widely depending on the mapper and new tags can be added freely. In addition, reads within the same SAM file may have different numbers of optional fields, depending on the program that generated the SAM file. Commonly used optional tags include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;AS:i&lt;/code&gt; - Alignment score&lt;/li&gt;
&lt;li&gt;&lt;code&gt;BC:Z&lt;/code&gt; - Barcode sequence&lt;/li&gt;
&lt;li&gt;&lt;code&gt;HI:i&lt;/code&gt; - Match is i-th hit to the read&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NH:i&lt;/code&gt; - Number of reported alignments for the query sequence&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NM:i&lt;/code&gt; - Edit distance of the query to the reference&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MD:Z&lt;/code&gt; - String that contains the exact positions of mismatches (should complement the CIGAR string)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RG:Z&lt;/code&gt; - Read group (should match the entry after ID if @RG is present in the header.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thus, for example, we can use the NM:i:0 tag to select only those reads which map perfectly to the reference(i.e., have no mismatches). While the optional fields listed above are fairly standardized, tags that begin with &lt;code&gt;X&lt;/code&gt;, &lt;code&gt;Y&lt;/code&gt;, and &lt;code&gt;Z&lt;/code&gt; are reserved for particularly free usage and will never be part of the official SAM file format specifications. &lt;code&gt;XS&lt;/code&gt;, for example, is used by TopHat (an RNA-seq analysis tool we will discuss later) to encode the strand information (e.g., &lt;code&gt;XS:A:+&lt;/code&gt;) while Bowtie2 and BWA use &lt;code&gt;XS:i:&lt;/code&gt; for reads with multiple alignments to store the alignment score for the next-best-scoring alignment (e.g., &lt;code&gt;XS:i:30&lt;/code&gt;).&lt;/p&gt;

&lt;h3 id=&#34;read-groups&#34;&gt;Read Groups&lt;/h3&gt;

&lt;p&gt;One of the key features of SAM/BAM format is the ability to label individual reads with readgroup tags. This allows pooling results of multiple experiments into a single BAM dataset. This significantly simplifies downstream logistics: instead of dealing with multiple datasets one can handle just one. Many downstream analysis tools such as variant callers are designed to recognize readgroup data and output results on per-readgroup basis.&lt;/p&gt;

&lt;p&gt;One of the best descriptions of BAM readgroups is on &lt;a href=&#34;http://gatkforums.broadinstitute.org/discussion/1317/collected-faqs-about-bam-files&#34;&gt;GATK support site&lt;/a&gt;. We have gratefully stolen two tables describing the most important readgroup tags - &lt;code&gt;ID&lt;/code&gt;, &lt;code&gt;SM&lt;/code&gt;, &lt;code&gt;LB&lt;/code&gt;, and &lt;code&gt;PL&lt;/code&gt; - from GATK forum and provide them here:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/rg.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;As further described in the GATK forum:&amp;rdquo;&lt;em&gt;A concrete example may be instructive. Suppose I have a trio of samples: MOM, DAD, and KID. Each has two DNA libraries prepared, one with 400 bp inserts and another with 200 bp inserts. Each of these libraries is run on two lanes of an Illumina machine, requiring 3 x 2 x 2 = 12 lanes of data. When the data come off the sequencer, I would create 12 bam files, with the following @RG fields in the header&lt;/em&gt;&amp;ldquo;:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/rg_example.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;Too see an example of read group manipulation in Galaxy see the following &lt;a href=&#34;https://player.vimeo.com/video/123102338#t=1:40&#34;&gt;clip&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;manipulating-sam-bam-datasets&#34;&gt;Manipulating SAM/BAM datasets&lt;/h2&gt;

&lt;p&gt;We support four major toolsets for processing of SAM/BAM datasets:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://deeptools.github.io/&#34;&gt;DeepTools&lt;/a&gt; - a suite of user-friendly tools for the visualization, quality control and normalization of data from deep-sequencing DNA sequencing experiments.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.htslib.org/&#34;&gt;SAMtools&lt;/a&gt; - various utilities for manipulating alignments in the SAM/BAM format, including sorting, merging, indexing and generating alignments in a per-position format.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pezmaster31/bamtools/wiki/Tutorial_Toolkit_BamTools-1.0.pdf&#34;&gt;BAMtools&lt;/a&gt; - a toolkit for reading, writing, and manipulating BAM (genome alignment) files.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://broadinstitute.github.io/picard/&#34;&gt;Picard&lt;/a&gt; - a set of Java tools for manipulating high-throughput sequencing data (HTS) data and formats.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The following video highlights de-duplication, filtering, and cleaning of a BAM dataset using BAMtools and Picard tools:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/123113197&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;font-color-red-try-it-yourself-font-2&#34;&gt;&lt;font color=&#34;red&#34;&gt;Try it yourself&lt;/font&gt;&lt;/h3&gt;

&lt;p&gt;Perform a similar analyses with your own data.&lt;/p&gt;

&lt;h2 id=&#34;the-challenge-of-read-duplicates&#34;&gt;The challenge of read duplicates&lt;/h2&gt;

&lt;h3 id=&#34;pcr-duplicates&#34;&gt;PCR duplicates&lt;/h3&gt;

&lt;p&gt;Preparation of sequencing libraries (at least at the time of writing) for technologies such as Illumina (used in this examples) involves PCR amplification. It is required to generate sufficient number of sequencing templates so that a reliable detection can be performed by base callers. Yet PCR has it&amp;rsquo;s biases, which are especially profound in cases of multitemplate PCR used for construction of sequencing libraries (Kanagawa et al. &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;amp;db=PubMed&amp;amp;dopt=Abstract&amp;amp;list_uids=16233530&#34;&gt;2003&lt;/a&gt;).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/pcr-duplicates.png&#34; /&gt;
    
    
&lt;/figure&gt;

Analyzing molecules aligning with the same outer coordinates, a mapping quality of at least 30 and a length of at least 30nt, resulted in an average coverage of 12.9 per PCR duplicate and an empirical coverage distribution similar to an exponential/power law distribution (left upper panel). This indicates that many molecules are only observed for deeper sequencing while other molecules are available at higher frequencies. Analyzing length (left middle panel) and GC content (left lower panel) patterns as well as the combination (right panel) shows higher PCR duplicate counts for a GC content between 30% to 70% as well as for shorter molecules compared to longer molecules. This effect may be due to an amplification bias from the polymerase or the cluster generation process necessary for Illumina sequencing. From Ph.D. dissertation of &lt;a href=&#34;http://www.qucosa.de/fileadmin/data/qucosa/documents/7110/pflichtexemplar_final.pdf&#34;&gt;Martin Kircher&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Duplicates can be identified based on their outer alignment coordinates or using sequence-based clustering. One of the common ways for identification of duplicate reads is the &lt;code&gt;MarkDuplicates&lt;/code&gt; utility from &lt;a href=&#34;https://broadinstitute.github.io/picard/command-line-overview.html&#34;&gt;Picard&lt;/a&gt; package. It is designed to identify both PCR and optical duplicates:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Duplicates are identified as read pairs having identical 5&amp;rsquo; positions (coordinate and strand) for both reads in a mate pair (and optionally, matching unique molecular identifier reads; see BARCODE_TAG option). Optical, or more broadly Sequencing, duplicates are duplicates that appear clustered together spatially during sequencing and can arise from optical/imagine-processing artifacts or from bio-chemical processes during clonal amplification and sequencing; they are identified using the READ_NAME_REGEX and the OPTICAL_DUPLICATE_PIXEL_DISTANCE options. The tool&amp;rsquo;s main output is a new SAM or BAM file in which duplicates have been identified in the SAM flags field, or optionally removed (see REMOVE_DUPLICATE and REMOVE_SEQUENCING_DUPLICATES), and optionally marked with a duplicate type in the &amp;lsquo;DT&amp;rsquo; optional attribute. In addition, it also outputs a metrics file containing the numbers of READ_PAIRS_EXAMINED, UNMAPPED_READS, UNPAIRED_READS, UNPAIRED_READ DUPLICATES, READ_PAIR_DUPLICATES, and READ_PAIR_OPTICAL_DUPLICATES. Usage example: java -jar picard.jar MarkDuplicates I=input.bam \ O=marked_duplicates.bam M=marked_dup_metrics.txt.`&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;sampling-coincidence-duplicates&#34;&gt;Sampling coincidence duplicates&lt;/h3&gt;

&lt;p&gt;However, one has to be careful when removing duplicates in cases when the sequencing targets are small (e.g., sequencing of bacterial, viral, or organellar genomes as well as amplicons). This is because when sequencing target is small reads will have the same coordinates by chance and not because of PCR amplification issues. The figure below illustrates the fine balance between estimates allele frequency, coverage, and variation in insert size:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/sampling-bias.png&#34; /&gt;
    
    
&lt;/figure&gt;

The Variant Allele Frequency (VAF) bias determined by coverage and insert size variance. Reads are paired-end and read length is 76. The insert size distribution is modeled as a Gaussian distribution with mean at 200 and standard deviation shown on the x-axis. The true VAF is 0.05. The darkness at each position indicates the magnitude of the bias in the VAF. (From Zhou et al. &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/30/8/1073&#34;&gt;2013&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>6. Introduction to Galaxy: Exons and Repeats</title>
      <link>https://nekrut.github.io/BMMB554/post/topic6/</link>
      <pubDate>Wed, 01 Feb 2017 10:39:09 -0400</pubDate>
      
      <guid>https://nekrut.github.io/BMMB554/post/topic6/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/topic6_cover.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;introduction-to-galaxy&#34;&gt;Introduction to Galaxy&lt;/h1&gt;

&lt;p&gt;In this lecture we will introduce you to bare basics of Galaxy:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Getting data from external databases such as UCSC&lt;/li&gt;
&lt;li&gt;Performing simple data manipulation&lt;/li&gt;
&lt;li&gt;Understanding Galaxy&amp;rsquo;s History system&lt;/li&gt;
&lt;li&gt;Creating a running a workflow&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;what-are-we-trying-to-do&#34;&gt;What are we trying to do?&lt;/h2&gt;

&lt;p&gt;Suppose you get the following question:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Mom (or Dad) &amp;hellip; Which coding exon has the highest number of single nucleotide polymorphisms on chromosome 22?&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You think to yourself &amp;ldquo;Wow! This is a simple question &amp;hellip; I know exactly where the data is (at UCSC) but how do I actually compute this?&amp;rdquo; The truth is, there is really no straightforward way of answering this question in a time frame comparable to the attention span of a 7-year-old. Well &amp;hellip; actually there is and it is called Galaxy. So let&amp;rsquo;s try it&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;0-organizing-your-windows-and-setting-up-galaxy-account&#34;&gt;0. Organizing your windows and setting up Galaxy account&lt;/h2&gt;

&lt;h3 id=&#34;0-0-getting-your-display-sorted-out&#34;&gt;0.0. Getting your display sorted out&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Some screenshots shown here may appear slightly different from the ones you will see on your screen. Galaxy is quickly evolving and as a result some discrepancies are possible (and likely).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To get the most of this tutorial open two browser windows. One you already have (it is this page). To open the other, &lt;strong&gt;right&lt;/strong&gt; click &lt;a href=&#34;http://usegalaxy.org&#34;&gt;this link&lt;/a&gt; and choose &amp;ldquo;Open in a New Window&amp;rdquo; (or something similar depending on your operating system and browser):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/newWindow.png&#34; alt=&#34;open in a new window&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Then organize your windows as something like this (depending on the size of your monitor you may or may not be able to organize things this way, but you get the idea):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://galaxyproject.org/galaxy101/twoScreens.png&#34; alt=&#34;Windows side by side&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;0-1-setting-up-galaxy-account&#34;&gt;0.1. Setting up Galaxy account&lt;/h3&gt;

&lt;p&gt;Go to the &lt;strong&gt;User&lt;/strong&gt; link at the top of Galaxy interface and choose &lt;strong&gt;Register&lt;/strong&gt; (unless of course you already have an account):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/register.png&#34; alt=&#34;register&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Then enter your information and you&amp;rsquo;re in!&lt;/p&gt;

&lt;h2 id=&#34;1-getting-data-from-ucsc&#34;&gt;1. Getting data from UCSC&lt;/h2&gt;

&lt;h3 id=&#34;1-0-getting-coding-exons&#34;&gt;1.0. Getting coding exons&lt;/h3&gt;

&lt;p&gt;First thing we will do is to obtain data from UCSC by clicking &lt;strong&gt;Get Data &amp;#8594; UCSC Main&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/getDataUCSC.png&#34; alt=&#34;get data from UCSC&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You will see UCSC Table Browser interface appearing in your browser window:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/ucscGenes.png&#34; alt=&#34;UCSC genes&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Make sure that your settings are exactly the same as shown on the screen (in particular, &lt;strong&gt;position&lt;/strong&gt; should be set to &amp;ldquo;chr22&amp;rdquo;, &lt;strong&gt;output format&lt;/strong&gt; should be set to &amp;ldquo;BED - browser extensible data&amp;rdquo;, and &amp;ldquo;Galaxy&amp;rdquo; should be checked within the &lt;strong&gt;Send output to&lt;/strong&gt; option). Click &lt;strong&gt;get output&lt;/strong&gt; and you will see the next screen:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/ucscGenes2.png&#34; alt=&#34;UCSC ganes 2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;here make sure &lt;strong&gt;Create one BED record per:&lt;/strong&gt; is set to &amp;ldquo;Coding Exons&amp;rdquo; and click &lt;strong&gt;Send Query to Galaxy&lt;/strong&gt; button. After this you will see your first History Item in Galaxy&amp;rsquo;s right pane. It will go through gray (preparing) and yellow (running) states to become green:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/firstHistoryItem.png&#34; alt=&#34;First history item&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-1-getting-snps&#34;&gt;1.1. Getting SNPs&lt;/h3&gt;

&lt;p&gt;Now is the time to obtain SNP data (SNPs are &lt;a href=&#34;https://ghr.nlm.nih.gov/primer/genomicresearch/snp&#34;&gt;&lt;em&gt;single nucleotide polymorphisms&lt;/em&gt;&lt;/a&gt;). This is done almost exactly the same way. First thing we will do is to again click on &lt;strong&gt;Get Data &amp;#8594; UCSC Main&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/getDataUCSC.png&#34; alt=&#34;get data from UCSC&#34; /&gt;&lt;/p&gt;

&lt;p&gt;but now change &lt;strong&gt;group&lt;/strong&gt; to &amp;ldquo;Variation&amp;rdquo;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/variation.png&#34; alt=&#34;Variation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;so that the whole page looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/ucscSNPs.png&#34; alt=&#34;UCSC SNPs&#34; /&gt;&lt;/p&gt;

&lt;p&gt;click get output and you should see this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/ucscSNPs2.png&#34; alt=&#34;UCSC SNPs 2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;where you need to make sure that &lt;strong&gt;Whole Gene&lt;/strong&gt; is selected (&amp;ldquo;Whole Gene&amp;rdquo; here really means &amp;ldquo;Whole Feature&amp;rdquo;) and click &lt;strong&gt;Send Query to Galaxy&lt;/strong&gt; button. You will get your second item in the history:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/secondHistoryItem.png&#34; alt=&#34;Second history item&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now we will rename the two history items to &amp;ldquo;Exons&amp;rdquo; and &amp;ldquo;SNPs&amp;rdquo; by clicking on the Pencil icon adjacent to each item. After changing the name scroll down and click &lt;strong&gt;Save&lt;/strong&gt;.  Also we will rename history to &amp;ldquo;my example&amp;rdquo; (or whatever you want) by clicking on &lt;strong&gt;Unnamed history&lt;/strong&gt; so everything looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/rename.png&#34; alt=&#34;Rename&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;video&#34;&gt;Video&lt;/h3&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/185523444&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h2 id=&#34;2-finding-exons-with-the-highest-number-of-snps&#34;&gt;2. Finding Exons with the highest number of SNPs&lt;/h2&gt;

&lt;h3 id=&#34;2-0-joining-exons-with-snps&#34;&gt;2.0. Joining exons with SNPs&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s remind ourselves that our objective was to find which exon contains the most SNPs. This first step in answering this question will be joining exons with SNPs (a fancy word for printing exons and SNPs that overlap side by side). This is done using &lt;strong&gt;Operate on Genomics Intervals &amp;#8594; Join&lt;/strong&gt; tool:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/join.png&#34; alt=&#34;Join&#34; /&gt;&lt;/p&gt;

&lt;p&gt;make sure your &lt;strong&gt;Exons&lt;/strong&gt; are first and &lt;strong&gt;SNPs&lt;/strong&gt; are second and click &lt;strong&gt;Execute&lt;/strong&gt;. You will get the third history item:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/thirdHistoryItem.png&#34; alt=&#34;Third history item&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-1-counting-the-number-of-snps-per-exon&#34;&gt;2.1. Counting the number of SNPs per exon&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s look at the data obtained from the join operation above (you can do it by clicking the &amp;ldquo;eye&amp;rdquo; icon adjacent to the dataset). Below is a subsample of rows from the joined datasets (you may need to scroll sideways to see the entire length of the rows below):&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;font color=&#34;red&#34;&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chr22 15710867 15711034 uc062bej.1_cds_9_0_chr22_15710868_f  0 + chr22 15710880 15710881 rs568292779 0 -
chr22 15710867 15711034 uc062bej.1_cds_9_0_chr22_15710868_f  0 + chr22 15710947 15710948 rs544633418 0 -
chr22 15710867 15711034 uc062bej.1_cds_9_0_chr22_15710868_f  0 + chr22 15710906 15710907 rs548691624 0 -
chr22 15710867 15711034 uc062bej.1_cds_9_0_chr22_15710868_f  0 + chr22 15710920 15710921 rs530488686 0 -
chr22 15710867 15711034 uc062bej.1_cds_9_0_chr22_15710868_f  0 + chr22 15710932 15710933 rs563306354 0 -
chr22 15710867 15711034 uc062bej.1_cds_9_0_chr22_15710868_f  0 + chr22 15711019 15711020 rs559431407 0 -
chr22 15710867 15711034 uc062bej.1_cds_9_0_chr22_15710868_f  0 + chr22 15710949 15710950 rs532940301 0 -
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/font&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;                                                      ....
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;chr22 15719659 15719777 uc062bej.1_cds_10_0_chr22_15719660_f 0 + chr22 15719668 15719669 rs200891952 0 -
chr22 15719659 15719777 uc062bej.1_cds_10_0_chr22_15719660_f 0 + chr22 15719751 15719752 rs556077431 0 -
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Look at the rows highlighted in red. They all correspond to the same exon (id = &lt;code&gt;uc062bej.1_cds_9_0_chr22_15710868_f&lt;/code&gt;) that overlaps seven distinct SNPs (ids: &lt;code&gt;rs568292779&lt;/code&gt;, &lt;code&gt;rs544633418&lt;/code&gt;, &lt;code&gt;rs548691624&lt;/code&gt;, &lt;code&gt;rs530488686&lt;/code&gt;, &lt;code&gt;rs563306354&lt;/code&gt;, &lt;code&gt;rs559431407&lt;/code&gt;, &lt;code&gt;rs532940301&lt;/code&gt;). In other words this means that this exon contains seven SNPs. Since our ultimate goal is to count the number of SNPs per exon we can simply do this by counting how many times an exon&amp;rsquo;s id appears in pur dataset. This can be easily done with the &lt;strong&gt;Join, Subtract, and Group &amp;#8594; Group&lt;/strong&gt; tool:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/group1.png&#34; alt=&#34;Group&#34; /&gt;&lt;/p&gt;

&lt;p&gt;choose column 4 by selecting &amp;ldquo;Column: 4&amp;rdquo; in &lt;strong&gt;Group by&lt;/strong&gt; column. Then click on &lt;strong&gt;Insert Operation&lt;/strong&gt; and make sure the interface looks exactly as shown below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/group2.png&#34; alt=&#34;Group2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;click &lt;strong&gt;Execute&lt;/strong&gt;. Your history will look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/fourthHistoryItem.png&#34; alt=&#34;Fourth history item&#34; /&gt;&lt;/p&gt;

&lt;p&gt;if you look at the above image you will see that the result of grouping (dataset #4) contains two columns. This first contains the exon name while the second shows the number of times this name has been repeated in dataset #3.&lt;/p&gt;

&lt;h3 id=&#34;2-2-sorting-exons-by-snp-count&#34;&gt;2.2. Sorting exons by SNP count&lt;/h3&gt;

&lt;p&gt;To see which exon has the highest number of SNPs we can simply sort the dataset #4 on the second column in descending order. This is done with &lt;strong&gt;Filter and Sort &amp;#8594; Sort&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/sort.png&#34; alt=&#34;Sort&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This will generate the fifth history item:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/fifthHistoryItem.png&#34; alt=&#34;Fifth history item&#34; /&gt;&lt;/p&gt;

&lt;p&gt;and you can now see that the highest number of SNPs per exon is 63.&lt;/p&gt;

&lt;h3 id=&#34;2-3-selecting-top-five&#34;&gt;2.3. Selecting top five&lt;/h3&gt;

&lt;p&gt;Now let&amp;rsquo;s select top five exons with the highest number of SNPs. For this we will use &lt;strong&gt;Text Manipulation &amp;#8594; Select First&lt;/strong&gt; tool:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/selectFirst.png&#34; alt=&#34;Select first&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Clicking &lt;strong&gt;Execute&lt;/strong&gt; will produce the sixth history item that will contain just five lines:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/sixthHistoryItem.png&#34; alt=&#34;Sixth history item&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-4-recovering-exon-info-and-displaying-data-in-genome-browsers&#34;&gt;2.4. Recovering exon info and displaying data in genome browsers&lt;/h3&gt;

&lt;p&gt;Now we know that in this dataset the five top exons contain between 26 and 63 SNPs. But what else can we learn about these? To know more we need to get back the positional information (coordinates) of these exons. This information was lost at the grouping step and now all we have is just two columns. To get coordinates back we will match the names of exons in dataset #6 (column 1) against names of the exons in the original dataset #1 (column 4). This can be done with &lt;strong&gt;Join, Subtract and Group &amp;#8594; Compare two Queries&lt;/strong&gt; tool (note the settings of the tool in the middle pane):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/compare.png&#34; alt=&#34;Compare&#34; /&gt;&lt;/p&gt;

&lt;p&gt;this adds the seventh dataset to the history:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/seventhHistoryItem.png&#34; alt=&#34;Seventh history item&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The best way to learn about these exons is to look at their genomic surrounding. There is really no better way to do this than using genome browsers. Because this analysis was performed on &amp;ldquo;standard&amp;rdquo; human genome (&lt;code&gt;hg38&lt;/code&gt; in this case), you have two choices - &lt;a href=&#34;http://genomes.ucsc.edu&#34;&gt;UCSC Genome Browser&lt;/a&gt; and &lt;a href=&#34;https://www.broadinstitute.org/igv/&#34;&gt;IGV&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/browsers.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;For example, clicking on &lt;strong&gt;display at UCSC main&lt;/strong&gt; will show something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/ucsc.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;video-1&#34;&gt;Video&lt;/h3&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/185538367&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h2 id=&#34;3-understanding-histories&#34;&gt;3. Understanding histories&lt;/h2&gt;

&lt;p&gt;In Galaxy your analysis steps are represented as a list called &lt;em&gt;History&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/seventhHistoryItem.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Histories can be very large, you can have as many histories as you want, and all history behavior is controlled by the &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-refresh.png&#34; alt=&#34;refresh&#34; /&gt;, &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-cog.png&#34; alt=&#34;cog&#34; /&gt;, and &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-columns.png&#34; alt=&#34;multi_history&#34; /&gt; buttons on the top of the History pane:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxyproject.org/galaxy101/historyDetail.png&#34; alt=&#34;History detail&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-refresh.png&#34; alt=&#34;refresh&#34; /&gt; simply refreshes the history. The &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-cog.png&#34; alt=&#34;cog&#34; /&gt; button gives you access to myriad of history-specific options:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/historyOptions.png&#34; alt=&#34;History options&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Many of the options here are self-explanatory. If you create a new history, your current history does not disappear. If you would like to list all of your histories just choose &lt;strong&gt;Saved Histories&lt;/strong&gt; and you will see a list of all your histories in the center pane:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/historyList.png&#34; alt=&#34;History list&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Yet there is a better way to look for all your histories. This is what the &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-columns.png&#34; alt=&#34;refresh&#34; /&gt; button is for. It allows you to browse and move datasets across histories:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxyproject.org/galaxy101/multiHistoryView.png&#34; alt=&#34;History list&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here, the current history is on the left (&lt;strong&gt;Galaxy 101 (2015)&lt;/strong&gt;) and your (or mine in this case) other histories are displayed to the right of the current history. These can be ordered in a variety of ways by clicking the &lt;strong&gt;&amp;hellip;&lt;/strong&gt; button:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxyproject.org/galaxy101/orderingHistories.png&#34; alt=&#34;History list&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can also scroll sideways using trackpad gestures, move datasets across histories by simply clicking and dragging, and search for histories and individual datasets. This interface also allows you to switch to any existing history (i.e., making it current). Click &lt;strong&gt;Done&lt;/strong&gt; once you&amp;rsquo;re done.&lt;/p&gt;

&lt;p&gt;A comprehensive overview of Galaxy&amp;rsquo;s history functions is found &lt;a href=&#34;https://wiki.galaxyproject.org/Histories&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;4-creating-and-editing-a-workflow&#34;&gt;4. Creating and editing a workflow&lt;/h2&gt;

&lt;h3 id=&#34;4-0-extracting-a-workflow&#34;&gt;4.0. Extracting a workflow&lt;/h3&gt;

&lt;p&gt;Lets take a look at the history again:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/historyCollapsed.png&#34; alt=&#34;Collapsed history&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can see that this history contains all steps of our analysis. So by building this history we have actually created a complete record of our analysis with Galaxy preserving all parameter settings applied at every step. Wouldn&amp;rsquo;t it be nice to just convert this history into a workflow that we&amp;rsquo;ll be able to execute again and again? This can be done by clicking on the &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-cog.png&#34; alt=&#34;cog&#34; /&gt; button and selecting &lt;strong&gt;Extract Workflow&lt;/strong&gt; option:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/extractWorkflow.png&#34; alt=&#34;Extract workflow&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The center pane will change as shown below and you will be able to choose which steps to include/exclude and how to name the newly created workflow. In this case I named it &lt;code&gt;galaxy101-2015&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/createWorkflow.png&#34; alt=&#34;Create workflow&#34; /&gt;&lt;/p&gt;

&lt;p&gt;once you click &lt;strong&gt;Create Workflow&lt;/strong&gt; you will get the following message: &amp;ldquo;Workflow &amp;lsquo;galaxy101-2015&amp;rsquo; created from current history. You can &lt;strong&gt;edit&lt;/strong&gt; or &lt;strong&gt;run&lt;/strong&gt; the workflow&amp;rdquo;.&lt;/p&gt;

&lt;h3 id=&#34;4-1-opening-workflow-editor&#34;&gt;4.1. Opening workflow editor&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s click &lt;strong&gt;edit&lt;/strong&gt; (if you click something else and the message in the center page disappears, you can always access all your workflows including the one you just created using the &lt;strong&gt;Workflow&lt;/strong&gt; link on top of Galaxy interface). This will open Galaxy&amp;rsquo;s workflow editor (to get this view I clicked the arrow at the lower left corner of the screen, which collapsed the tool pane of the Galaxy interface). It will allow you to examine and change settings of this workflow as shown below. Note that the box corresponding to the &lt;strong&gt;Select First&lt;/strong&gt; tool is selected (highlighted with the blueish border) and you can see parameters of this tool on the right pane. This is how you can view and change parameters of all tools involved in the workflow:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/wfEditor.png&#34; alt=&#34;Workflow editor&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;4-2-hiding-intermediate-steps&#34;&gt;4.2. Hiding intermediate steps&lt;/h3&gt;

&lt;p&gt;Among multiple things you can do with workflows I will just mention one. When workflow is executed one is usually interested in the final product and not in the intermediate steps. These steps can be hidden by mousing over a small asterisk in the lower right corner of every tool:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/hideStep.png&#34; alt=&#34;Hide step&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Yet there is a catch. In a newly created workflow all steps are hidden by default and the default behavior of Galaxy is that if all steps of a given workflow are hidden, then nothing gets hidden in the history. This may be counterintuitive, but this is done to decrease the amount of clicking if you do want to hide some steps. So in our case if we want to hide all intermediate steps with the exception of the last one we will click that asterisk in last step of the workflow:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/lastStep.png&#34; alt=&#34;Last step&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Once you do this the representation of the workflow in the bottom right corner of the editor will change with the last step becoming orange. This means that this is the only step, which will generate a dataset visible in the history:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/workflowOverview.png&#34; alt=&#34;Workflow Overview&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;4-3-renaming-inputs&#34;&gt;4.3. Renaming inputs&lt;/h3&gt;

&lt;p&gt;Right now both inputs to the workflow look exactly the same. This is a problem as will be very confusing which input should be &lt;strong&gt;Exons&lt;/strong&gt; and which should be &lt;strong&gt;SNPs&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/namingInputs1.png&#34; alt=&#34;Naming inputs 1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;One the image above you will see that the top input dataset (the one with the blue border) connects to the &lt;strong&gt;Join tool&lt;/strong&gt; first, so it must correspond to the exon data. If you click on this box (in the image above it is already clicked on because it is outlined with the blue border) you will be able to rename the dataset in the right pane:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/renameExons.png&#34; alt=&#34;Rename Exons&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Then click on the second input dataset and rename it &amp;ldquo;Features&amp;rdquo; (this would make this workflow a bit more generic, which will be useful later in this tutorial):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/renameFeatures.png&#34; alt=&#34;Rename features&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;4-4-renaming-outputs&#34;&gt;4.4. Renaming outputs&lt;/h3&gt;

&lt;p&gt;Finally let&amp;rsquo;s rename the workflow&amp;rsquo;s output. For this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;click on the last dataset (&lt;strong&gt;Compare two Queries&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;scroll down the rightmost pane and click on &lt;img src=&#34;http://galaxy.psu.edu/galaxy101/addAction.png&#34; alt=&#34;add action&#34; /&gt;&lt;/li&gt;
&lt;li&gt;Type &lt;code&gt;Top Exons&lt;/code&gt; in the &lt;strong&gt;Rename dataset&lt;/strong&gt; text box:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/topExons.png&#34; alt=&#34;Top exons&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;4-5-setting-parameters-at-runtime&#34;&gt;4.5. Setting parameters &amp;ldquo;at runtime&amp;rdquo;&lt;/h3&gt;

&lt;p&gt;What we are trying to do here is do design a generic workflow. This means that time to time you will need to change parameters within this workflow. For instance, in this tutorial we were selecting 5 exons containing the highest number of SNPs. But what if you need to select 10? Thus it makes sense to leave these types of parameters adjustable. To do this:&lt;/p&gt;

&lt;p&gt;First, select a tool in which you want to set parameters at runtime (&lt;code&gt;Select first&lt;/code&gt; in this case):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/runtimeTool.png&#34; alt=&#34;runtime Tool Selection&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Next, select parameter you would like to set at runtime. To do this just hover over the &lt;img src=&#34;http://galaxy.psu.edu/galaxy101/paramSymbol.png&#34; alt=&#34;paramSymbol&#34; /&gt; icon so it looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/runtimeParam.png&#34; alt=&#34;runtime Param Selection&#34; /&gt;&lt;/p&gt;

&lt;p&gt;and click! Your parameter will now be set at runtime.&lt;/p&gt;

&lt;h3 id=&#34;4-6-save-it-is-important&#34;&gt;4.6. Save! It is important&amp;hellip;&lt;/h3&gt;

&lt;p&gt;Now let&amp;rsquo;s save the changes we&amp;rsquo;ve made by clicking &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-cog.png&#34; alt=&#34;cog&#34; /&gt; and selecting Save:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/wfSave.png&#34; alt=&#34;wfSave&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;5-run-workflow-on-whole-genome-data&#34;&gt;5. Run workflow on whole genome data&lt;/h2&gt;

&lt;p&gt;Now that we have a workflow, let&amp;rsquo;s do something grand like, for example, finding exons with the highest number of repetitive elements across the entire human genome.&lt;/p&gt;

&lt;h3 id=&#34;5-0-create-a-new-history&#34;&gt;5.0. Create a new history&lt;/h3&gt;

&lt;p&gt;First go back into analysis view by clicking &lt;strong&gt;Analyze Data&lt;/strong&gt; on top of the Galaxy&amp;rsquo;s interface. Now let&amp;rsquo;s create a new history by clicking &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-cog.png&#34; alt=&#34;cog&#34; /&gt; and selecting &lt;strong&gt;Create New&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/createNewHistory.png&#34; alt=&#34;Create new history&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;5-1-get-exons&#34;&gt;5.1. Get Exons&lt;/h3&gt;

&lt;p&gt;Now let&amp;rsquo;s get coding exons for the entire genome by going to &lt;strong&gt;Get Data &amp;#8594; UCSC Main&lt;/strong&gt; and setting up parameters as shown below. Note that this time &lt;code&gt;region&lt;/code&gt; radio button is set to &lt;strong&gt;genome&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/getAllGenes.png&#34; alt=&#34;Get all genes&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Click &lt;strong&gt;get output&lt;/strong&gt; and you will get the next page (if it looks different from the image below, go back and make sure &lt;code&gt;output format&lt;/code&gt; is set to &lt;strong&gt;BED - browser extensible format&lt;/strong&gt;):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/ucscGenes2.png&#34; alt=&#34;Get exons&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Choose &lt;strong&gt;Coding exons&lt;/strong&gt; and click &lt;strong&gt;Send query to Galaxy&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&#34;5-2-get-repeats&#34;&gt;5.2. Get Repeats&lt;/h2&gt;

&lt;p&gt;Go again to &lt;strong&gt;Get Data &amp;#8594; UCSC Main&lt;/strong&gt; and make sure the following settings are selected (in particular &lt;code&gt;group&lt;/code&gt; = &lt;strong&gt;Repeats&lt;/strong&gt; and &lt;code&gt;track&lt;/code&gt; = &lt;strong&gt;RepeatMasker&lt;/strong&gt;):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/allRepeats.png&#34; alt=&#34;All repeats&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Click &lt;strong&gt;get output&lt;/strong&gt; and you will get the next page (if it looks different from the image below, go back and make sure &lt;code&gt;output format&lt;/code&gt; is set to &lt;strong&gt;BED - browser extensible format&lt;/strong&gt;):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/allRepeats2.png&#34; alt=&#34;All repeats 2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Select &lt;strong&gt;Whole gene&lt;/strong&gt; and click &lt;strong&gt;Send Query to Galaxy&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&#34;5-3-start-the-workflow&#34;&gt;5.3. Start the Workflow&lt;/h3&gt;

&lt;p&gt;At this point you will have two items in your history - one with exons and one with repeats. These datasets are large (especially repeats) and it will take some time for them to become green. Luckily you do not have to wait as Galaxy will automatically start jobs once uploads have ended. So nothing stops us from starting the workflow we have created. First, click on the &lt;strong&gt;Workflow link&lt;/strong&gt; at the top of Galaxy interface, mouse over &lt;strong&gt;galaxy101-2015&lt;/strong&gt;, click, and select &lt;strong&gt;Run&lt;/strong&gt;. Center pane will change to allow you launching the workflow. Select appropriate datasets for &lt;code&gt;Repeats&lt;/code&gt; and &lt;code&gt;Exon&lt;/code&gt; inputs as shown below. Now scroll to &lt;strong&gt;Step 6&lt;/strong&gt; and will see that we can set up &lt;code&gt;Select first&lt;/code&gt; parameter at &lt;em&gt;Runtime&lt;/em&gt; (meaning Now!). So lets put &lt;code&gt;20&lt;/code&gt; in there (or anything else you want) and scroll further down to click &lt;img src=&#34;http://galaxy.psu.edu/galaxy101/runWorkflowButton.png&#34; alt=&#34;Run workflow&#34; /&gt; to see this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/launchWorkflow.png&#34; alt=&#34;Launch workflow&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Once workflow has started you will initially be able to see all its steps. Note that you are joining all exons with all repeats, so naturally this will take some time:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/launchedWorkflow.png&#34; alt=&#34;Launched workflow&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;5-4-get-coffee&#34;&gt;5.4. Get coffee&lt;/h3&gt;

&lt;p&gt;As we mentioned above this will take some time, so go get coffee. At last you will see this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/final.png&#34; alt=&#34;Final view&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;6-we-did-not-fake-this&#34;&gt;6. We did not fake this:&lt;/h2&gt;

&lt;p&gt;The two histories and the workflow described in this page are accessible directly from this page below:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;History &lt;a href=&#34;https://usegalaxy.org/u/aun1/h/galaxy-101-2015&#34;&gt;&lt;strong&gt;Galaxy 101 (2015)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;History &lt;a href=&#34;https://usegalaxy.org/u/aun1/h/exons-vs-repeats-2015-1&#34;&gt;&lt;strong&gt;Exons vs. Repeats&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Workflow &lt;a href=&#34;https://usegalaxy.org/u/aun1/w/galaxy101-2015-1&#34;&gt;&lt;strong&gt;Galaxy 101-2015&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;From there you can import histories and workflows to make them your own. For example, to import &lt;strong&gt;Galaxy 101 (2015)&lt;/strong&gt; history simply click &lt;a href=&#34;https://usegalaxy.org/u/aun1/h/galaxy-101-2015&#34;&gt;this link&lt;/a&gt; and select &lt;code&gt;Import history&lt;/code&gt; link:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/importHistory.png&#34; alt=&#34;Final view&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;next&#34;&gt;Next&lt;/h1&gt;

&lt;p&gt;We will start using Galaxy to process and map NGS data.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>5. Aligning many sequences quickly</title>
      <link>https://nekrut.github.io/BMMB554/post/topic5/</link>
      <pubDate>Mon, 30 Jan 2017 10:13:02 -0400</pubDate>
      
      <guid>https://nekrut.github.io/BMMB554/post/topic5/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/topic5_cover.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;speeding-things-up&#34;&gt;Speeding things up&lt;/h1&gt;

&lt;p&gt;The topics we discussed in the past lecture explain fundamental concepts behind analysis of biological sequences. Today, we will be talking about algorithms that allow aligning billions of sequencing reads against reference genomes. Similarly to the previous lecture I have borrowed heavily from the &lt;a href=&#34;http://www.langmead-lab.org/teaching-materials/&#34;&gt;course&lt;/a&gt; taught by Ben Langmead at Johns Hopkins. The cover image is from &lt;a href=&#34;https://en.wikipedia.org/wiki/Burrows%E2%80%93Wheeler_transform&#34;&gt;Wikpedia article&lt;/a&gt; on Burrows-Wheeler transform.&lt;/p&gt;

&lt;h2 id=&#34;the-challenge-of-really-large-datasets&#34;&gt;The challenge of really large datasets&lt;/h2&gt;

&lt;p&gt;In the previous lecture we have seen how dynamic programming helps aligning sequences. Unfortunately in reality this approach is not practical for aligning billions of sequencing reads that are routinely generated with NGS technologies.&lt;/p&gt;

&lt;p&gt;If you recall the previous lecture, we were finding alignments using the following approach:&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                             &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \color{red}0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                           T &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1\\
                    \hline
                           A &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 1\\
                    \hline
                           C &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                           G &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3\\
                    \hline
                           C &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 4\\
                    \hline
                           A &amp; 7 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 5 &amp; 4\\
                    \hline
                           G &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 5\\
                    \hline
                           C &amp; 9 &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 6 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 5 &amp; 5

 \end{array}
 $$

&lt;/div&gt;

&lt;p&gt;The performance of this approach expressed as the &lt;a href=&#34;https://en.wikipedia.org/wiki/Big_O_notation&#34;&gt;big O notation&lt;/a&gt; is:&lt;/p&gt;

&lt;p&gt;$\mathcal{O}(mn)$&lt;/p&gt;

&lt;p&gt;where $n$ is the read length and $m$ is the genome length. $m$ can be &lt;strong&gt;very&lt;/strong&gt; large. For instance, in the case of human genome it is $3\times10^9$. On top of that we &lt;em&gt;very many&lt;/em&gt; reads. The latest Illumina HiSeq 2500 machine can produce as much as $6\times10^9$ 100 bp reads. Taking this into account our big O notation becomes:&lt;/p&gt;

&lt;p&gt;$\mathcal{O}(dmn)$&lt;/p&gt;

&lt;p&gt;where $d\times m\times n = 2\times10^{21}$ ($d$ stands for &lt;em&gt;depth&lt;/em&gt;). In other words to compute alignments between a genome and all these reads we need to perform $2\times10^{21}$ cell updates in the dynamic programming matrices even before we start the traceback. On a cluster containing 1,000 3GHz CPUs this will take over &lt;strong&gt;2&lt;/strong&gt; years!&lt;/p&gt;

&lt;h2 id=&#34;mapping-versus-alignment&#34;&gt;Mapping versus alignment&lt;/h2&gt;

&lt;p&gt;One possible idea on how to speed things up will be to first find most likely locations for each read and them refine alignments as necessary. In other words reads should be &lt;em&gt;mapped&lt;/em&gt; by identifying regions of the genomes from which they most likely originate. The term &lt;em&gt;mapping&lt;/em&gt; is sometimes used interchangeably with the word &amp;ldquo;alignment&amp;rdquo;. Yet &lt;em&gt;mapping&lt;/em&gt; and &lt;em&gt;alignment&lt;/em&gt; are somewhat different concepts. &lt;a href=&#34;http://lh3lh3.users.sourceforge.net/&#34;&gt;Heng Li&lt;/a&gt; defines them this way:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mapping&lt;/strong&gt;: assigning a sequencing read to a location within genome. Mapping is said to be correct and it overlaps the true region from which this read has originated.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alignment&lt;/strong&gt;: detailed placement of every base within a read to a corresponding base within the genome. Alignment is said to be correct is every base if placed correctly.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So let&amp;rsquo;s see how we can find potential read locations quickly. Below is a list of key publications highlighting basic principles of current mapping tools:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2009 | How to map billions of short reads onto genomes? - &lt;a href=&#34;http://www.nature.com/nbt/journal/v27/n5/full/nbt0509-455.html&#34;&gt;Trapnell &amp;amp; Salzberg&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2009 | Bowtie 1 - &lt;a href=&#34;http://genomebiology.com/content/10/3/R25&#34;&gt;Langmead et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2012 | Bowtie 2 - &lt;a href=&#34;http://www.nature.com/nmeth/journal/v9/n4/full/nmeth.1923.htm&#34;&gt;Langmead and Salzberg&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2009 | BWA - &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/25/14/1754.long&#34;&gt;Li and Durbin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2010 | BWA - &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/26/5/589&#34;&gt;Li and Durbin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2013 | BWA-MEM - &lt;a href=&#34;http://arxiv.org/abs/1303.3997&#34;&gt;Li&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2014 | Bioinformatics Algorithms - &lt;a href=&#34;http://bioinformaticsalgorithms.com&#34;&gt;Compeau and Pevzner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2014 | Johns Hopkins Computational Genomics Course - &lt;a href=&#34;http://www.langmead-lab.org/teaching-materials/&#34;&gt;Langmead&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;indexing-and-substrings&#34;&gt;Indexing and substrings&lt;/h3&gt;

&lt;p&gt;Indexing is not a new idea. Most books have an index where a word is &lt;em&gt;mapped&lt;/em&gt; back to a page where it is found. This particular type of index is called &lt;em&gt;inverted index&lt;/em&gt;. The word &lt;em&gt;inverted&lt;/em&gt; implies that there is also a non-inverted or &lt;em&gt;forward&lt;/em&gt; index. The image below explain the distinction between the two:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/inverted_index.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Inverted index.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/forward_index.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Forward index. (From &lt;a href=&#34;https://en.wikipedia.org/wiki/Search_engine_indexing&#34;&gt;Wikipedia&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For what we are interested in (searching for the best location of a read in the reference genome) we will use &lt;em&gt;inverted index&lt;/em&gt;. We will refer to it simply as &lt;em&gt;index&lt;/em&gt;. So to find a pattern in a string using an index we first need to create that index. To create an index for a string &lt;em&gt;T&lt;/em&gt; (i.e., a genome) we will need to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;extract substrings of length &lt;em&gt;L&lt;/em&gt; and record where these substrings occur;&lt;/li&gt;
&lt;li&gt;organize the list of substrings and their coordinates and an easily accessible data structure (a &lt;em&gt;map&lt;/em&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/create_index.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;From &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now that we&amp;rsquo;ve created an index for text &lt;em&gt;T&lt;/em&gt; = &lt;code&gt;CGTGCCTACTTACTTACAT&lt;/code&gt; we might as well search it. Suppose we now want to find whether a pattern &lt;code&gt;CTACTTAC&lt;/code&gt; (we will refer to pattern as to &lt;em&gt;P&lt;/em&gt;) is present in &lt;em&gt;T&lt;/em&gt;. To do this we need:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;extract substrings from &lt;em&gt;P&lt;/em&gt;;&lt;/li&gt;
&lt;li&gt;check the index to see if they are present;&lt;/li&gt;
&lt;li&gt;if they are present extend to see if the entire string is matching.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/search_index.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Looking for &lt;em&gt;P&lt;/em&gt; in &lt;em&gt;T&lt;/em&gt;. The first three substrings don&amp;rsquo;t have a match. Image from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the figure above you can see that trying various substrings from &lt;em&gt;P&lt;/em&gt; yields three failures and a success with two hits. Of course in our case the &lt;em&gt;T&lt;/em&gt; is very short and you can easily see that an index for a realistic fragment of DNA can be very large. For example, an index for human chromosome 1 (~249,000,000 nucleotides) will occupy over 12 GB of space. In these cases a practical solution may be skipping some of the substrings while making the index. For instance, including only every 4th substring (i.e., using interval of &lt;em&gt;4&lt;/em&gt;) in a human chromosome 1 index will reduce memory usage to a peak of ~8Gb.&lt;/p&gt;

&lt;p&gt;As one can see finding patterns in text using indexes requires finding values for parameters such as substring length and the interval (if we use skipping). These value have significant implications to the speed of the search, memory use, and , importantly, to specificity. The following table shows how choosing different values for substring length and interval affect speed, memory footprint, and specificity for finding pattern&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGGCGGG
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;within human chromosome 1 (data from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;here&lt;/a&gt;):&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;Substring length&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Interval&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Indexing time (s)&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Search time (s)&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Memory usage (Gb)&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Specificity (%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;59.31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.40&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;~7.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.12&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;63.74&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.06&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;~5.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.26&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;72.52&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.02&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;~3.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.11&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;18&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40.20&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.02&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;~2.1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.37&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19.78&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;~1.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.72&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Specificity can be thought of as a proxy for the number of times an index hit can be extended to a true match between &lt;em&gt;T&lt;/em&gt; and &lt;em&gt;P&lt;/em&gt;. The figure below explain this idea:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/specificity.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Specificity. Matching &lt;code&gt;ord&lt;/code&gt; to &lt;code&gt;time_for_such_a_word&lt;/code&gt;. Image from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;here we look for pattern &lt;code&gt;ord&lt;/code&gt; within text &lt;code&gt;time_for_such_a_word&lt;/code&gt;. The first index hit does not produce a match, while the second does. Decreasing the number of fruitless hits increases specificity and speeds up the search. Intuitively, this is achieved by increasing the substring length.&lt;/p&gt;

&lt;p&gt;In summary, we have seen that we can create an index (a map) containing coordinates of substrings from a text &lt;em&gt;T&lt;/em&gt;. We can then use this map to find occurrences (if they exist) of pattern &lt;em&gt;P&lt;/em&gt; within the &lt;em&gt;T&lt;/em&gt;. The map can be represented in variety of ways including sorted lists, hash tables, and trees:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/sorted_list.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Sorted list&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/hash.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hash&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/trie.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Trie&lt;/p&gt;

&lt;p&gt;Sorted list (top), Hash (middle), and Trie (bottom). From &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Trie#/media/File:Trie_example.svg&#34;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;What&amp;rsquo;s important here is that sorted lists and especially hash tables provide a quick way to find the initial hit, but they are limited by the choice of the substring size. We&amp;rsquo;ve seen before (the &lt;em&gt;Specificity&lt;/em&gt; table above) that the choice of substring size will have profound effects on the performance of the search. Would it be nice if we would not need to make that choice. For this we will continue to &lt;em&gt;Tries and Trees&lt;/em&gt; below.&lt;/p&gt;

&lt;h3 id=&#34;tries-and-trees&#34;&gt;Tries and trees&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s consider text &lt;em&gt;T&lt;/em&gt; = &lt;code&gt;gtccacctagtaccatttgt&lt;/code&gt;. Using the logic from previous section we can build an index using substrings of length 2 with interval 2 (skipping every other substring) that would look like this after sorting:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Substring&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Offset&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;ac&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;ag&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;at&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;14&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;cc&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;12&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;cc&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;ct&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;gt&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;18&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;gt&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;ta&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;tt&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;16&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Representing this sorted list as a &lt;em&gt;trie&lt;/em&gt; that would map substrings to their positions (offsets) will look like this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/substring_trie.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A trie. Example from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Note that this &lt;em&gt;trie&lt;/em&gt; is the smallest tree (&lt;a href=&#34;http://stackoverflow.com/questions/4737904/difference-between-tries-and-trees&#34;&gt;&lt;em&gt;trie&lt;/em&gt; versus &lt;em&gt;tree&lt;/em&gt;&lt;/a&gt; is indeed a bit confusing) representing a collection of substrings that has the following properties:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Each edge is labeled with a character from a given alphabet (in this case &lt;code&gt;A&lt;/code&gt;, &lt;code&gt;C&lt;/code&gt;, &lt;code&gt;G&lt;/code&gt;, and &lt;code&gt;T&lt;/code&gt;);&lt;/li&gt;
&lt;li&gt;Each node has a single outgoing edge corresponding to an alphabet character;&lt;/li&gt;
&lt;li&gt;Each &lt;em&gt;key&lt;/em&gt; (substrings of length 2 in the above case) is spelled out along a path starting at the root.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While the above example shows how we can quickly find positions for a given substring, it still relies on a fixed substring length. To see how we can deal with this limitation let&amp;rsquo;s introduce the idea of indexing with &lt;em&gt;suffixes&lt;/em&gt; rather than with fixed substrings. Consider the following text &lt;em&gt;T&lt;/em&gt; = &lt;code&gt;GTTATAGCTGATCGCGGCGTAGCGG&lt;/code&gt;. Let&amp;rsquo;s add a special symbol &lt;code&gt;$&lt;/code&gt; to the end of this text. For &lt;em&gt;T$&lt;/em&gt; a list of all substrings will look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GTTATAGCTGATCGCGGCGTAGCGG$
 TTATAGCTGATCGCGGCGTAGCGG$
  TATAGCTGATCGCGGCGTAGCGG$
   ATAGCTGATCGCGGCGTAGCGG$
    TAGCTGATCGCGGCGTAGCGG$
     AGCTGATCGCGGCGTAGCGG$
      GCTGATCGCGGCGTAGCGG$
       CTGATCGCGGCGTAGCGG$
        TGATCGCGGCGTAGCGG$
         GATCGCGGCGTAGCGG$
          ATCGCGGCGTAGCGG$
           TCGCGGCGTAGCGG$
            CGCGGCGTAGCGG$
             GCGGCGTAGCGG$
              CGGCGTAGCGG$
               GGCGTAGCGG$
                GCGTAGCGG$
                 CGTAGCGG$
                  GTAGCGG$
                   TAGCGG$
                    AGCGG$
                     GCGG$
                      CGG$
                       GG$
                        G$
                         $
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Recall that a trie has the following properties:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Each edge is labeled with a character from a given alphabet;&lt;/li&gt;
&lt;li&gt;Each node has a single outgoing edge corresponding to an alphabet character;&lt;/li&gt;
&lt;li&gt;Each substring (in this case a suffix) is spelled out along a path starting at the root.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let&amp;rsquo;s now use these rules to build a suffix trie for a much simpler text &lt;em&gt;T&lt;/em&gt; = &lt;code&gt;abaaba&lt;/code&gt;. It is much smaller than the text we used above and so it will be easier to get the point across. First, let&amp;rsquo;s add &lt;code&gt;$&lt;/code&gt; and create a list of all suffixes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;abaaba$
 baaba$
  aaba$
   aba$
    ba$
     a$
      $
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;now let&amp;rsquo;s create a trie:&lt;/p&gt;

&lt;h3 id=&#34;looking-for-substrings-in-a-trie&#34;&gt;Looking for substrings in a Trie&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The green path shows the longest suffix (the entire thing). The blue path is the shortest suffix containing only the terminal character.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/trie_no_end.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Note, that the trie would look &lt;strong&gt;dramatically&lt;/strong&gt; different had we not added the &lt;code&gt;$&lt;/code&gt; at the end. The difference is that without the &lt;code&gt;$&lt;/code&gt; the trie will &lt;strong&gt;not&lt;/strong&gt; have every suffix to be represented by a path from &lt;code&gt;root&lt;/code&gt; to a leaf.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In suffix trie every edge is labeled with a single character and nodes have no labels in our representation. However, you can think of every node as being labeled with a string that spells out all characters occurring along a path from the root up to the that node. For example, the blue node &lt;code&gt;baa&lt;/code&gt; spells out characters &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt;, and &lt;code&gt;a&lt;/code&gt; along a path from the root.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Suffix trie is an ideal data stricture to quickly check if a pattern is or is not present in a text. The following three examples highlight how this can be done. Suppose we want to check if a substring &lt;code&gt;baa&lt;/code&gt; is present within text &lt;code&gt;abaaba&lt;/code&gt; represented as our suffix trie. We start at the root and take an edge labeled with &lt;code&gt;b&lt;/code&gt;. We next proceed through an edge labeled &lt;code&gt;a&lt;/code&gt;. At this point there are two outgoing edges: &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;$&lt;/code&gt;. Since the last character in &lt;code&gt;baa&lt;/code&gt; is &lt;code&gt;a&lt;/code&gt; we take the edge labeled as &lt;code&gt;a&lt;/code&gt;. Because the entire substring &lt;code&gt;baa&lt;/code&gt; can be spelled out as a path from the root we conclude that &lt;code&gt;baa&lt;/code&gt; is indeed a substring of &lt;code&gt;abaaba&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now let&amp;rsquo;s do the same for &lt;code&gt;abaaba&lt;/code&gt;. Proceeding along the green path spells out all characters. Again, we conclude that &lt;code&gt;abaaba&lt;/code&gt; is valid substring. |&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But for &lt;code&gt;baabb&lt;/code&gt; things look different. We proceed successfully (red path) through &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt;, and &lt;code&gt;b&lt;/code&gt;. However, there is no edge labeled &lt;code&gt;b&lt;/code&gt; at &lt;code&gt;baab&lt;/code&gt; node. Thus we fall off and conclude that &lt;code&gt;baabb&lt;/code&gt; is &lt;strong&gt;not&lt;/strong&gt; a substring of &lt;code&gt;abaaba&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_6.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We can also use suffix trie to check if a string is a suffix of a text. You can see that &lt;code&gt;baa&lt;/code&gt; is &lt;strong&gt;not&lt;/strong&gt; a suffix. This is because although it is valid substring, which traces a path through the trie, such path does not with an outgoing edge labeled with &lt;code&gt;$&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_7.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here &lt;code&gt;aba&lt;/code&gt; is a suffix because one of the outgoing edges from the final node is labeled with &lt;code&gt;$&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_8.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Another useful feature of suffix trie is the ability to tell how many times a particular substring if found in a text. Here &lt;code&gt;aba&lt;/code&gt; is found twice as the last edge of a path spelling &lt;code&gt;aba&lt;/code&gt; leads to a node (&lt;code&gt;n&lt;/code&gt;) with two outgoing edges.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_9.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Finally, similar logic allows to find the longest repeated substrings within a text. A deepest (furthest from the root) node with multiple outgoing edges wound point to a repetitive substring. Here &lt;code&gt;aba&lt;/code&gt; is the longest repeated substring of &lt;code&gt;abaaba&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Now that we explained how suffix tries can be used to find substrings in text, let&amp;rsquo;s reduce non-branching paths in tries and convert them to trees:&lt;/p&gt;

&lt;h3 id=&#34;from-a-trie-to-a-tree&#34;&gt;From a Trie to a Tree&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If we collapse all non-branching paths and concatenate their labels we will get:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_tree_1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now, let&amp;rsquo;s label every leaf of the tree with offset (position in the text) of the corresponding suffix:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_tree_2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Collapsing non-branching paths has given us a somewhat more compact data structure. Now see how we can use this data structure.&lt;/p&gt;

&lt;h3 id=&#34;looking-for-substrings-in-a-tree&#34;&gt;Looking for substrings in a Tree&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_tree_3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Checking the above suffix tree to see if &lt;code&gt;baa&lt;/code&gt; is a substring of the text. The logic is exactly the same as with suffix tries, except we now have to account for the fact that along some edges only a portion of the characters within a label will match. In this case matching characters are highlighted with uppercase: &lt;code&gt;BA&lt;/code&gt; matches along the first edge along the blue path, and only &lt;code&gt;A&lt;/code&gt; matches along the second edge. The conclusion is that &lt;code&gt;baa&lt;/code&gt; is a substring of the text.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_tree_4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now let&amp;rsquo;s see if &lt;code&gt;aba&lt;/code&gt; is a suffix of our text. It matches along the blue path and the last node along this path has an outgoing edge labeled with &lt;code&gt;$&lt;/code&gt;. Thus it is a suffix.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_tree_5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And just like with suffix tries we can count occurrences of a substring by counting the number of outgoing edges from the last node.&lt;/p&gt;

&lt;h3 id=&#34;application-of-suffix-trees&#34;&gt;Application of suffix trees&lt;/h3&gt;

&lt;p&gt;One of the common applications of suffix trees to the genome data analysis is finding (longest) common subsequences between two sequences. &lt;a href=&#34;http://mummer.sourceforge.net/manual/&#34;&gt;MUMMER&lt;/a&gt; implements this approach. The following plot shows a comparison between &lt;em&gt;E. coli&lt;/em&gt; K12 and APEC O1 strains. It is computed in 8 seconds using approximately 10 Mb of RAM (K12 and APEC O1 genomes are 4.5 and 4.9. Mb, respectively).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/mum.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To find longest common subsequences a suffix tree can be constructed from both sequences at once as shown in the following slide from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/suffix_trees.pdf&#34;&gt;Ben Langmead&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/lcs.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;While suffix trees allow sequence comparisons to be performed in nearly linear time, they have large memory footprint. At some point this becomes a serious limitation making the use of suffix trees impractical. For example, indexing human genome will require ~47 Gb of memory.&lt;/p&gt;

&lt;h3 id=&#34;suffix-arrays&#34;&gt;Suffix arrays&lt;/h3&gt;

&lt;p&gt;Suffix array offers a more compact solution to representing test suffixes. It specified a lexicographic ordering of suffixes derived from text &lt;em&gt;T&lt;/em&gt;$:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/sa.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A suffix array. Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Because one does not need additional pointers required for tree representation, the suffix array (SA) has a significantly smaller memory footprint. For example, SA for human genome will occupy ~12Gb (down from 47Gb required for a suffix tree). Yet there is an even better idea.&lt;/p&gt;

&lt;h2 id=&#34;burrows-wheeler-transform-and-fm-index&#34;&gt;Burrows-Wheeler Transform and FM index&lt;/h2&gt;

&lt;p&gt;Burrows-Wheeler (BW) transform is a reversible permutation of a string. For example, for a string:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;abaaba$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;create all rotations:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$abaaba
a$abaab
ba$abaa
aba$aba
aaba$ab
baaba$a
abaaba$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;sort them lexicographically with &lt;code&gt;$&lt;/code&gt; as first character:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$abaaba
a$abaab
aaba$ab
aba$aba
abaaba$
ba$abaa
baaba$a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;take the last column. It will be the BWT of the original string &lt;code&gt;abaaba$&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;abba$aa
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Below is the entire procedure as one slide:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bw.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Burrows-Wheeler transform. Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;video&#34;&gt;Video&lt;/h4&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/184566773&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;It has three important features that make it ideas for creating searchable compact representations of genomic data:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;It can be compressed&lt;/li&gt;
&lt;li&gt;It can be reversed to reconstruct the original string&lt;/li&gt;
&lt;li&gt;It can be used as an index&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;lf-mapping-of-burrows-wheeler-matrix-bwm&#34;&gt;LF mapping of Burrows-Wheeler Matrix (BWM)&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s take the original string &lt;code&gt;abaaba&lt;/code&gt; add &lt;code&gt;$&lt;/code&gt; and list charters ranks:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;strong&gt;b&lt;/strong&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;2&lt;/sub&gt;&lt;strong&gt;b&lt;/strong&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;3&lt;/sub&gt;$&lt;/p&gt;

&lt;p&gt;This ranking is done based on the order of the characters in the text (T-ranking). The order of ranked characters is preserved between the first column (F) and the last column (L):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/lf_a.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;LF mapping: &lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;s&lt;/sub&gt; has the same order in F and L&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/lf_b.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;LF mapping: &lt;strong&gt;b&lt;/strong&gt;&lt;sub&gt;s&lt;/sub&gt; has the same order in F and L&lt;/p&gt;

&lt;p&gt;Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let&amp;rsquo;s now rank characters in order of their appearance in the sorted list of rotations (B-ranking):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bw_b_rank.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Burrows-Wheeler transform with B-rankings. Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Look at the A very important implication of this is that we can quickly jump from L to F:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/f_from_l.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;L/F jumping. Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;video-1&#34;&gt;Video&lt;/h4&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/184569791&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;reversing-btw&#34;&gt;Reversing BTW&lt;/h3&gt;

&lt;p&gt;Because of the LF mapping property was can also easily reconstruct original text from its BWT:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_rev.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_rev2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Reversing BWT. Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;video-2&#34;&gt;Video&lt;/h4&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/184568361&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;searching-bwt&#34;&gt;Searching BWT&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s try to find is the string &lt;code&gt;aba&lt;/code&gt; is present in a &amp;ldquo;genome&amp;rdquo; stored as a BWT.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We start with suffix of $ab\color{red}a$ shown in red. This gives us a range of characters in the F column (all &lt;strong&gt;a&lt;/strong&gt;s)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_q1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We now extend to $a\color{red}{ba}$ and see how many of &lt;strong&gt;a&lt;/strong&gt;s have preceding &lt;strong&gt;b&lt;/strong&gt;s:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_q2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Finally we extend to the entire string $\color{red}{aba}$:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_q3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This tells us the range [3,5) but, as opposed to suffix array, this does not tell us where these matches occur in the actual sequence. We will come back to this problem shortly.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_q4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The shide below shows what happens when a match is &lt;strong&gt;not&lt;/strong&gt; present in the &amp;ldquo;genome&amp;rdquo;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_q5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Querying BWT. Images from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/bwt_and_fm_index.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;video-3&#34;&gt;Video&lt;/h4&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/184568259&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;practicalities-of-using-bwt&#34;&gt;Practicalities of using BWT&lt;/h3&gt;

&lt;p&gt;As we have seen BWT is &lt;strong&gt;very&lt;/strong&gt; compact but has few shortcomings such as, for example, the difficulty is seeing where the matches are in the actual genome as well as some performance limitations. Combining BWT with auxiliary data structures creates &lt;a href=&#34;https://en.wikipedia.org/wiki/FM-index&#34;&gt;FM-index&lt;/a&gt; (where FM stands for Full-text index in Minute space; curiously, the names of FM-index creators are &lt;a href=&#34;http://dl.acm.org/citation.cfm?id=796543&#34;&gt;Ferrigina and Manzini&lt;/a&gt;). The components of FM-index used for aligning reads to a genome are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  BWT               Tally        Check    
                                 points 

  F       L         a b          a b       SA    
  ---------        -----        -----     ----       
  $ abaab a         1 0          1 0       6 $
  a $abaa b         1 1                    5 a$
  a aba$a b         1 2                    2 aaba$
  a ba$ab a         2 2          2 2       3 aba$
  a baaba $         2 2                    0 abaaba$
&amp;gt; b a$aba a         3 2                    4 ba$
  b aaba$ a         4 2          4 2       1 baaba$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Where:&lt;/p&gt;

&lt;h4 id=&#34;bwt&#34;&gt;BWT&lt;/h4&gt;

&lt;p&gt;BWT - the BWT (L column from above) is stored and the first column (F) can be easily reconstructed as it is simply a list of all characters (4 in the case of DNA) and their counts.&lt;/p&gt;

&lt;h4 id=&#34;tally&#34;&gt;Tally&lt;/h4&gt;

&lt;p&gt;Because we do not explicitly store ranks they can simply be obtained by counting occurrences of individual characters from the top of L column. Yet this is computationally expensive. Instead we store a tally table. At every row of the BWT matrix it shows how many times each character has been seen up to this point. For example at row marked with &lt;code&gt;&amp;gt;&lt;/code&gt; there were 3 As and 2 Bs up to this point. In reality, to save space, only a subset of Tally entries is stored as &lt;em&gt;Checkpoints&lt;/em&gt; recorded in regular intervals as shown above.&lt;/p&gt;

&lt;h4 id=&#34;sa-sample&#34;&gt;SA Sample&lt;/h4&gt;

&lt;p&gt;Finally, to find coordinates of matches in the genome offsets from an SA index are stored as SA sample (actual suffixes are not stored). This allows quickly finding location of a match within the genome by a direct look up. Similarly to Checkpoints only a fraction of these is stored to save space.&lt;/p&gt;

&lt;p&gt;Thus the final list of components is:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;First column = integers corresponding to character type counts. In case of DNA four integers: number of As, Cs, Gs, and Ts.&lt;/li&gt;
&lt;li&gt;Last column = the BWT transform. Size is equal to the length of the original text&lt;/li&gt;
&lt;li&gt;Checkpoints = length of text $\times$ number of character types  $\times$ sampling fraction (how sparse rows are sampled)&lt;/li&gt;
&lt;li&gt;SA sample = length of text $\times$ fraction of the rows kept&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For human genome with DNA alphabet of four nucleotides, saving checkpoint every 128&lt;sup&gt;th&lt;/sup&gt; row, and saving SA offsets every 32&lt;sup&gt;nd&lt;/sup&gt; row we will have:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;First column = 16 bytes&lt;/li&gt;
&lt;li&gt;Last column = 2bit $\times$ 3 billion characters = 750 MB&lt;/li&gt;
&lt;li&gt;Checkpoints = 3 billion $\times$ 4 bytes/char / 128 &amp;#x2248; 100 MB&lt;/li&gt;
&lt;li&gt;SA sample = 3 billion $\times$ 4 bytes/char /32 &amp;#x2248; 400 MB&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;next&#34;&gt;Next&lt;/h2&gt;

&lt;p&gt;We will start pitting these ideas into practice.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>4. Aligning sequences with dynamic programming</title>
      <link>https://nekrut.github.io/BMMB554/post/topic4/</link>
      <pubDate>Wed, 25 Jan 2017 11:12:04 -0400</pubDate>
      
      <guid>https://nekrut.github.io/BMMB554/post/topic4/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/topic4_cover.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;sequence-alignment&#34;&gt;Sequence alignment&lt;/h1&gt;

&lt;p&gt;In the previous lecture we have seen the principle behind dynamic programming. This approach is extremely useful for comparing biological sequences, which is coincidentally one of the main points of this course. This lecture explain how this is done. In writing this text I heavily relied on wonderful &lt;a href=&#34;http://www.langmead-lab.org/teaching-materials/&#34;&gt;course&lt;/a&gt; taught by Ben Langmead at Johns Hopkins. The cover image shows pairwise alignments for human, mouse, and dog &lt;em&gt;KIF3&lt;/em&gt; locus from &lt;a href=&#34;http://genome.cshlp.org/content/10/9/1304.long&#34;&gt;Dubchak et al. 2000&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;how-different-are-two-sequences&#34;&gt;How different are two sequences?&lt;/h2&gt;

&lt;p&gt;Suppose you have two sequences of the same length:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A C A T G C C T A
A C T G C C T A C
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;How different are they? In other words, how many bases should be change to turn one sequence onto the other:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A C A T G C C T A
| | * * * | * * *
A C T G C C T A C
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;the vertical lines above indicate positions that are identical between the two sequences, while asterisks show differences. It will take six substitutions to turn one sequence into the other. This number &amp;ndash; six substitutions &amp;ndash; is called &lt;a href=&#34;https://en.wikipedia.org/wiki/Hamming_distance&#34;&gt;&lt;em&gt;Hamming distance&lt;/em&gt;&lt;/a&gt; or the &lt;em&gt;minimal&lt;/em&gt; number of substitutions required to turn one string into another. The code below computes the Hamming distance. Try it. You can change &lt;code&gt;seq1&lt;/code&gt; and &lt;code&gt;seq2&lt;/code&gt; into whatever you want except that they should have the same length.&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/99a02b790a?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Now in addition to &lt;em&gt;substitutions&lt;/em&gt; (i.e., changing one character into another) let&amp;rsquo;s allow &lt;strong&gt;instertions&lt;/strong&gt; and &lt;strong&gt;deletions&lt;/strong&gt;. This will essentially allow us to insert dashes (gaps) between characters:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A C A T G C C T A -
| | * | | | | | | *
A C - T G C C T A C
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this case the &lt;a href=&#34;https://en.wikipedia.org/wiki/Edit_distance&#34;&gt;&lt;strong&gt;edit distance&lt;/strong&gt;&lt;/a&gt; between two sequences is 2. It is defined as the minimum number of operations (substitutions, insertions, and deletions) requited to turn one string into another. The compared strings do not have to be of the same length to be able to compute the edit distance as we can compensate for length differences using deletions and insertions. While the situation above (where we inserted two dashes) is biologically much more meaningful (and realistic), it is much more difficult to find.&lt;/p&gt;

&lt;h1 id=&#34;generalizing-the-problem&#34;&gt;Generalizing the problem&lt;/h1&gt;

&lt;p&gt;Before we can develop an algorithm that will help us to compute the edit distance let&amp;rsquo;s develop a general framework that would allow us to think about the problem in exact terms. Let&amp;rsquo;s look at a pair of VERY long sequences. So long, that we do not even see the left end &amp;ndash; it disappears into $\infty$:&lt;/p&gt;

&lt;div&gt;
    $$
        \color{red}{\texttt{.....A C T G C C T A}}\texttt{ G}\\
        \color{red}{\texttt{.....A C T G C C T A}}\texttt{ C}\\
    $$
&lt;/div&gt;

&lt;p&gt;the red parts of the two sequences represent &lt;strong&gt;prefixes&lt;/strong&gt; for the last nucleotides shown in black. Let&amp;rsquo;s assume that the edit distance between the two prefixes is known (don&amp;rsquo;t ask how we know, we just do). For simplicity let&amp;rsquo;s &amp;ldquo;compact&amp;rdquo; the prefix of the first sequence into $\alpha$ and the prefix of the second sequence into $\beta$:&lt;/p&gt;

&lt;div&gt;
    $$
        \alpha \texttt{G}\\
        \beta  \texttt{C}
    $$
&lt;/div&gt;

&lt;p&gt;again, the edit distance between $\alpha$ and $\beta$ is known to us. The three possibilities for computing the edit distance between $\alpha G$ and $\beta C$ are:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\alpha\texttt{G},\beta\texttt{C})  = min\begin{cases} 
                    Edit\ Distance(\alpha,\beta) + 1 \leftarrow\ because\ they\ do\ not\ match&amp; \\
                    Edit\ Distance(\alpha\texttt{G},\beta) + 1 \leftarrow\ because\ we\ are\ adding\ a\ gap&amp; \\
                    Edit\ Distance(\alpha,\beta\texttt{C}) + 1 \leftarrow\ because\ we\ are\ adding\ a\ gap
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;but we not always have $\texttt{G}$ and $\texttt{C}$ as two last nucleotiodes, so for the general case:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\alpha\texttt{x},\beta\texttt{y}) = min\begin{cases} 
                    Edit\ Distance(\alpha,\beta) + \delta(x,y) &amp; \\
                    Edit\ Distance(\alpha\texttt{x},\beta) + 1 &amp; \\
                    Edit\ Distance(\alpha,\beta\texttt{y}) + 1
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;where $\delta(x,y) = 0$ if $x = y$ (nucleotides match) and $\delta(x,y) = 1$ if $x \neq y$ (nucleotides do not match). The $\delta(x,y)$ has a particular meaning. If the two nucleotides at the end are equal to each other, there is nothing to be done &amp;ndash; no substitution operation is necessary. If a substitution is necessary however, we will record this by adding 1. When we will be talking about global and local alignment below the power of $\delta(x,y)$ will become even more clear.&lt;/p&gt;

&lt;p&gt;Recall the change problem from the previous lecture. We can write an algorithm that would exhaustively evaluate the above expression for all possible suffixes. This algorithm is below. Try executing it. It will take roughly ~30 seconds to find the edit distance between the two sequences used in the beginning of this lecture:&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/eff3a798bf?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Again, don&amp;rsquo;t worry if Python looks scary to you. The take-home-message here is that it takes a very long time to compute the edit distance between two sequences that are only &lt;strong&gt;nine&lt;/strong&gt; nucleotides long! Why is this happening? Figure 1 below shows a small subset of situations the algorithm is evaluating for two very short strings $\texttt{TAG}$ and $\texttt{TAC}$:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/editDist.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 1&lt;/strong&gt; | A fraction of situations evaluated by the nave algorithm for computing the edit distance. Just like in the case of the change problem discussed in the previous lecture a lot of time is wasted on computing distances between suffixes that has been seen more than once (shown in red).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To understand the magnitude of this problem let&amp;rsquo;s look at slightly modified version of the previous Python code below. All we do here is keeping track how many times a particular pair of suffixes (in this case $\texttt{AC}$ and $\texttt{AC}$) are seen by the program. The number is staggering: 48,639. So this algorithm is &lt;strong&gt;extremely&lt;/strong&gt; wasteful.&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/8994bfe46e?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;While this approach to the edit distance problem is correct, it will hardly help us on the genome-wide scale. Just like in case of the change problem and Manhattan tourist problem dynamic programming is going to save the day.&lt;/p&gt;

&lt;h2 id=&#34;video&#34;&gt;Video&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/183583352&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;hr /&gt;

&lt;h1 id=&#34;dynamic-programming-to-the-rescue&#34;&gt;Dynamic programming to the rescue&lt;/h1&gt;

&lt;p&gt;Let&amp;rsquo;s recall Manhattan tourist problem. The objective of the problem was to find a path through Manhattan that visits the highest number of landmarks. If you remember, we represented Manhattan as a matrix where each edge was representing a block and was labeled with the number of landmarks within that block. Here, we will use a similar idea to find an optimal &lt;strong&gt;alignment&lt;/strong&gt; between two sequences. Note that so far this is the first time we use the term &lt;strong&gt;alignment&lt;/strong&gt; in this section. It turns out that in order to find the alignment we first need to learn how to compute edit distances between sequences efficiently. So, suppose we have two sequences that deliberately have different lengths:&lt;/p&gt;

&lt;p&gt;$\texttt{G C T A T A C}$&lt;/p&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;p&gt;$\texttt{G C G T A T G C}$&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s represent them as the following matrix where the first character $\epsilon$ represents an empty string:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon\\
                    \hline
                    G\\
                    \hline
                    C\\
                    \hline
                    G\\
                    \hline
                    T\\
                    \hline
                    A\\
                    \hline
                    T\\
                    \hline
                    G\\
                    \hline
                    C

 \end{array}

  \\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;Let&amp;rsquo;s fill the first column and first raw of the matrix. Because the distance between a string and an empty string is equal to the length of the string (e.g., a distance between string $\texttt{TCG}$ and an empty string is 3) this resulting matrix will look like this:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                    G &amp; 1\\
                    \hline
                    C &amp; 2\\
                    \hline
                    G &amp; 3\\
                    \hline
                    T &amp; 4\\
                    \hline
                    A &amp; 5\\
                    \hline
                    T &amp; 6\\
                    \hline
                    G &amp; 7\\
                    \hline
                    C &amp; 8

 \end{array}

  \\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;Now, let&amp;rsquo;s fill in the cell between $\texttt{G}$ and $\texttt{G}$. Recall that:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\alpha\texttt{x},\beta\texttt{y}) = min\begin{cases} 
                    \color{red}{Edit\ Distance(\alpha,\beta) + \delta(x,y)} &amp; \\
                    \color{blue}{Edit\ Distance(\alpha\texttt{x},\beta) + 1} &amp; \\
                    \color{green}{Edit\ Distance(\alpha,\beta\texttt{y}) + 1}
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;where $\delta(x,y) = 0$ if $x = y$ and $\delta(x,y) = 1$ if $x \neq y$. And now let&amp;rsquo;s color each of the cells corresponding to each part of the above expression:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; \color{red}0 &amp; \color{green}1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                    G &amp; \color{blue}1\\
                    \hline
                    C &amp; 2\\
                    \hline
                    G &amp; 3\\
                    \hline
                    T &amp; 4\\
                    \hline
                    A &amp; 5\\
                    \hline
                    T &amp; 6\\
                    \hline
                    G &amp; 7\\
                    \hline
                    C &amp; 8

 \end{array}

  \\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;In this specific case:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\epsilon\texttt{G},\epsilon\texttt{G}) = min\begin{cases} 
                    \color{red}{Edit\ Distance(\epsilon,\epsilon) + \delta(G,G)\ or\ 0\ +\ 0\ =\ 0} &amp; \\
                    \color{blue}{Edit\ Distance(\epsilon\texttt{G},\epsilon) + 1\ or\ 1\ +\ 1\ =\ 2} &amp; \\
                    \color{green}{Edit\ Distance(\epsilon,\epsilon\texttt{G}) + 1\ or\ 1\ +\ 1\ =\ 2}
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;This minimum of 0, 2, and 2 will be 0, so we are putting zero into that cell:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C \\
                    \hline
                    \epsilon &amp; \color{red}0 &amp; \color{green}1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                    G &amp; \color{blue}1 &amp; \color{red}0\\
                    \hline
                    C &amp; 2\\
                    \hline
                    G &amp; 3\\
                    \hline
                    T &amp; 4\\
                    \hline
                    A &amp; 5\\
                    \hline
                    T &amp; 6\\
                    \hline
                    G &amp; 7\\
                    \hline
                    C &amp; 8

 \end{array}

 \\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;Using this uncomplicated logic we can fill the entire matrix like this:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                           G &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6\\
                    \hline
                           C &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           G &amp; 3 &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           T &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3 &amp; 4\\
                    \hline
                           A &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3\\
                    \hline
                           G &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           C &amp; 8 &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; \color{red}2

 \end{array}

 \\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;The lower rightmost cell highlighted in red is special. It contains the value for the edit distance between the two strings. The following Python script implements this idea. You can see that it is essentially instantaneous:&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python3/1bec8f9150?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;h2 id=&#34;video-1&#34;&gt;Video&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/183583042&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;hr /&gt;

&lt;h1 id=&#34;from-edit-distance-to-alignment&#34;&gt;From edit distance to alignment&lt;/h1&gt;

&lt;p&gt;In the previous section we have filled the dynamic programming matrix to find out that the edit distance between the sequences is 2. But in biological applications we are most often interested not in edit distance &lt;em&gt;per se&lt;/em&gt; but in the actual &lt;strong&gt;alignment&lt;/strong&gt; between two sequences.&lt;/p&gt;

&lt;h2 id=&#34;the-traceback&#34;&gt;The traceback&lt;/h2&gt;

&lt;p&gt;We can use the dynamic programming matrix to reconstruct the alignment. This is done using &lt;strong&gt;traceback&lt;/strong&gt; procedure. Let&amp;rsquo;s look at the rightmost bottom cell of the matrix highlighted in &lt;strong&gt;bold&lt;/strong&gt;:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                           G &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6\\
                    \hline
                           C &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           G &amp; 3 &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           T &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3 &amp; 4\\
                    \hline
                           A &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3\\
                    \hline
                           G &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           C &amp; 8 &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; \textbf{2}

 \end{array}

    $$
&lt;/div&gt;

&lt;p&gt;When we were filling this matrix did we come to this point from above ($\color{green}3$), from the left ($\color{blue}3$), or diagonally ($\color{red}2$):&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ | c | c }
                \hline
                   \color{red}2 &amp; \color{green}3\\
                \hline
                   \color{blue}3 &amp; \textbf{2}
    \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Remembering the fact that when filling the matrix we are trying to minimize the expression for edit distance, we clearly arrived to this point diagonally from $\color{red}2$. This because arriving from top ($\color{green}3$) or left ($\color{blue}3$) would add 1. So we highlight diagonal cell in red:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                           G &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6\\
                    \hline
                           C &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           G &amp; 3 &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           T &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3 &amp; 4\\
                    \hline
                           A &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3\\
                    \hline
                           G &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}2 &amp; 3\\
                    \hline
                           C &amp; 8 &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; \color{red}2

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Continuing this idea we will draw a trace like the one below until we hit an interesting point:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                           G &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6\\
                    \hline
                           C &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           G &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           T &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 3 &amp; 4\\
                    \hline
                           A &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3\\
                    \hline
                           G &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}2 &amp; 3\\
                    \hline
                           C &amp; 8 &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; \color{red}2

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;At this point we have arrived to this value from the top because 0 + 1 = 1. If we were arriving diagonally it would be 1 + 1 = 2 since $\texttt{G}\ \neq\ \texttt{C}$, so we are turning traceback upward and then again diagonally:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; \color{red}0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                           G &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6\\
                    \hline
                           C &amp; 2 &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           G &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           T &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 3 &amp; 4\\
                    \hline
                           A &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3\\
                    \hline
                           G &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}2 &amp; 3\\
                    \hline
                           C &amp; 8 &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; \color{red}2

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Now going through traceback line from the top we are getting the following alignment between two two sequences:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;G C - T A T A C
| | * | | | * |
G C G T A T G C
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;approximate-matching&#34;&gt;Approximate matching&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s now get a bit more practical. In many real biological applications we are trying to see if one sequence is contained within another. So, how can we use dynamic programming to find if there is an approximate match between two sequences $\it\texttt{P}$ and $\texttt{T}$?&lt;/p&gt;

&lt;p&gt;Suppose we have two strings:&lt;/p&gt;

&lt;p&gt;$\it{T} = \texttt{A A C C C T A T G T C A T G C C T T G G A}$&lt;/p&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;p&gt;$\it{P} = \texttt{T A C G T C A G C}$&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s construct the following matrix:&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                               \\
                    \hline
                              T\\
                    \hline
                              A\\
                    \hline
                              C\\
                    \hline
                              G\\
                    \hline
                              T\\
                    \hline
                              C\\
                    \hline
                              A\\
                    \hline
                              G\\
                    \hline
                              C\\

 \end{array}

\\

\textbf{Note}: sequence\ \texttt{T}\ is\ horizontal\ while\ \texttt{P}\ is\ vertical.

 $$

&lt;/div&gt;

&lt;p&gt;Let me remind you that our goal is to find where $\it\texttt{P}$ matches $\texttt{T}$. &lt;em&gt;A priori&lt;/em&gt; we do not know when it may be, so we will start by filling the entire first row with zeroes. This is because the match between $\it\texttt{P}$ and $\texttt{T}$ may start at any point up there. The first column we will initialize the same way we did previously: with increasing sequence of numbers:&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                             &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                         T &amp; 1\\
                    \hline
                         A &amp; 2\\
                    \hline
                         C &amp; 3\\
                    \hline
                         G &amp; 4\\
                    \hline
                         T &amp; 5\\
                    \hline
                         C &amp; 6\\
                    \hline
                         A &amp; 7\\
                    \hline
                         G &amp; 8\\
                    \hline
                         C &amp; 9\\

 \end{array}
 $$

&lt;/div&gt;

&lt;p&gt;Now let&amp;rsquo;s fill this matrix in using the same logic we used before:&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                             &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                           T &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1\\
                    \hline
                           A &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 1\\
                    \hline
                           C &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                           G &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3\\
                    \hline
                           C &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 4\\
                    \hline
                           A &amp; 7 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 5 &amp; 4\\
                    \hline
                           G &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 5\\
                    \hline
                           C &amp; 9 &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 6 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 5 &amp; 5

 \end{array}
 $$

&lt;/div&gt;

&lt;p&gt;Now that we have filled in the complete matrix let&amp;rsquo;s look at the bottom row. Instead of using the rightmost cell we will find a cell with the lowest number. That would be 2 (highlighted in red):&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                             &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                           T &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1\\
                    \hline
                           A &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 1\\
                    \hline
                           C &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                           G &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3\\
                    \hline
                           C &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 4\\
                    \hline
                           A &amp; 7 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 5 &amp; 4\\
                    \hline
                           G &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 5\\
                    \hline
                           C &amp; 9 &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 6 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 5 &amp; 5

 \end{array}
 $$

&lt;/div&gt;

&lt;p&gt;Starting already familiar traceback procedure at that cell we will get the following path through the matrix:&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                             &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \color{red}0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                           T &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1\\
                    \hline
                           A &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 1\\
                    \hline
                           C &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                           G &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3\\
                    \hline
                           C &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 4\\
                    \hline
                           A &amp; 7 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 5 &amp; 4\\
                    \hline
                           G &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 5\\
                    \hline
                           C &amp; 9 &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 6 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 5 &amp; 5

 \end{array}
 $$

&lt;/div&gt;

&lt;p&gt;for a corresponding alignment:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A A C C C T A T G T C A T G C C T T G G A
          | | * | | | | * | | 
          T A C G T C A - G C
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;video-2&#34;&gt;Video&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/183587535&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;hr /&gt;

&lt;h1 id=&#34;global-alignment&#34;&gt;Global alignment&lt;/h1&gt;

&lt;p&gt;So far in filling the dynamic programming matrix we were using the following expression to compute the number within each cell:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\alpha\texttt{x},\beta\texttt{y}) = min\begin{cases} 
                    \color{red}{Edit\ Distance(\alpha,\beta) + \delta(x,y)} &amp; \\
                    \color{blue}{Edit\ Distance(\alpha\texttt{x},\beta) + 1} &amp; \\
                    \color{green}{Edit\ Distance(\alpha,\beta\texttt{y}) + 1}
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;Basically we were adding 1 if there was a mismatch (the $\delta$ function) and also adding 1 for every gap. This however is not biologically realistic. If we look at the rates of different rates of mutations in the human genome we will see that they vary dramatically. Let&amp;rsquo;s look at substitutions first:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/TsTv.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 2&lt;/strong&gt; | There are two kinds of nucleotide substitutions: Transitions and Transversions. Transitions are substitutions between nucleotides belonging to the same chemical group. For example, a substitution of Adenine, a purine, to Guanine, also a purine, is a transition. Transversions, on the other hand, occur between chemically dissimilar nucleotides. For example, any substitution of a purine to a pyrimidine and vice verse will be a transition. (Image from &lt;a href=&#34;https://en.wikipedia.org/wiki/Transversion&#34;&gt;Wikipedia&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;you can see that there are move ways in which we can have a transversion. Despite this fact transversions are significantly less frequent that transitions. In fact in human the so called &lt;em&gt;Transition/Transversion ratio&lt;/em&gt; ($Ts:Tv$) is close to &lt;a href=&#34;http://www.pnas.org/content/107/3/961.long&#34;&gt;2&lt;/a&gt; (or even higher in &lt;a href=&#34;http://genomebiology.biomedcentral.com/articles/10.1186/gb-2011-12-9-r84&#34;&gt;coding regions&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;The situation with insertions and deletions (that are often called &lt;em&gt;indels&lt;/em&gt;) is similar in that are relatively rare and their rarity increases with size. A single nucleotide indel may occur every 1,000 bases on average, while a two-nucleotide deletion occurs every 3,000 bases and so on (see &lt;a href=&#34;http://genome.cshlp.org/content/23/5/749.abstract&#34;&gt;Montgomery et al. 2013&lt;/a&gt; for a more detailed statistics).&lt;/p&gt;

&lt;p&gt;As a result it is simply unrealistic to use &amp;ldquo;1&amp;rdquo; is all cases. Instead, we need to &lt;em&gt;penalize&lt;/em&gt; rare events more than we penalize frequent, more probable events. Let&amp;rsquo;s create a &lt;em&gt;penalty matrix&lt;/em&gt; to achieve this goal:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c  c  c  c  c }
                     &amp; A &amp; C &amp; G &amp; T &amp; -\\
                  \hline
                   A &amp; 0 &amp; \color{blue}4 &amp; \color{red}2 &amp; \color{blue}4 &amp; \color{orange}8\\  
                   C &amp; \color{blue}4 &amp; 0 &amp; \color{blue}4 &amp; \color{red}2 &amp; \color{orange}8\\
                   G &amp; \color{red}2 &amp; \color{blue}4 &amp; 0 &amp; \color{blue}4 &amp; \color{orange}8\\
                   T &amp; \color{blue}4 &amp; \color{red}2 &amp; \color{blue}4 &amp; 0 &amp; \color{orange}8\\
                   - &amp; \color{orange}8 &amp; \color{orange}8 &amp; \color{orange}8 &amp; \color{orange}8 &amp; \\
                \hline
                   
    \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Here if two nucleotides match, the penalty is 0. For a transitional substitution we pay $\color{red}2$ and for a transversional we pay $\color{blue}4$. The gap is the most expensive at $\color{orange}8$.&lt;/p&gt;

&lt;p&gt;Now, let&amp;rsquo;s align two sequences:&lt;/p&gt;

&lt;p&gt;$\it{X} = \texttt{T A T G T C A T G C}$&lt;/p&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;p&gt;$\it{Y} = \texttt{T A C G T C A G C}$&lt;/p&gt;

&lt;p&gt;First, we need to fill the following dynamic programming matrix:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C\\
                    \hline
                    \epsilon \\
                    \hline
                           T \\
                    \hline
                           A \\
                    \hline
                           C \\
                    \hline
                           G \\
                    \hline
                           T \\
                    \hline
                           C \\
                    \hline
                           A \\
                    \hline
                           G \\
                    \hline
                           C 

 \end{array}

\\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;But now we using penalty matrix generated above to calculate values in each cell. Specifically, before we were using this expression:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\alpha\texttt{x},\beta\texttt{y}) = min\begin{cases} 
                    Edit\ Distance(\alpha,\beta) + \delta(x,y) &amp; \\
                    Edit\ Distance(\alpha\texttt{x},\beta) + 1 &amp; \\
                    Edit\ Distance(\alpha,\beta\texttt{y}) + 1
             \end{cases}$$
&lt;/div&gt;

&lt;p&gt;but now, we will change it into this:&lt;/p&gt;

&lt;div&gt;

$$D(\alpha\texttt{x},\beta\texttt{y}) = min\begin{cases} 
                    D(\alpha,\beta) + p\texttt{(x,y)} &amp; \\
                    D(\alpha\texttt{x},\beta) + p\texttt{(x,-)} &amp; \\
                    D(\alpha,\beta\texttt{y}) + p\texttt{(-,y)}
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;where $p\texttt{(x,y)}$, $p\texttt{(x,-)}$, and $p\texttt{(-,y)}$ are taken directly from penalty matrix. Let&amp;rsquo;s start with the first row. In this row we can only fill from the left were we essentially inserting a gap every time. Since the gap penalty is 8 we will get:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C\\
                    \hline
                \epsilon &amp; 0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72 &amp; 80\\
                    \hline
                           T \\
                    \hline
                           A \\
                    \hline
                           C \\
                    \hline
                           G \\
                    \hline
                           T \\
                    \hline
                           C \\
                    \hline
                           A \\
                    \hline
                           G \\
                    \hline
                           C 

 \end{array}

\\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;Similarly, for the first column we get:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C\\
                    \hline
                \epsilon &amp; 0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72 &amp; 80\\
                    \hline
                           T &amp; 8\\
                    \hline
                           A &amp; 16\\
                    \hline
                           C &amp; 24\\
                    \hline
                           G &amp; 32\\
                    \hline
                           T &amp; 40\\
                    \hline
                           C &amp; 48\\
                    \hline
                           A &amp; 56\\
                    \hline
                           G &amp; 64\\
                    \hline
                           C &amp; 72

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;and finally the full matrix:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C\\
                    \hline
                \epsilon &amp; 0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72 &amp; 80\\
                    \hline
                           T &amp; 8 &amp; 0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72\\
                    \hline
                           A &amp; 16 &amp; 8 &amp; 0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64\\
                    \hline
                           C &amp; 24 &amp; 16 &amp; 8 &amp; 2 &amp; 10 &amp; 18 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56\\
                    \hline
                           G &amp; 32 &amp; 24 &amp; 16 &amp; 10 &amp; 2 &amp; 10 &amp; 18 &amp; 26 &amp; 34 &amp; 40 &amp; 48\\
                    \hline
                           T &amp; 40 &amp; 32 &amp; 24 &amp; 16 &amp; 10 &amp; 2 &amp; 10 &amp; 18 &amp; 26 &amp; 34 &amp; 42\\
                    \hline
                           C &amp; 48 &amp; 40 &amp; 32 &amp; 24 &amp; 18 &amp; 10 &amp; 2 &amp; 10 &amp; 18 &amp; 26 &amp; 34\\
                    \hline
                           A &amp; 56 &amp; 48 &amp; 40 &amp; 32 &amp; 26 &amp; 18 &amp; 10 &amp; 2 &amp; 10 &amp; 18 &amp; 26\\
                    \hline
                           G &amp; 64 &amp; 56 &amp; 48 &amp; 40 &amp; 32 &amp; 26 &amp; 18 &amp; 10 &amp; 6 &amp; 10 &amp; 18\\
                    \hline
                           C &amp; 72 &amp; 64 &amp; 56 &amp; 48 &amp; 40 &amp; 34 &amp; 26 &amp; 18 &amp; 12 &amp; 10 &amp; 10

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Drawing a traceback through this matrix will give us:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C\\
                    \hline
                \epsilon &amp; \color{red}0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72 &amp; 80\\
                    \hline
                           T &amp; 8 &amp; \color{red}0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72\\
                    \hline
                           A &amp; 16 &amp; 8 &amp; \color{red}0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64\\
                    \hline
                           C &amp; 24 &amp; 16 &amp; 8 &amp; \color{red}2 &amp; 10 &amp; 18 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56\\
                    \hline
                           G &amp; 32 &amp; 24 &amp; 16 &amp; 10 &amp; \color{red}2 &amp; 10 &amp; 18 &amp; 26 &amp; 34 &amp; 40 &amp; 48\\
                    \hline
                           T &amp; 40 &amp; 32 &amp; 24 &amp; 16 &amp; 10 &amp; \color{red}2 &amp; 10 &amp; 18 &amp; 26 &amp; 34 &amp; 42\\
                    \hline
                           C &amp; 48 &amp; 40 &amp; 32 &amp; 24 &amp; 18 &amp; 10 &amp; \color{red}2 &amp; 10 &amp; 18 &amp; 26 &amp; 34\\
                    \hline
                           A &amp; 56 &amp; 48 &amp; 40 &amp; 32 &amp; 26 &amp; 18 &amp; 10 &amp; \color{red}2 &amp; \color{red}{10} &amp; 18 &amp; 26\\
                    \hline
                           G &amp; 64 &amp; 56 &amp; 48 &amp; 40 &amp; 32 &amp; 26 &amp; 18 &amp; 10 &amp; 6 &amp; \color{red}{10} &amp; 18\\
                    \hline
                           C &amp; 72 &amp; 64 &amp; 56 &amp; 48 &amp; 40 &amp; 34 &amp; 26 &amp; 18 &amp; 12 &amp; 10 &amp; \color{red}{10}

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;This corresponds to the following alignment:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;T A C G T C A - G C
| | * | | | | * | | 
T A T G T C A T G C
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The following Python code implements Global alignment approach we have seen above. Note that the first function, &lt;code&gt;exampleCost&lt;/code&gt;, can be changed to set different value for the penalty matrix. You can play with it here:&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python3/911a7ddd2e?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;600&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;h2 id=&#34;local-alignment&#34;&gt;Local alignment&lt;/h2&gt;

&lt;p&gt;Global alignment discussed above works only in cases when we truly expect sequences to match across their entire lengths. In majority of biological application this is rarely the case. For instance, suppose you want to compare two bacterial genomes to figure out if they have matching sequences. Local alignment algorithm helps with this challenge. Surprisingly, it is almost identical to the approaches we used before. So here is our problem:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Sequence 1: ##################################################
                              |||||||||||||||||
Sequence 2:         #################################################
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;there are two sequences (shown with # characters) and they share a region of high similarity (indicated by vertical lines). How do we find this region? We cannot use global alignment logic here because across the majority of their lengths these sequences are dissimilar.&lt;/p&gt;

&lt;p&gt;To approach this problem we will change our penalty strategy. Instead of giving a high value for each mismatch we will instead give negative penalties. Only matches get positive rewards. Here is an example of such &lt;em&gt;scoring matrix&lt;/em&gt; (as opposed to the &lt;em&gt;penalty matrix&lt;/em&gt; we&amp;rsquo;ve used before):&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c  c  c  c  c }
                     &amp; A &amp; C &amp; G &amp; T &amp; -\\
                  \hline
                   A &amp; 2 &amp; \color{blue}{-4} &amp; \color{red}{-4} &amp; \color{blue}{-4} &amp; \color{orange}{-6}\\  
                   C &amp; \color{blue}{-4} &amp; 2 &amp; \color{blue}{-4} &amp; \color{red}{-4}  &amp; \color{orange}{-6}\\
                   G &amp; \color{red}{-4} &amp; \color{blue}{-4} &amp; 2 &amp; \color{blue}{-4}  &amp; \color{orange}{-6}\\
                   T &amp; \color{blue}{-4} &amp; \color{red}{-4} &amp; \color{blue}{-4}  &amp; 2 &amp; \color{orange}{-6}\\
                   - &amp; \color{orange}{-6} &amp; \color{orange}{-6} &amp; \color{orange}{-6} &amp; \color{orange}{-6} &amp; \\
                \hline
                   
    \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Our scoring logic will also change:&lt;/p&gt;

&lt;div&gt;

$$D(\alpha\texttt{x},\beta\texttt{y}) = max\begin{cases} 
                    D(\alpha,\beta) + s\texttt{(x,y)} &amp; \\
                    D(\alpha\texttt{x},\beta) + s\texttt{(x,-)} &amp; \\
                    D(\alpha,\beta\texttt{y}) + s\texttt{(-,y)} &amp; \\
                    0
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;We are now looking for &lt;strong&gt;maximum&lt;/strong&gt; and use &lt;em&gt;0&lt;/em&gt; to prevent having negative values in the matrix. This also implies that the first row and column will now be filled with zeros. Let apply this to two sequences:&lt;/p&gt;

&lt;p&gt;Now, let&amp;rsquo;s align two sequences:&lt;/p&gt;

&lt;p&gt;$\texttt{T A T A T G C G G C G T T T}$&lt;/p&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;p&gt;$\texttt{G G T A T G C T G G C G C T A}$&lt;/p&gt;

&lt;p&gt;Dynamic programming matrix with initialized first row and column will look like this:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; A &amp; T &amp; G &amp; C &amp; G &amp; G &amp; C &amp; G &amp; T &amp; T &amp; T\\
                     \hline
                   \epsilon &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          T &amp; 0\\
                    \hline
                          A &amp; 0\\ 
                    \hline
                          T &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          C &amp; 0\\
                    \hline
                          T &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          C &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          C &amp; 0\\
                    \hline
                          T &amp; 0\\
                    \hline
                          A &amp; 0\\
                   
\end{array}

\\

\textbf{Remember}: sequence\ \texttt{X}\ is\ vertical\ while\ \texttt{Y}\ is\ horizontal.


    $$
&lt;/div&gt;

&lt;p&gt;Filling it completely will yield the following matrix. Note that clues to where the local alignment may be are given off by positive numbers in the sea of 0s:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; A &amp; T &amp; G &amp; C &amp; G &amp; G &amp; C &amp; G &amp; T &amp; T &amp; T\\
                     \hline
                   \epsilon &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 4 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 2 &amp; 2\\
                    \hline
                          A &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\ 
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 6 &amp; 0 &amp; 6 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 8 &amp; 2 &amp; 2 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 10 &amp; 4 &amp; 0 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 4 &amp; 6 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 6 &amp; 8 &amp; 2 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 8 &amp; 4 &amp; 4 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 2 &amp; 10 &amp; 4 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 6 &amp; 2 &amp; 4 &amp; \color{red}{12} &amp; 6 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 2 &amp; 4 &amp; 6 &amp; 8 &amp; 2 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 8 &amp; 10 &amp; 4\\
                    \hline
                          A &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 4 &amp; 6\\
                   
\end{array}
    $$
&lt;/div&gt;

&lt;p&gt;To identify to boundary of the local alignment we need to identify the cell with the &lt;strong&gt;highest&lt;/strong&gt; value. This cell has value of $\color{red}{12}$ and is highlighted above. Using traceback procedure we will find:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; A &amp; T &amp; G &amp; C &amp; G &amp; G &amp; C &amp; G &amp; T &amp; T &amp; T\\
                     \hline
                   \epsilon &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 4 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; \color{red}2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 2 &amp; 2\\
                    \hline
                          A &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; \color{red}4 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\ 
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 6 &amp; 0 &amp; \color{red}6 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; \color{red}8 &amp; 2 &amp; 2 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; \color{red}{10} &amp; 4 &amp; 0 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; \color{red}4 &amp; 6 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; \color{red}6 &amp; 8 &amp; 2 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; \color{red}8 &amp; 4 &amp; 4 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 2 &amp; \color{red}{10} &amp; 4 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 6 &amp; 2 &amp; 4 &amp; \color{red}{12} &amp; 6 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 2 &amp; 4 &amp; 6 &amp; 8 &amp; 2 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 8 &amp; 10 &amp; 4\\
                    \hline
                          A &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 4 &amp; 6\\
                   
\end{array}
    $$
&lt;/div&gt;

&lt;p&gt;This corresponds to the best local alignment between the two sequences:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; T A T A T G C - G G C G T T T
     | | | | | * | | | |
 G G T A T G C T G G C G C T A
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here is a Python representation of this approach:&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python3/aa05b81499?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;600&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;This algorithm was developed by &lt;a href=&#34;http://dornsife.usc.edu/assets/sites/516/docs/papers/msw_papers/msw-042.pdf&#34;&gt;Temple Smith and Michael Waterman&lt;/a&gt; in 1981. This is why it is most often called Smith Waterman local alignment algorithm.&lt;/p&gt;

&lt;h2 id=&#34;video-3&#34;&gt;Video&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/183588416&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;hr /&gt;

&lt;h1 id=&#34;next&#34;&gt;Next&amp;hellip;&lt;/h1&gt;

&lt;p&gt;In the next lecture we will learn about speeding sequence searches with indexing and talk about mappers.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>3. Sequence alignment: Introductory concepts</title>
      <link>https://nekrut.github.io/BMMB554/post/topic3/</link>
      <pubDate>Wed, 25 Jan 2017 10:43:18 -0400</pubDate>
      
      <guid>https://nekrut.github.io/BMMB554/post/topic3/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/nyc.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;In the previous lecture we have seen several ways in which DNA sequence data can be accumulated (the reason for having Manhattan in the figure above will be apparent a bit later). Because sequencing machines (especially the ones made by Illumina) generate billions of sequences (called reads) from every run, the real challenge is what one does with all this data once sequencing is done. So before we get into details of technology and its application we need to introduce some basic algorithmic concepts related to sequence analysis. Today we will start with &lt;strong&gt;dynamic programming&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&#34;dynamic-programming-for-the-change-problem&#34;&gt;Dynamic programming for the change problem&lt;/h2&gt;

&lt;p&gt;When introducing algorithmic concepts to biological audience it often becomes critical to use good examples. One of the people who probably succeeded most in this endeavor is &lt;a href=&#34;http://cseweb.ucsd.edu/~ppevzner/&#34;&gt;Pavel Pevzner&lt;/a&gt;, a Ronald R. Taylor Professor of Computer Science at UCSD, who (together with &lt;a href=&#34;http://compeau.cbd.cmu.edu/&#34;&gt;Phillip Compeau&lt;/a&gt;) published a very informatics (and entertaining) &lt;a href=&#34;https://www.amazon.com/Bioinformatics-Algorithms-Active-Learning-Approach/dp/0990374602&#34;&gt;book&lt;/a&gt; on the subject of computational biology. The example I use below comes from this book.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Suppose you are a cashier who&amp;rsquo;s job is, generally speaking, to receive money and to give out change. Suppose that someone buys something that costs \$9.37 and gives you a 10 dollar bill. You need to give \$0.63 back in smallest possible number of coins. The US coin denominations are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;100 (1 dollar)&lt;/li&gt;
&lt;li&gt;50 (half-dollar)&lt;/li&gt;
&lt;li&gt;25 (quarter)&lt;/li&gt;
&lt;li&gt;10 (dime)&lt;/li&gt;
&lt;li&gt;5 (nickel)&lt;/li&gt;
&lt;li&gt;1 (penny)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, given these coins you will:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;start with the largest coin smaller than the amount you need to give back = &lt;strong&gt;50 Cents&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;repeat for the remaining $0.13 and select &lt;strong&gt;10 Cents&lt;/strong&gt;  (&lt;strong&gt;NOTE&lt;/strong&gt;: this is recursion happening)&lt;/li&gt;
&lt;li&gt;finish with three 1 cent counts thus you ended up with 5 (&lt;strong&gt;50&lt;/strong&gt; + &lt;strong&gt;10&lt;/strong&gt; + 3x&lt;strong&gt;1&lt;/strong&gt;) coins.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;solving-problem-exhaustively&#34;&gt;Solving problem exhaustively&lt;/h3&gt;

&lt;p&gt;Now (as suggested &lt;a href=&#34;http://interactivepython.org/runestone/static/pythonds/Recursion/DynamicProgramming.html&#34;&gt;here&lt;/a&gt;) suppose you are a cashier in a strange country where there is also a &lt;strong&gt;21&lt;/strong&gt; cent coin in circulation. By using the algorithm above you will still give your customer 5 coins, while the &amp;ldquo;correct&amp;rdquo; solution will certainly be giving him/her 3 &lt;strong&gt;21&lt;/strong&gt; cent coins. So the algorithm we used above simply does not work.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s rephrase the problem. The smallest number of coins summing up to $0.63 cents (in our strange country with a &lt;strong&gt;21&lt;/strong&gt; cent coin) will be:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.62 plus a &lt;strong&gt;1&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.58 plus a &lt;strong&gt;5&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.53 plus a &lt;strong&gt;10&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.42 plus a &lt;strong&gt;21&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.38 plus a &lt;strong&gt;25&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.13 plus a &lt;strong&gt;50&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/change1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 1&lt;/strong&gt; | First iteration&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Next, for each of these possibilities we will repeat this again. For example for $0.62 will consider:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.61 plus a &lt;strong&gt;1&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.57 plus a &lt;strong&gt;5&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.52 plus a &lt;strong&gt;10&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.41 plus a &lt;strong&gt;21&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.37 plus a &lt;strong&gt;25&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.12 plus a &lt;strong&gt;50&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/change2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 2&lt;/strong&gt; | Second iteration&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And again. For $0.58 we will have:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/change3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 3&lt;/strong&gt; | Note that amounts highlighted in red are repeated. Below we explain why this is &lt;strong&gt;really bad&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;and so on. Basically, as every iteration we are trying to find:&lt;/p&gt;

&lt;div&gt;

$$numCoins = min\begin{cases} 1 + numCoins(original\_amount - 1) 
                         &amp; \\ 1 + numCoins(original\_amount - 5) 
                         &amp; \\ 1 + numCoins(original\_amount - 10) 
                         &amp; \\ 1 + numCoins(original\_amount - 21) 
                         &amp; \\ 1 + numCoins(original\_amount - 25) 
                         &amp; \\ 1 + numCoins(original\_amount - 50) 
                 \end{cases}$$

&lt;/div&gt;

&lt;p&gt;While this algorithm will find us the smallest number of coins necessary to give out a particular amount in change, it does this at a horrific price: it is extremely inefficient as it recomputes all possibilities at every iteration. For instance, if we ask the algorithm to compute the minimal number of coins necessary to give out 63 cents in change in a country with only four coins (1, 5, 10, and 25 cents) it will take &lt;strong&gt;67,716,925&lt;/strong&gt; iterations (recursive calls). As a result you will probably loose all of your customers while they are waiting for the change.&lt;/p&gt;

&lt;p&gt;The code snippet below implements this algorithm (do not worry if you don&amp;rsquo;t quire understand python. It is OK for now). If you execute it (press the play button) your browser will likely crash as it will get tired waiting for result to come back (try it anyway):&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/a74fb5b988?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;h3 id=&#34;caching-helps-a-bit&#34;&gt;Caching helps a bit&lt;/h3&gt;

&lt;p&gt;One potential way to solve our problem in a reasonable amount of time is to take advantage of red nodes shown in Figure 3. What if before calling the function we check if a minimum number of coins for a particular amount was already computed? Apparently this speeds things up quite dramatically:&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/efcc5b3667?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Now you can see that it takes under a second to find that it takes 3 coins to give 63 cents in change in a country with 1, 5, 10, 21, and 25 cent coins. Yet this script still makes 221 calls (better than 67,716,925, but still a lot) for find the answer.&lt;/p&gt;

&lt;h3 id=&#34;introducing-dynamic-programming&#34;&gt;Introducing dynamic programming&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s flip things around. Instead of starting from &lt;strong&gt;63&lt;/strong&gt; cents and going down through the tree as shown in Figs 1 - 3 we will instead compute the minimal number of coins for every value from 1 to 63. To save space, let&amp;rsquo;s instead assume that we need to give 11 cents in change. Let&amp;rsquo;s compute a dynamic programming array for minimal number of coins between 1 and 11 (you may need to scroll sideways if your screen is small):&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt;Amount                   0  1  2  3  4  5  6  7  8  9 10 11
Minimum number of coins  0  1  2  3  4  1  2  3  4  5  1  2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Table 1&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;for amounts between &lt;strong&gt;1&lt;/strong&gt; and &lt;strong&gt;4&lt;/strong&gt;, we have no choice, since we have only pennies. At &lt;strong&gt;5&lt;/strong&gt; we can either use 5 pennies or 1 nickel. According to this strategy (for a country with 1, 5, 10, and 25 cent coins):&lt;/p&gt;

&lt;div&gt;

$$numCoins = min\begin{cases} 1 + numCoins(original\_amount - 1) 
                         &amp; \\ 1 + numCoins(original\_amount - 5) 
                         &amp; \\ 1 + numCoins(original\_amount - 10) 
                         &amp; \\ 1 + numCoins(original\_amount - 25) 
                                         \end{cases}$$

&lt;/div&gt;

&lt;p&gt;nickel wins (needs just 1 coin). From &lt;strong&gt;6&lt;/strong&gt; to &lt;strong&gt;9&lt;/strong&gt; we can either use all pennies (values will be 6, 7, 8, and 9) or a combination of nickel and pennies (values will be 2, 3, 4, 5). Again, smaller values win.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s now use this table to decide what is the minimum number of coins necessary to give 11 cents in change:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/change4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 4&lt;/strong&gt; | Making change for 11 cents. Let&amp;rsquo;s look at leftmost branch. If you give 1 cent in change, you are left with 10 more to give. You consult Table 1 above and see that 10 cents can be given with 1 coin, so it will be 1 + 1 = 2 coins. In the center branch we give 5 cents in one coin and have 6 more cents to give. Looking at Table 1 tells us that 6 cents can be given in 2 coins, so 1 + 2 = 3 coins. Finally, in the rightmost branch giving 10 cents as one coin leaves 1 cent to give in change, which is also 1 coin, so 1 + 1 = 2. Thus we can either give 10 cents + 1 cent or 1 cent + 10 cents, which is equivalent since in both cases we give only 2 coins.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The following python code implements a function called &lt;code&gt;dynamicCoinChange&lt;/code&gt; which computes a table (like Table 1) for any amount. In line 20 of the script we print a value corresponding to the amount we need to give back. That value is the minimum number of coins. Note that this program takes virtually no time to run.&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/81c07a3750?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;strong&gt;So&lt;/strong&gt;, dynamic programming is a methodology where complex problems are broken down to simple subproblems, that are computed just once and then used to solve the complete problem. In this example, we first pre-compute the number of coins needed to make change for any amount up to the required one, and then produce the answer.&lt;/p&gt;

&lt;h2 id=&#34;dynamic-programming-for-manhattan-tourist-problem&#34;&gt;Dynamic programming for Manhattan tourist problem&lt;/h2&gt;

&lt;p&gt;Now let&amp;rsquo;s get into a multi(2)-dimensional world beautifully elaborated in Jones and Pevzner (&lt;a href=&#34;http://www.amazon.com/Introduction-Bioinformatics-Algorithms-Computational-Molecular/dp/0262101068/&#34;&gt;2004&lt;/a&gt;) book:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/6.3.png&#34; alt=&#34;&#34; /&gt;|&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 5&lt;/strong&gt; | Reproduced from &lt;a href=&#34;http://www.amazon.com/Introduction-Bioinformatics-Algorithms-Computational-Molecular/dp/0262101068/&#34;&gt;JP&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The goal of this game is to visit the &lt;strong&gt;maximum number&lt;/strong&gt; of attractions along a stroll across Manhattan.
Let&amp;rsquo;s formalize this a bit:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;city = &lt;em&gt;n&lt;/em&gt; x &lt;em&gt;m&lt;/em&gt; directed graph&lt;/li&gt;
&lt;li&gt;node = intersection&lt;/li&gt;
&lt;li&gt;edge = block&lt;/li&gt;
&lt;li&gt;edge weight = number of attractions along a city block&lt;/li&gt;
&lt;li&gt;start node = source&lt;/li&gt;
&lt;li&gt;end node = sink&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/6.4a.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/6.4b.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;The city&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;and a path through it (Figure 6.4 from &lt;a href=&#34;http://www.amazon.com/Introduction-Bioinformatics-Algorithms-Computational-Molecular/dp/0262101068/&#34;&gt;JP&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The figure above provides a path from source to the sink, yet this path is not the longest. We can identify the optimal path recursively, but just like in the case if the change problem we will end up with a very inefficient code. Let&amp;rsquo;s instead pre-fill our matrix using the following logic:&lt;/p&gt;

&lt;div&gt;

$$s_i,_j = max\begin{cases} s_{i-1,j} + weight\ of\ the\ edge\ between\ (i - 1, j)\ and\ (i,j)
                         &amp; \\ s_{i,j-1} + weight\ of\ the\ edge\ between\ (i, j - 1)\ and\ (i,j)
                 
                 \end{cases}$$

&lt;/div&gt;

&lt;p&gt;This will result in the following progression:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid1.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid2.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid2.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid4.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid3.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid6.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;From &lt;a href=&#34;http://www.amazon.com/Introduction-Bioinformatics-Algorithms-Computational-Molecular/dp/0262101068/&#34;&gt;JP&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;You can see that wandering from the source may get us into a dead end. However, backtracking from the sink will always get us to source along the longest path! This by pre-computing the matrix we can easily solve the Manhattan tourist problem. Now we are ready to tackle sequence alignment problems.&lt;/p&gt;

&lt;h1 id=&#34;video&#34;&gt;Video&lt;/h1&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/182594750&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>2. DNA sequencing</title>
      <link>https://nekrut.github.io/BMMB554/post/topic2/</link>
      <pubDate>Tue, 17 Jan 2017 11:17:20 -0400</pubDate>
      
      <guid>https://nekrut.github.io/BMMB554/post/topic2/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/illumina_pseudocolor.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;the-60s-and-the-70s&#34;&gt;The 60s and the 70s&lt;/h1&gt;

&lt;p&gt;The first complete nucleic acids being sequenced were RNAs (tRNAs in particular; see pioneering work of &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/pubmed/14263761&#34;&gt;Robert Holley and colleagues&lt;/a&gt;). The work on finding approaches to sequencing DNA molecules began in late 60s and early 70s. One of the earliest contributions has been made by Ray Wu from Cornell, who used &lt;em&gt;E. coli&lt;/em&gt; DNA polymerase to &lt;a href=&#34;http://www.sciencedirect.com/science/article/pii/0022283670900045&#34;&gt;incorporate radioactively labelled nucleotides into protruding ends of bacteriphage lambda&lt;/a&gt;. It took several more years for the development of more &amp;ldquo;high throughput&amp;rdquo; technologies by Sanger and Maxam/Gilbert. The Sanger technique has ultimately won over Maxam/Gilbert&amp;rsquo;s protocol due to its relative simplicity (once dideoxynucleotides has become commercially available) and the fact that it required smaller amount of starting material as the polymerase was used to generate fragments necessary for sequence determination.&lt;/p&gt;

&lt;h1 id=&#34;original-approaches-were-laborious&#34;&gt;Original approaches were laborious&lt;/h1&gt;

&lt;p&gt;In the original &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC431765/pdf/pnas00043-0271.pdf&#34;&gt;Sanger paper&lt;/a&gt; the authors sequenced bacteriophage phiX174 by using its own restriction fragments as primers. This was an ideal set up to show the proof of principle for the new method. This is because phiX174 DNA is homogeneous and can be isolated in large quantities. Now suppose that you would like to sequence a larger genome (say &lt;em&gt;E. coli&lt;/em&gt;). Remember that the original version of Sanger method can only sequence fragments up to 200 nucleotides at a time. So to sequence the entire &lt;em&gt;E. coli&lt;/em&gt; genome (which by-the-way was not sequenced until &lt;a href=&#34;http://science.sciencemag.org/content/277/5331/1453&#34;&gt;1997&lt;/a&gt;) you would need to split the genome into multiple pieces and sequence each of them individually. This is hard, because to produce a readable Sanger sequencing gel each sequence must be amplified to a suitable amount (around 1 nanogram) and be homogeneous (you cannot mix multiple DNA fragments in a single reaction as it will be impossible to interpret the gel). Molecular cloning enabled by the availability of commercially available restriction enzymes and cloning vectors simplified this process. Until the onset of next generation sequencing in 2005 the process for sequencing looked something like this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(&lt;strong&gt;1&lt;/strong&gt;) - Generate a collection of fragments you want to sequence. It can be a collection of fragments from a genome that was mechanically sheared or just a single fragment generated by PCR.&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;2&lt;/strong&gt;) - These fragment(s) are then cloned into a plasmid vector (we will talk about other types of vectors such as BACs later in the course).&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;3&lt;/strong&gt;) - Vectors are transformed into bacterial cells and positive colonies (containing vectors with insert) are picked from an agar plate.&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;4&lt;/strong&gt;) - Each colony now represents a unique piece of DNA.&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;5&lt;/strong&gt;) - An individual colony is used to seed a bacterial culture that is grown overnight.&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;6&lt;/strong&gt;) - Plasmid DNA is isolated from this culture and now can be used for sequencing because it is (1) homogeneous and (2) we now a sufficient amount.&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;7&lt;/strong&gt;) - It is sequenced using universal primers. For example the image below shows a map for pGEM-3Z plasmid (a pUC18 derivative). Its multiple cloning site is enlarged and sites for &lt;strong&gt;T7&lt;/strong&gt; and &lt;strong&gt;SP6&lt;/strong&gt; sequencing primers are shown. These are the &lt;strong&gt;pads&lt;/strong&gt; I&amp;rsquo;m referring to in the lecture. These provide universal sites that can be used to sequence any insert in between.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/pgem3z.png&#34; /&gt;
    
    
&lt;/figure&gt;

Figure from Promega, Inc.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Until the invention of NGS the above protocol was followed with some degree of automation. But you can see that it was quite laborious if the large number of fragements needed to be sequenced. This is because each of them needed to be subcloned and handled separately. This is in part why Human Genome Project, a subject of our next lecture, took so much time to complete.&lt;/p&gt;

&lt;h2 id=&#34;evolution-of-sequencing-machines&#34;&gt;Evolution of sequencing machines&lt;/h2&gt;

&lt;p&gt;The simplest possible sequencing machine is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Polyacrylamide_gel_electrophoresis&#34;&gt;gel rig with polyacrylamide gel&lt;/a&gt;. Sanger used it is his protocol obtaining the following results:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/sangerGel.png&#34; /&gt;
    
    
&lt;/figure&gt;

Figure from &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC431765/pdf/pnas00043-0271.pdf&#34;&gt;Sanger et al. 1977&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here for sequencing each fragment four separate reactions are peformed (with ddA, ddT, ggC, and ddG) and four lanes on the gel are used. One simplification of this process that came in the 90s was to use fluorescently labelled dideoxy nucleotides. This is easier because everything can be performed in a single tube and uses a single lane on a gel:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/dd_labels.png&#34; /&gt;
    
    
&lt;/figure&gt;

Figure from Applied Biosystems &lt;a href=&#34;https://www3.appliedbiosystems.com/cms/groups/mcb_support/documents/generaldocuments/cms_041003.pdf&#34;&gt;support site&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;However, there is still substantial labor involved in pouring the gels, loading them, running machines, and cleaning everything post-run. A significant improvement was offered by the development of capillary electrophoresis allowing automation of liquid handling and sample loading. Although several manufacturers have been developing and selling such machines a &lt;em&gt;de facto&lt;/em&gt; standard in this area was (and still is) the Applied Biosystems (ABI) Genetics and DNA Anlayzer systems. The highest throughput ABI system, 3730&lt;em&gt;xl&lt;/em&gt;, had 96 capillaries and could automatically process 384 samples.&lt;/p&gt;

&lt;h1 id=&#34;ngs&#34;&gt;NGS!&lt;/h1&gt;

&lt;p&gt;384 samples may sound like a lot, but it is nothing if we are sequencing an entire genome. The beauty of NGS is that these technologies are not bound by sample handling logistics. They still require preparation of libraries, but once a library is made (which can be automated) it is processed more or less automatically to generate multiple copies of each fragment (in the case of 454, Illumina, and Ion Torrent) and loaded onto the machine, where millions of individual fragments are sequenced simultaneously. The following videos and slides explains how these technologies work.&lt;/p&gt;

&lt;h2 id=&#34;watch-introductory-video&#34;&gt;Watch introductory video&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/181072208&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h1 id=&#34;ngs-in-depth&#34;&gt;NGS in depth&lt;/h1&gt;

&lt;h2 id=&#34;1-454-sequencing&#34;&gt;1: 454 sequencing&lt;/h2&gt;

&lt;p&gt;454 Technology is a massively parallel modification of &lt;a href=&#34;http://genome.cshlp.org/content/11/1/3&#34;&gt;pyrosequencing&lt;/a&gt; technology. Incorporation of nucleotides are registered by a &lt;a href=&#34;https://en.wikipedia.org/wiki/Charge-coupled_device&#34;&gt;CCD&lt;/a&gt; camera as a flash of light generated from the interaction between ATP and Luciferin. The massive scale of 454 process is enabled by generation of a population of beads carrying multiple copies of the same DNA fragment. The beads are distributed across a microtiter plate where each well of the plate holding just one bead. Thus every unique coordinate (a well) on the plate generates flashes when a nucleotide incorporation event takes plate. This is &amp;ldquo;monochrome&amp;rdquo; technique: flash = nucleotide is incorporated; lack of flash = no incorporation. Thus to distinguish between A, C, G, and T individual nucleotides are &amp;ldquo;washed&amp;rdquo; across the microtiter plate at discrete times: if &lt;strong&gt;A&lt;/strong&gt; is being washed across the plate and a flash of light is emitted, this implies that A is present in the fragment being sequenced.&lt;/p&gt;

&lt;p&gt;454 can generated fragments up 1,000 bases in length. Its biggest weakness is inability to precisely determine the length of &lt;a href=&#34;https://www.broadinstitute.org/crd/wiki/index.php/Homopolymer&#34;&gt;homopolymer runs&lt;/a&gt;. Thus the main type if sequencing error generated by 454 are insertions and deletions (indels).&lt;/p&gt;

&lt;h3 id=&#34;slides&#34;&gt;Slides&lt;/h3&gt;

&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;28bd628499b54d09b4f9c6e7534c7e8f&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;

&lt;h3 id=&#34;video&#34;&gt;Video&lt;/h3&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/121286060&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;Underlying slides are &lt;a href=&#34;https://speakerdeck.com/nekrut/ngs-technologies-454#&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;reading&#34;&gt;Reading&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;2001 | &lt;a href=&#34;http://genome.cshlp.org/content/11/1/3&#34;&gt;Overview of pyrosequencing methodology - Ronaghi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2005 | &lt;a href=&#34;http://www.nature.com/nature/journal/v437/n7057/pdf/nature03959.pdf&#34;&gt;Description of 454 process - Margulies et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2007 | &lt;a href=&#34;http://link.springer.com/protocol/10.1385/1-59745-377-3:1&#34;&gt;History of pyrosequencing - Pal Nyren&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2007 | &lt;a href=&#34;http://genomebiology.com/content/pdf/gb-2007-8-7-r143.pdf&#34;&gt;Errors in 454 data - Huse et al. &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2010 | &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/26/18/i420.full.pdf+html&#34;&gt;Properties of 454 data - Balzer et al.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;2-illumina-sequencing&#34;&gt;2: Illumina sequencing&lt;/h2&gt;

&lt;p&gt;Illumina (originally called &amp;ldquo;Solexa&amp;rdquo;) uses glass flowcells with oligonucleotides permanently attached to internal surface. These oligonucleotides are complementary to sequencing adapters added to DNA fragments being sequenced during library preparation. The DNA fragements that are &amp;ldquo;stuck&amp;rdquo; on the flowcell due to complementary interaction between adapters are amplified via &amp;ldquo;bridge amplification&amp;rdquo; to form clusters. Sequencing is performed using reversible terminator chemistry with nucleotides modified to carry dyes specific to each nucleotide. As a result all nucleotides can be added at once and are distinguished by colors. Currently, it is possible to sequence up to 300 bases from each end of the fragment being sequenced. Illumina has the highest throughput (and lowest cost per base) of all existing technologies at this moment. The HiSeq 2500 machine can produce &lt;a href=&#34;http://www.illumina.com/systems/hiseq_2500_1500/performance_specifications.html&#34;&gt;600 billion nucleotides in 5 days&lt;/a&gt;. In this course we will most often work with Illumina data.&lt;/p&gt;

&lt;h3 id=&#34;slides-1&#34;&gt;Slides&lt;/h3&gt;

&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;942908c8c24546d58cf8b61b3598feb3&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;

&lt;h3 id=&#34;video-1&#34;&gt;Video&lt;/h3&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/121178846&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;Underlying slides are &lt;a href=&#34;https://speakerdeck.com/nekrut/ngs-technologies-illumina#&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;reading-1&#34;&gt;Reading&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;2008 | &lt;a href=&#34;http://www.nature.com/nature/journal/v456/n7218/pdf/nature07517.pdf&#34;&gt;Human genome sequencing on Illumina - Bentley et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2010 | &lt;a href=&#34;http://nar.oxfordjournals.org/content/39/13/e90.full-text-lowres.pdf&#34;&gt;Data quality 1 - Nakamura et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2011 | &lt;a href=&#34;http://genomebiology.com/content/pdf/gb-2011-12-11-r112.pdf&#34;&gt;Data quality 2 - Minoche et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2011 | &lt;a href=&#34;http://www.biomedcentral.com/content/pdf/1471-2164-12-382.pdf&#34;&gt;Illumina pitfalls - Kircher et al.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;10x-a-way-to-extend-the-utility-of-short-illumina-reads&#34;&gt;10X: A way to extend the utility of short Illumina reads&lt;/h3&gt;

&lt;p&gt;A company called &lt;a href=&#34;http://www.10xgenomics.com/technology/&#34;&gt;10X Genomics&lt;/a&gt; has developed a technology which labels reads derived from continuous fragments of genomic DNA. In this technology a gel bead covered with a large number of adapter molecules is placed within a droplet containing PCR reagents and one or several long molecules of genomic DNA to be sequenced.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/10x.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;10X bead&lt;/strong&gt; containing the standard Illumina P5 adapter combined with barcode, sequencing primer annealing site (R1) and random primer (N-mer) Slide from &lt;a href=&#34;http://www.slideshare.net/GenomeInABottle/aug2015-analysis-team-04-10x-genomics&#34;&gt;Slideshare&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The droplets are generated by combining beads, PCR reagents, and genomic DNA in a microfluidic device:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.nature.com/nbt/journal/v34/n3/fig_tab/nbt.3432_F1.html&#34;&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/10x-overview.jpg&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;10X workflow&lt;/strong&gt; (&lt;strong&gt;a&lt;/strong&gt;) Gel beads loaded with primers and barcoded oligonucleotides are mixed with DNA and enzyme mixture then oil-surfactant solution at a microfluidic &amp;lsquo;double-cross&amp;rsquo; junction. Gel beadcontaining droplets flow to a reservoir where gel beads are dissolved, initiating whole-genome primer extension. The products are pooled from each droplet. The final library preparation requires shearing the libraries and incorporation of Illumina adapters. (&lt;strong&gt;b&lt;/strong&gt;) Top, linked reads of the ALK gene from the NA12878 WGS sample. Lines represent linked reads; dots represent reads; color indicates barcode. Middle, exon boundaries of the ALK gene. Bottom, linked reads of the ALK gene from the NA12878 exome data. Reads from neighboring exons are linked by common barcodes. Only a small fraction of linked reads is presented here. Reproduced from &lt;a href=&#34;http://www.nature.com/nbt/journal/v34/n3/full/nbt.3432.html&#34;&gt;Zheng:2015&lt;/a&gt; (click the image to go to the original paper).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In essence, 10X allows to uniquely map reads derived from long genomic fragments. This information is essential for bridging together genome and transcriptome assemblies as we will see in later in this course.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/120429438&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h2 id=&#34;3-pacbio-single-molecule-sequencing&#34;&gt;3: PacBio Single Molecule Sequencing&lt;/h2&gt;

&lt;p&gt;PacBio is a fundamentally different approach to DNA sequencing as it allows reading single molecules. Thus it is an example is so called &lt;em&gt;Single Molecule Sequencing&lt;/em&gt; or &lt;em&gt;SMS&lt;/em&gt;. PacBio uses highly processive DNA polymerase placed at the bottom of each well on a microtiter plate. The plate is fused to the glass slide illuminated by a laser. When polymerase is loaded with template it attracts fluorescently labeled nucleotides to the bottom of the well where they emit light with a wavelength characteristic of each nucleotide. As a result a &amp;ldquo;movie&amp;rdquo; is generated for each well recording the sequence and duration of incorporation events. One of the key advantage of PacBio technology is its ability to produce long reads with ones at 10,000 bases being common.&lt;/p&gt;

&lt;h3 id=&#34;slides-2&#34;&gt;Slides&lt;/h3&gt;

&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;ccb3d34f1a214f66ac7a2d233caedaf5&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;

&lt;h3 id=&#34;video-2&#34;&gt;Video&lt;/h3&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/121267426&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;Underlying slides are &lt;a href=&#34;https://speakerdeck.com/nekrut/ngs-technologies-pacific-biosceinces&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;reading-2&#34;&gt;Reading&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;2003 | &lt;a href=&#34;http://www.sciencemag.org/content/299/5607/682.full.pdf&#34;&gt;Single Molecule Analaysis at High Concentration - Levene et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2008 | &lt;a href=&#34;http://www.pnas.org/content/105/4/1176.full&#34;&gt;ZMW nanostructures - Korlach et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2009 | &lt;a href=&#34;http://www.sciencemag.org/content/323/5910/133.full&#34;&gt;Real Time Sequencing with PacBio - Eid et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2010 | &lt;a href=&#34;http://www.nature.com/nmeth/journal/v7/n6/pdf/nmeth.1459.pdf&#34;&gt;Modification detection with PacBio - Flusberg et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2012 | &lt;a href=&#34;http://www.nature.com/nbt/journal/v30/n7/pdf/nbt.2280.pdf&#34;&gt;Error correction of PacBio reads - Koren et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2014 | &lt;a href=&#34;http://www.pnas.org/cgi/doi/10.1073/pnas.1400447111&#34;&gt;Transcriptome with PacBio - Taligner et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2015 | &lt;a href=&#34;http://dx.doi.org/10.1038/nature13907&#34;&gt;Resolving complex regions in Human genomes with PacBio - Chaisson et al.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;4-oxford-nanopore&#34;&gt;4: Oxford Nanopore&lt;/h2&gt;

&lt;p&gt;Oxford nanopore is another dramatically different technology that threads single DNA molecules through biologically-derived (transmembrane proteins) pore in a membrane impermeable to ions. It uses polymerase to control the speed of translocation of the DNA molecule through membrane. In that sense it is not &lt;em&gt;Sequencing by synthesis&lt;/em&gt; we have seen in the other technologies discussed here. This technology generates longest reads possible today: in many instances a single read can be hundreds of thousands if nucleotides in length. It still however suffers from high error rate and relatively low throughput (compared to Illumina). On the upside Oxford Nanopore sequencing machines are only slightly bigger than a thumb-drive and cost very little.&lt;/p&gt;

&lt;h3 id=&#34;slides-3&#34;&gt;Slides&lt;/h3&gt;

&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;3895a3069bc64ad5bc74c972a0353911&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;

&lt;p&gt;A recent overview of latest developments at Oxford Nanopore can be found &lt;a href=&#34;https://github.com/lmmx/talk-transcripts/blob/master/Nanopore/NoThanksIveAlreadyGotOne.md&#34;&gt;here&lt;/a&gt; as well as in the following video&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/nizGyutn6v4&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;reading-3&#34;&gt;Reading&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;2016 | &lt;a href=&#34;http://nature.com/nnano/journal/v11/n2/full/nnano.2016.9.html&#34;&gt;The promises and challenges of solid-state sequencing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2015 | &lt;a href=&#34;http://nature.com/nmeth/journal/v12/n4/full/nmeth.3290.html&#34;&gt;Improved data analysis for the minion nanopore sequencer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2015 | &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4722697/&#34;&gt;MinION Analysis and Reference Consortium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2015 | &lt;a href=&#34;http://www.nature.com/nmeth/journal/v12/n8/full/nmeth.3444.html&#34;&gt;A complete bacterial genome assembled &lt;em&gt;de novo&lt;/em&gt; using only nanopore sequencing data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2012 | &lt;a href=&#34;http://nature.com/nbt/journal/v30/n4/full/nbt.2171.html&#34;&gt;Reading DNA at single-nucleotide resolution with a mutant MspA nanopore and phi29 DNA polymerase&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Simpson Lab &lt;a href=&#34;http://simpsonlab.github.io/2015/04/08/eventalign/&#34;&gt;blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Poretools analysis &lt;a href=&#34;http://poretools.readthedocs.org/&#34;&gt;suite&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>1. History</title>
      <link>https://nekrut.github.io/BMMB554/post/topic1/</link>
      <pubDate>Wed, 11 Jan 2017 11:41:14 -0500</pubDate>
      
      <guid>https://nekrut.github.io/BMMB554/post/topic1/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/luria_small.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;why-history&#34;&gt;Why history?&lt;/h1&gt;

&lt;p&gt;Knowing history is essential for understanding how we arrived to the current state of affairs in our field. It is also full of acciental discoveries and dramatic relationships making it quite interesting to read about. I strongly advise you to take a look at the mansucripts below.&lt;/p&gt;

&lt;h2 id=&#34;classical-publications&#34;&gt;Classical publications&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;1965 | &lt;a href=&#34;http://www.amazon.com/A-History-Genetics-A-H-Sturtevant/dp/0879696079&#34;&gt;A history of genetics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1943 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/delbruck-luria-1943.pdf&#34;&gt;Delbruck &amp;amp; Luria&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1944 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/avery-1944.pdf&#34;&gt;Avery, MacLeod, &amp;amp; McCarty&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1952 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/hershey-chase-1952.pdf&#34;&gt;Herhey &amp;amp; Chase&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1953 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/watsoncrick.pdf&#34;&gt;Watson &amp;amp; Crick&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1958 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/Proc%20Natl%20Acad%20Sci%20USA%201958%20Meselson.pdf&#34;&gt;Meselson &amp;amp; Stahl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1960 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/jacob-monod-1961.pdf&#34;&gt;Jacob and Monod&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;popular-yet-very-informative-literature&#34;&gt;Popular (yet very informative) literature&lt;/h2&gt;

&lt;p&gt;Get one of these and read it on a plane:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1978 | &lt;a href=&#34;https://www.amazon.com/Molecular-Genetics-Introductory-Gunther-Stent/dp/0716700484&#34;&gt;Molecular Gemetics: An Itroductory Narrative&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2001 | &lt;a href=&#34;http://www.amazon.com/The-Double-Helix-Discovery-Structure/dp/074321630X&#34;&gt;The double helix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2005 | &lt;a href=&#34;http://www.amazon.com/Third-Man-Double-Helix-Autobiography/dp/019280667X&#34;&gt;The Third Man of the Double Helix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2014 | &lt;a href=&#34;http://www.amazon.com/Brave-Genius-Philosopher-Adventures-Resistance/dp/0307952347&#34;&gt;Brave Genius&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;publication-highlight-the-fluctuation-test&#34;&gt;Publication highlight | The fluctuation test&lt;/h1&gt;

&lt;p&gt;In a truly collaborative spirit a german physicist &lt;a href=&#34;http://www.nobelprize.org/nobel_prizes/medicine/laureates/1969/delbruck-facts.html&#34;&gt;Max Delbrck&lt;/a&gt; joined forces with an italian microbiologist &lt;a href=&#34;http://www.nobelprize.org/nobel_prizes/medicine/laureates/1969/luria-facts.html&#34;&gt;Salvador Luria&lt;/a&gt; to prove the stochastic nature of mutations and to reject &amp;ldquo;the last stroghold of Lamarckism&amp;rdquo;. This &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/delbruck-luria-1943.pdf&#34;&gt;classical work&lt;/a&gt; was published in 1943 in journal &lt;em&gt;Genetics&lt;/em&gt;. Here we re-examine some of the fundamental aspects of this work. In this we occasionally rely on a classical textbook in &lt;a href=&#34;http://www.amazon.com/Molecular-Genetics-Introductory-Gunther-Stent/dp/0716700484&#34;&gt;Molecular Genetics&lt;/a&gt; by Gnther Stent.&lt;/p&gt;

&lt;p&gt;So, it has been know for some time that:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bacteria sensitive (infectable) by phage becomes resistant as a result of exposure to bacteriophage&lt;/li&gt;
&lt;li&gt;The resistance is preserved when descendants of these cells are incubated&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This can, in principle, be explained by two mutually exclusive hypotheses:&lt;/p&gt;

&lt;h2 id=&#34;acquired-resistance-vs-spontaneous-mutation&#34;&gt;Acquired resistance vs. spontaneous mutation&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;direct action of phage on bacteria triggers &amp;ldquo;acquisition&amp;rdquo; of the resistance;&lt;/li&gt;
&lt;li&gt;some cells in a population already have a mutation conferring the resistance and the exposure to the phage merely brings carriers of such mutations to prominence by killing off all sensitive cells.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;How can we distinguish between these two alternative possibilities? Let&amp;rsquo;s try to put hypothesis (1) into quantitative framework:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;There are two bacterial phenotypes: &lt;em&gt;S&lt;/em&gt; - sensitive (is lysed by the phage) and &lt;em&gt;R&lt;/em&gt; - resistant (is not lysed and does not absorb phage)&lt;/li&gt;
&lt;li&gt;Bacterial population progresses from a single cell to $N$ cells&lt;/li&gt;
&lt;li&gt;The probability of changing from &lt;em&gt;S&lt;/em&gt; to &lt;em&gt;R&lt;/em&gt; is $a$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, if one grows $S$ bacteria in a culture and then plates them on agar containing excess of phage, where will be $n$ of $R$ colonies, where $n =  aN$. Since we can estimate $n$ directly (by counting colonies on the plate) and $N$ is also known (a function of the number of generations) the fraction of $R$ individuals in a population is going to be same for all stages of the population:&lt;/p&gt;

&lt;div&gt;
$$

\frac{n}{N} = a

$$
&lt;/div&gt;

&lt;p&gt;This will not be quite the same for hypothesis (2) since the number of cells carrying the resistance mutation will differ depending on when in population history they occurred and how many generation have passed since their occurrence. After $g$ generations there will be&lt;/p&gt;

&lt;div&gt;
$$

N = 2^g

$$
&lt;/div&gt;

&lt;p&gt;cells. Consequently, if the probability of mutation is $a$, then by $i$-th generation there will be $a2^i$ cells carrying mutations and we can arrive to the ratio of&lt;/p&gt;

&lt;div&gt;
$$

\frac{n}{N} = ga

$$
&lt;/div&gt;

&lt;p&gt;Delbck and Luria&amp;rsquo;s experience with estimating such ratio has proven to be difficult as they were observing great fluctuation in the number of $R$ cells. They have subsequently realized that such fluctuation was in fact an indirect indication that the mutation hypothesis is likely true. Delbrck has developed a theoretical framework predicting the distribution of mutant phenotypes for both hypotheses. &lt;a href=&#34;http://www.amazon.com/Molecular-Genetics-Introductory-Gunther-Stent/dp/0716700484&#34;&gt;Stent&lt;/a&gt; provides the following elegant description of Delbck&amp;rsquo;s reasonong. It is based on measuring the variance in the number of resistant colonies across a number of replicates. Suppose there are $c$ &lt;em&gt;E. coli&lt;/em&gt; replicates (cultures) started from a single &lt;em&gt;S&lt;/em&gt; bacterium. Each is grown for $g$ generations, and each accumulates $N = 2^g$ cells as a result. The entire content of each culture is then spread over agar plate saturated with the phage. The number $n$ of &lt;em&gt;R&lt;/em&gt; colonies is then counted. If $n_j$ is the number of &lt;em&gt;R&lt;/em&gt; colonies from culture $j$, then the average of the numbner of resistant colonies is:&lt;/p&gt;

&lt;div&gt;
$$

\bar{n} = \frac{\sum_{j=1}^{c}n_j}{c}

$$
&lt;/div&gt;

&lt;p&gt;and the variance is:&lt;/p&gt;

&lt;div&gt;
$$ 

var_n = \frac{\sum_{j=1}^{c}(\bar{n}-n_j)}{c}

$$
&lt;/div&gt;

&lt;p&gt;The behaviour of ratio of &lt;code&gt;variance/average&lt;/code&gt; is critical to distinguishing between hypothesis (1) and (2). If (1) is true we expect low fluctuation and the ratio will be close to 1. If (2) is true the variation will be considerable and the ratio will be much higher than one. Look at Fig. 1 below.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;In pane A (Hypothesis 1) phage induces changes in the bacteria upon plating and because the probability of changing from &lt;code&gt;S&lt;/code&gt; to &lt;code&gt;R&lt;/code&gt; is the same for  all cells we would see approximately the same number of &lt;code&gt;R&lt;/code&gt; cells. The mean here is &lt;code&gt;2.5&lt;/code&gt; and the variance/mean ratio is &lt;code&gt;1.1&lt;/code&gt;.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;In pane B (Hypothesis 2) every cell has the same mutation rate, but the mutations may occur at any point during the culture propagation. If they occur early - many resistant colonies will be produced from such culture. If they occur late - just a few. As a result one would expect to see significant fluctuation. Here the mean is the same as in A = &lt;code&gt;2.5&lt;/code&gt;, but the variance/mean ratio is much higher at &lt;code&gt;4.3&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/luria.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/stent.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Figure 1&lt;/strong&gt; (Fig. 6-4 from Stent)&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Table 1&lt;/strong&gt; (Table 6-1 from Stent)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Table 1 settles these issues. Here one can see a significant fluctuation across 20 independent experiments with the main of &lt;code&gt;11.3&lt;/code&gt; and variance/mean ratio of &lt;code&gt;61&lt;/code&gt;. This table also show the result of plating aliquots from a bulk culture. In this case 10 ml culture was incubated for the same duration as the 20 independent cultures. Small amount from this culture were then plated on 10 independent plates. Because these cells share their genetic ancestry there is very little variation across these platings.&lt;/p&gt;

&lt;p&gt;This paper settled one of the most contentious issues in biology and won the Nobel prize to its authors.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;slides&#34;&gt;Slides&lt;/h1&gt;

&lt;p&gt;Slides covering material for Lecture 1&lt;/p&gt;

&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;7726e8b8b3ee41f0a2a1497128d59ca0&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;video&#34;&gt;Video&lt;/h1&gt;

&lt;p&gt;Video presentation from last year.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/180735569&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;hr /&gt;

&lt;h1 id=&#34;what-to-do-before-next-lecture&#34;&gt;What to do before next lecture&lt;/h1&gt;

&lt;p&gt;Read two following papers:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;ldquo;DNA sequencing with chain-terminating inhibitors&amp;rdquo; by Sanger, Nicklen, and Coulson (&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC431765/pdf/pnas00043-0271.pdf&#34;&gt;1977&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&amp;ldquo;A new method for sequencing DNA&amp;rdquo; by Maxam and Gilbert (&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC392330/pdf/pnas00024-0174.pdf&#34;&gt;1977&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Syllabus</title>
      <link>https://nekrut.github.io/BMMB554/post/syllabus/</link>
      <pubDate>Mon, 09 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://nekrut.github.io/BMMB554/post/syllabus/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://xkcd.com/451/&#34;&gt;&lt;img src=&#34;http://imgs.xkcd.com/comics/impostor.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;instructor&#34;&gt;Instructor&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Anton Nekrutenko&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;mailto:aun1@psu.edu?Subject=BMMB554&#34;&gt;aun1@psu.edu&lt;/a&gt;&lt;br&gt;
Wartik 505&lt;br&gt;
Office hours by appointment only&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;font color=&#34;orange&#34;&gt;&amp;#9888;&lt;/font&gt; When contacting instructor use the above e-mail and include &amp;ldquo;BMMB554&amp;rdquo; in the subject line (simply click on e-mail address).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;course-description&#34;&gt;Course description&lt;/h1&gt;

&lt;p&gt;This course is designed as a preparation routine for graduate students in Life Sciences. It has several focus areas including evolution of life sciences as well as in-depth overview of sequencing technologies and their applications.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;grading&#34;&gt;Grading&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Homework = 50%&lt;/li&gt;
&lt;li&gt;Final project = 50%&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;topics&#34;&gt;Topics&lt;/h1&gt;

&lt;p&gt;We will cover a breadth of topics. Below is the approximate list. Keep in mind that this field is very dynamic. To account for that we may skip or extend some of the subjects.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;History: From Genetics to Genomics&lt;/li&gt;
&lt;li&gt;Sequencing: From Sanger to Nanopores I&lt;/li&gt;
&lt;li&gt;Sequencing: From Sanger to Nanopores II&lt;/li&gt;
&lt;li&gt;Algorithms: Alignment Basics&lt;/li&gt;
&lt;li&gt;Algorithms: Aligning many sequences quickly&lt;/li&gt;
&lt;li&gt;Algorithms: Assembly I&lt;/li&gt;
&lt;li&gt;Algorithms: Assembly II&lt;/li&gt;
&lt;li&gt;Galaxy: An introduction&lt;/li&gt;
&lt;li&gt;Galaxy: Writing your own tools&lt;/li&gt;
&lt;li&gt;Re-sequencing I: Introduction and non-diploid case&lt;/li&gt;
&lt;li&gt;Re-sequencing II: Diploid genomes&lt;/li&gt;
&lt;li&gt;Practicum: Re-sequencing&lt;/li&gt;
&lt;li&gt;Transcriptomics I: Refrence-based&lt;/li&gt;
&lt;li&gt;Transcriptomics II: Reference-free&lt;/li&gt;
&lt;li&gt;Practicum: Transcriptomics&lt;/li&gt;
&lt;li&gt;RNA analysis: RiboSeq and ShapeSeq&lt;/li&gt;
&lt;li&gt;Practicum: RNA analysis&lt;/li&gt;
&lt;li&gt;DNA/Protein interactions I: Approaches&lt;/li&gt;
&lt;li&gt;DNA/Protein interactions II: ENCODE Project&lt;/li&gt;
&lt;li&gt;Practicum: DNA/Protein interactions&lt;/li&gt;
&lt;li&gt;Genome conformation analysis&lt;/li&gt;
&lt;li&gt;Practicum: Genome conformation analysis&lt;/li&gt;
&lt;li&gt;Metagenomics I: Approaches&lt;/li&gt;
&lt;li&gt;Metagenomics II: Community analysis&lt;/li&gt;
&lt;li&gt;Practicum: Metagenomics&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
&lt;p&gt;In an examination setting, unless the instructor gives explicit prior instructions to the contrary, violations of academic integrity shall consist of any attempt to receive assistance from written or printed aids, from any person or papers or electronic devices, or of any attempt to give assistance, whether the student doing so has completed his or her own work or not. Other violations include, but are not limited to, any attempt to gain an unfair advantage in regard to an examination, such as tampering with a graded exam or claiming another&amp;rsquo;s work to be one&amp;rsquo;s own. Other assessments (including ANGEL-administered quizzes and assessments as well as homework assignments) are expected to represent your own independent work unless specifically stated otherwise. Failure to comply will lead to sanctions against the student in accordance with the Policy on Academic Integrity in the Eberly College of Science. The Eberly College of Science Code of Mutual Respect and Cooperation (www.science.psu.edu/climate/Code-of-Mutual-Respect-final.pdf) embodies the values that we hope our faculty, staff, and students possess and will endorse to make The Eberly College of Science a place where every individual feels respected and valued, as well as challenged and rewarded.   The Eberly College of Science is committed to the academic success of students enrolled in the College&amp;rsquo;s  courses and undergraduate programs. When in need of help, students can utilize various College and University wide resources for learning assistance (&lt;a href=&#34;http://www.science.psu.edu/advising/success&#34;&gt;http://www.science.psu.edu/advising/success&lt;/a&gt;). Penn State welcomes students with disabilities into the University&amp;rsquo;s educational programs. If you have a disability-related need for reasonable academic adjustments in this course, contact the Office for Disability Services (ODS) at 814-863-1807 (V/TTY). For further information regarding ODS, please visit the Office for Disability Services Web site at &lt;a href=&#34;http://equity.psu.edu/ods/.&#34;&gt;http://equity.psu.edu/ods/.&lt;/a&gt; In order to receive consideration for course accommodations, you must contact ODS and provide documentation (see the &lt;a href=&#34;http://equity.psu.edu/student-disability-resources/guidelines&#34;&gt;documentation guidelines&lt;/a&gt;). If the documentation supports the need for academic adjustments, ODS will provide a letter identifying appropriate academic adjustments. Please share this letter and discuss the adjustments with your instructor as early in the course as possible. You must contact ODS and request academic adjustment letters at the beginning of each semester.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
  </channel>
</rss>